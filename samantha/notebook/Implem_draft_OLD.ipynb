{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Draft Lab OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beltre.wilton/miniforge3/envs/tars_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from dspy.functional import TypedPredictor\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from transitions import Machine\n",
    "from dotenv import dotenv_values\n",
    "from rich import print\n",
    "\n",
    "\n",
    "secret = dotenv_values('../../.secret')\n",
    "llm  = dspy.OpenAI(\n",
    "    model='gpt-3.5-turbo-0125',\n",
    "    # model='gpt-3.5-turbo',\n",
    "    # model='gpt-4',\n",
    "    # model='gpt-4o',\n",
    "    api_key=secret['OPEN_AI_API_KEY'],\n",
    "    max_tokens=4096\n",
    ")\n",
    "\n",
    "dspy.settings.configure(lm=llm)\n",
    "\n",
    "# groq = dspy.GROQ(model='llama3-70b-8192', api_key=secret['GROQ_API_KEY'], max_tokens=2000)\n",
    "# dspy.settings.configure(lm=groq, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m400\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Produce key-pair semantic synth-data by stage\n",
    "# stage: intro + uttetance type == greeting\n",
    "\n",
    "greetings = {\n",
    "  \"hello_messages\": [\n",
    "        \"Hi, how's it going?\",\n",
    "        \"Hey! 👋\",\n",
    "        \"Hi! I'm excited to chat with you.\",\n",
    "        \"Hello! What's up?\",\n",
    "        \"Hey there! 😊\",\n",
    "        \"Hi, it's nice to meet you.\",\n",
    "        \"Hey, how are you today?\",\n",
    "        \"Hi! I'm looking forward to talking to you.\",\n",
    "        \"Hey! What's new with you?\",\n",
    "        \"Hi, how's your day going?\",\n",
    "        \"Hey! I'm happy to connect with you.\",\n",
    "        \"Hi! It's great to meet you.\",\n",
    "        \"Hey, what brings you here?\",\n",
    "        \"Hi! I'm excited to get to know you.\",\n",
    "        \"Hey! Long time no talk!\",\n",
    "        \"Hi! I'm looking forward to chatting with you.\",\n",
    "        \"Hey! How's life treating you?\",\n",
    "        \"Hi! Let's catch up.\",\n",
    "        \"Hey! What's on your mind?\",\n",
    "        \"Hi! It's nice to reconnect.\",\n",
    "        \"Hey! Let's talk soon.\",\n",
    "        \"Hi! I'm glad we connected.\",\n",
    "        \"Hey there! 😊 How's it going?\",\n",
    "        \"Good morning! 🌞 Hope you're well!\",\n",
    "        \"Hi! 👋 What's up?\",\n",
    "        \"Hello! How are you today? 😄\",\n",
    "        \"Yo! What's good? 😎\",\n",
    "        \"Hey! Long time no chat! 🕰️\",\n",
    "        \"Hi! How's everything? 🌟\",\n",
    "        \"Hey, what's new? 🤔\",\n",
    "        \"Good evening! 🌙 How was your day?\",\n",
    "        \"Hey! What's happening? 🤷‍♂️\",\n",
    "        \"Hello! How have you been? 😊\",\n",
    "        \"Hey, what's cracking? 😄\",\n",
    "        \"Hey! How you doin'? 😉\",\n",
    "        \"Hello! Trust you're doing well. 🙏\",\n",
    "        \"Hi! What's going on? 🤔\",\n",
    "        \"Hey, how's your day been? 😊\",\n",
    "        \"Greetings! 🎉 How's it going?\",\n",
    "        \"Hey! Any news? 📰\",\n",
    "        \"Hi there! How's your week been? 📅\",\n",
    "        \"Hello! Everything good? 👍\",\n",
    "        \"Hey! What's the latest? 📢\",\n",
    "        \"Hi! How's your morning? ☕\",\n",
    "        \"Hey! What are you up to? 🤔\",\n",
    "        \"Hi! How's your day going? 😊\",\n",
    "        \"Hello! How are things? 🌟\",\n",
    "        \"Hey! How's your night? 🌙\",\n",
    "        \"Hi! What's up with you? 🤔\",\n",
    "        \"Hey! How's life treating you? 🍀\",\n",
    "        \"Hello! How's your week going? 📅\",\n",
    "        \"Hi! How's everything on your end? 🌟\",\n",
    "        \"Hey! What's good with you? 😎\",\n",
    "        \"Hi! How have you been feeling? 😊\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "\n",
    "company_related = {\n",
    "    \"comments\": [\n",
    "        \"What is the company culture like?\",\n",
    "        \"I'm interested in the customer service role, can you send me more info?\",\n",
    "        \"Do you offer any training programs for new hires?\",\n",
    "        \"What are the working hours for the inbound sales team?\",\n",
    "        \"How many days off do we get per year? 🤔\",\n",
    "        \"Is there opportunity for growth within the company?\",\n",
    "        \"What kind of benefits do you offer to employees?\",\n",
    "        \"I'm interested in the data entry role, what are the responsibilities?\",\n",
    "        \"Do you have a referral program for employees?\",\n",
    "        \"What is the average salary for a customer service rep?\",\n",
    "        \"Do you have a dress code policy?\",\n",
    "        \"How does the performance evaluation process work?\",\n",
    "        \"What kind of support does the company offer for professional development?\",\n",
    "        \"Can you tell me more about the team I'll be working with?\",\n",
    "        \"What are the company's short-term and long-term goals?\",\n",
    "        \"Are there any opportunities for remote work?\",\n",
    "        \"What's the typical career path for someone in the customer service team?\",\n",
    "        \"Do you offer any employee discounts or perks?\",\n",
    "        \"How does the company approach work-life balance?\",\n",
    "        \"What sets this company apart from other call centers?\",\n",
    "        \"What's the company's policy on flexible scheduling?\",\n",
    "        \"Hey there! Could you tell me more about the company's history?\",\n",
    "        \"Good morning! What are the company's main products or services?\",\n",
    "        \"Hi! Can you provide some insights into the company culture?\",\n",
    "        \"Hello! How does the company foster employee growth and development?\",\n",
    "        \"Yo! What's the company's mission and values?\",\n",
    "        \"Hey! I'm curious, what sets this company apart from its competitors?\",\n",
    "        \"Hi! What's the company's stance on sustainability?\",\n",
    "        \"Hey, what's the work environment like at the company?\",\n",
    "        \"Hey! What's the company's approach to diversity and inclusion?\",\n",
    "        \"Hi! Can you tell me about the company's financial performance?\",\n",
    "        \"Hello! How does the company give back to the community?\",\n",
    "        \"Hey, what's the average tenure of employees at the company?\",\n",
    "        \"Hi! How does the company ensure a safe and inclusive workplace?\",\n",
    "        \"Hey! Can you share any upcoming projects or initiatives the company is working on?\",\n",
    "        \"Hello! What's the company's policy on remote work?\",\n",
    "        \"Hi! How does the company encourage innovation among its employees?\",\n",
    "        \"Hey! Can you tell me about the company's customer base?\",\n",
    "        \"Hello! What training and development opportunities does the company provide?\",\n",
    "        \"Hey, what benefits does the company offer to its employees?\",\n",
    "        \"Hey! Can you provide some information about the company's technology stack?\",\n",
    "        \"Hello! How does the company ensure data privacy and security?\",\n",
    "        \"Hi! What's the company's policy on flexible working hours?\",\n",
    "        \"Hey! I'm interested to know about the company's training programs.\",\n",
    "        \"Hi! Can you tell me about the company's customer satisfaction ratings?\",\n",
    "        \"Hey, what opportunities for professional development does the company offer?\",\n",
    "        \"Hello! How does the company celebrate employee achievements?\",\n",
    "        \"Hi! What's the company's approach to employee wellness?\",\n",
    "        \"Hey! Can you share any success stories or case studies?\",\n",
    "        \"Hello! How does the company support employee mental health?\",\n",
    "        \"Hi! What's the company's strategy for growth and expansion?\",\n",
    "\n",
    "\n",
    "        \"Can you tell me more about the company's culture?\",\n",
    "        \"What's the typical career path for someone in this role?\",\n",
    "        \"How do you measure success in this position?\",\n",
    "        \"What are the main challenges new hires usually face?\",\n",
    "        \"Is there room for growth within the company?\",\n",
    "        \"What kind of training programs do you offer?\",\n",
    "        \"Can you explain the team structure here?\",\n",
    "        \"How do you handle employee feedback?\",\n",
    "        \"What's the most rewarding part of working here?\",\n",
    "        \"What are the shift patterns like?\",\n",
    "        \"Do you offer remote working options?\",\n",
    "        \"How do you support work-life balance?\",\n",
    "        \"What are the next steps in the hiring process?\",\n",
    "        \"Can you describe a typical day in this job?\",\n",
    "        \"How does this role contribute to the company's goals?\",\n",
    "        \"What's the company's stance on overtime?\",\n",
    "        \"Do you provide any mental health support for employees?\",\n",
    "        \"How often do you conduct performance reviews?\",\n",
    "        \"What's the team dynamic like?\",\n",
    "        \"Are there opportunities for advancement?\",\n",
    "        \"What's the company's turnover rate?\",\n",
    "        \"Can you tell me more about the company’s mission?\",\n",
    "        \"How does the company recognize and reward outstanding performance?\",\n",
    "        \"What are the biggest challenges the company is currently facing?\",\n",
    "        \"How do you handle conflict within the team?\",\n",
    "        \"What's the onboarding process like?\",\n",
    "        \"How are goals and expectations communicated to the team?\",\n",
    "        \"What kind of feedback can I expect from my supervisor?\",\n",
    "        \"What's your policy on work-from-home?\",\n",
    "        \"How diverse is your team?\",\n",
    "        \"Are there opportunities for cross-training or job rotation?\",\n",
    "        \"What tools and technologies will I be using?\",\n",
    "        \"How does the company support professional development?\",\n",
    "        \"What's the company’s approach to customer service?\",\n",
    "        \"Do you have a mentoring program?\",\n",
    "        \"What are the main goals for the team this year?\",\n",
    "        \"Can you tell me about a successful project the team has completed recently?\",\n",
    "        \"What type of clients or customers does the company serve?\",\n",
    "        \"How does the company handle high-stress periods?\",\n",
    "        \"What's the most common reason employees stay long-term?\",\n",
    "        \"Do you offer any tuition reimbursement programs?\",\n",
    "        \"How would you describe the company’s management style?\",\n",
    "        \"What are the key skills needed for success in this role?\",\n",
    "        \"What are the company's values?\",\n",
    "        \"How do you ensure employees feel valued?\",\n",
    "        \"Is there a dress code?\",\n",
    "        \"How soon can I expect to hear back after this interview?\",\n",
    "        \"What are the benefits and perks?\",\n",
    "        \"How do you keep employees motivated and engaged?\",\n",
    "        \"Do you celebrate achievements or milestones?\"\n",
    "        \n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "continue_related = {\n",
    "    \"responses\": [\n",
    "\t    \"Sounds good! Let's move forward.\",\n",
    "\t    \"I'm happy to help. Please proceed.\",\n",
    "\t    \"That's correct! Let's continue 💬\",\n",
    "\t    \"Got it! Next steps are...\",\n",
    "\t    \"Affirmative, let's go ahead.\",\n",
    "\t    \"Excellent, what's the next question?\",\n",
    "\t    \"That's okay, let's try again.\",\n",
    "\t    \"I completely agree. What's next?\",\n",
    "\t    \"That's correct! 👍\",\n",
    "\t    \"I'm on the same page. Please proceed.\",\n",
    "\t    \"That's awesome! What's the next step?\",\n",
    "\t    \"I'm excited to see what's next!\",\n",
    "\t    \"That sounds like a plan. Let's do it.\",\n",
    "\t    \"I'm with you on that. What's next?\",\n",
    "\t    \"That's a great idea! Let's run with it.\",\n",
    "\t    \"That's a good point. Let's build on that.\",\n",
    "\t    \"I'm good with that. What's the next move?\",\n",
    "\t    \"That's the right approach. Let's continue.\",\n",
    "\t    \"That's a great start! What's next?\",\n",
    "\t    \"I'm on board with that. Let's proceed.\",\n",
    "\t    \"That's a fantastic idea! Let's make it happen.\",\n",
    "\t    \"Oki\",\n",
    "\t    \"Okay\",\n",
    "\t    \"Ok\",\n",
    "        \"Yes, I would like to continue.\",\n",
    "        \"Sure, I'm in!\",\n",
    "        \"Absolutely, let's go ahead.\",\n",
    "        \"Count me in!\",\n",
    "        \"I agree, let's proceed.\",\n",
    "        \"I'm on board with this.\",\n",
    "        \"Yep, sounds good to me.\",\n",
    "        \"Definitely, let's do this.\",\n",
    "        \"Okay, I'm ready to move forward.\",\n",
    "        \"Alright, let's continue.\",\n",
    "        \"Of course, I'm in favor.\",\n",
    "        \"👍 I'm in.\",\n",
    "        \"Yes, please proceed.\",\n",
    "        \"I'm all set to continue.\",\n",
    "        \"For sure, let's keep going.\",\n",
    "        \"I'm okay with that, let's proceed.\",\n",
    "        \"Certainly, I agree.\",\n",
    "        \"👌 Let's go for it.\",\n",
    "        \"Fine by me, let's move forward.\",\n",
    "        \"I'm down for this!\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "not_continue_related = {\n",
    "    \"responses\": [\n",
    "        \"Thanks for the offer, but I’ll pass this time.\",\n",
    "        \"I appreciate it, but I’m not interested in continuing.\",\n",
    "        \"I'm going to have to decline, thanks for considering me.\",\n",
    "        \"Sorry, but I don’t agree with this approach.\",\n",
    "        \"I’ve decided not to move forward with this process.\",\n",
    "        \"Thanks, but I’m not up for it.\",\n",
    "        \"Unfortunately, I have to say no.\",\n",
    "        \"I’m not comfortable with this, sorry.\",\n",
    "        \"I’m out, but thanks for the opportunity.\",\n",
    "        \"I’ve thought about it, and I’m not interested.\",\n",
    "        \"Thanks, but this isn't for me.\",\n",
    "        \"I'm going to step back from this, but thank you.\",\n",
    "        \"I’m choosing not to proceed, thanks.\",\n",
    "        \"This doesn't align with my interests, so I’m not continuing.\",\n",
    "        \"I’ll be bowing out of this process.\",\n",
    "        \"I’m going to pass on this, thanks though.\",\n",
    "        \"No, I’m not going to accept this.\",\n",
    "        \"I can’t go along with this plan.\",\n",
    "        \"I have to say no, but I appreciate it.\",\n",
    "        \"Not agreeing with this, sorry.\",\n",
    "        \"I’m not interested in pursuing this further.\",\n",
    "        \"I’m going to have to pass on this opportunity.\",\n",
    "        \"I won’t be moving forward with this, thanks.\",\n",
    "        \"This isn’t something I want to do, sorry.\",\n",
    "        \"I’m not on board with this.\",\n",
    "        \"Nope, not for me. Thanks anyway!\",\n",
    "        \"I’m not feeling this, so I’m out.\",\n",
    "        \"I’m going to decline, but I appreciate the offer.\",\n",
    "        \"This doesn’t work for me, so I’m saying no.\",\n",
    "        \"I’ve decided against this, thanks anyway.\",\n",
    "        \"I’m not continuing with this, sorry.\",\n",
    "        \"I’m declining to move forward, thanks.\",\n",
    "        \"Thanks, but I’ll have to decline.\",\n",
    "        \"This isn't the right fit for me, so no.\",\n",
    "        \"I don't agree with this, so I won't proceed.\",\n",
    "        \"I’m going to have to say no to this.\",\n",
    "        \"Sorry, but I’m not interested in this.\",\n",
    "        \"Thanks, but I’m not going ahead with this.\",\n",
    "        \"I’m passing on this, but thanks.\",\n",
    "        \"I’m choosing not to participate, thank you.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "later_continue = {\n",
    "    \"phrases\": [\n",
    "        \"I'm taking a break, talk to you later on WhatsApp!\",\n",
    "        \"I need to go, catch you later!\",\n",
    "        \"I'm feeling a bit tired, will continue this convo later 😴\",\n",
    "        \"I'm out for now, will get back to you later!\",\n",
    "        \"Have to run, talk to you soon!\",\n",
    "        \"I'm not feeling up to chat right now, will continue later\",\n",
    "        \"I'm stepping away for a bit, be back soon!\",\n",
    "        \"I'm bored with this convo, will catch you later\",\n",
    "        \"I have to go, but we can pick this up later\",\n",
    "        \"I'm not able to continue right now, will talk to you later\",\n",
    "        \"I need some time to myself, talk to you later!\",\n",
    "        \"I'm taking a time-out, will come back to this later\",\n",
    "        \"I'm not feeling the energy to chat, will catch you later\",\n",
    "        \"I have to go, but we can continue this on WhatsApp later\",\n",
    "        \"I'm disconnecting for now, talk to you soon!\",\n",
    "        \"I'm not able to focus, will pick this up later\",\n",
    "        \"I'm out of energy, will catch you later!\",\n",
    "        \"I need a break from this convo, will continue later\",\n",
    "        \"I'm stepping away, but we can continue this on WhatsApp later\",\n",
    "        \"I'm not able to chat right now, will talk to you soon!\",\n",
    "        \"I'm feeling drained, will continue this later\",\n",
    "        \"Hey there! Thanks for reaching out. I'm currently tied up with a meeting, can we continue this later?\",\n",
    "        \"Good morning! I'm in the middle of something right now, can we pick this up in an hour?\",\n",
    "        \"Hi! Sorry, I'm swamped at the moment. Can we chat about this tomorrow?\",\n",
    "        \"Hello! I'm unable to continue the process at the moment due to some unforeseen circumstances.\",\n",
    "        \"Yo! Can we put a pin on this for now? I'll get back to you as soon as I can.\",\n",
    "        \"Hey! Unfortunately, I won't be able to proceed further with the interview today. Can we reschedule?\",\n",
    "        \"Hi! I'm tied up with back-to-back meetings. Can we touch base later?\",\n",
    "        \"Hello! I'm currently on the go, so I'll have to get back to you about this later.\",\n",
    "        \"Hey there! I'm really sorry, but I have an urgent task to attend to. Can we resume this discussion tomorrow?\",\n",
    "        \"Good morning! I'm running a bit behind schedule today. Can we continue this conversation later?\",\n",
    "        \"Hi! I'm afraid I won't be able to proceed with the evaluation at the moment. Can we reconvene tomorrow?\",\n",
    "        \"Hello! I'm currently dealing with an emergency situation. Can we postpone this to a later time?\",\n",
    "        \"Hey! I'm really sorry, but I have to step away for a moment. Can we continue this in an hour?\",\n",
    "        \"Hi! Unfortunately, I've hit a roadblock in the process. Can we revisit this tomorrow?\",\n",
    "        \"Hey there! I'm in the middle of something important. Can we catch up on this later?\",\n",
    "        \"Hello! I'm sorry, but I'm unable to dedicate time to this right now. Can we discuss this tomorrow?\",\n",
    "        \"Hi! I'm currently occupied with a pressing matter. Can we pick this up later in the day?\",\n",
    "        \"Hey! I'm juggling multiple tasks at the moment. Can we continue this at a more convenient time?\",\n",
    "        \"Hi! I'm really sorry, but I have to step out unexpectedly. Can we continue this discussion later?\",\n",
    "        \"Hello! I'm tied up with a deadline right now. Can we revisit this tomorrow?\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "feedbacks = {\n",
    "    \"feedback_requests\": [\n",
    "        \"Can you please update me on my application status?\",\n",
    "        \"What's the current stage of my hiring process?\",\n",
    "        \"Feedback on my interview would be appreciated, thanks!\",\n",
    "        \"How's my application doing? 🤔\",\n",
    "        \"Any news on my job application?\",\n",
    "        \"Could you share an update on my candidacy?\",\n",
    "        \"What's the latest on my application?\",\n",
    "        \"Kindly inform me about my application progress.\",\n",
    "        \"Can I get an update on my interview?\",\n",
    "        \"I'd love to know where I stand in the process.\",\n",
    "        \"Is there any update on my application status?\",\n",
    "        \"Please let me know if I'm still in the running?\",\n",
    "        \"Can you give me some feedback on my resume?\",\n",
    "        \"What's the current status of my application?\",\n",
    "        \"Any feedback on my performance during the interview?\",\n",
    "        \"Can I get an update on the hiring process?\",\n",
    "        \"I'm eagerly waiting to hear about my application.\",\n",
    "        \"What's the decision on my application?\",\n",
    "        \"Is my application still being considered?\",\n",
    "        \"Am I still in the running for this position?\",\n",
    "        \"Hey there! Just checking in to see if there's any update on my interview status?\",\n",
    "        \"Good morning! I was wondering if there's any news on where I stand in the evaluation process.\",\n",
    "        \"Hi! Can you provide me with an update on the status of my application, please?\",\n",
    "        \"Hello! I hope you're doing well. Could you please let me know the current status of my interview?\",\n",
    "        \"Yo! Any chance I could get an update on how things are progressing with my evaluation?\",\n",
    "        \"Hey! Just wanted to touch base and inquire about the status of my application.\",\n",
    "        \"Hi! I hope all is going smoothly. Any updates on my interview status?\",\n",
    "        \"Hello! Hope you're having a great day. Can you give me an update on my evaluation status?\",\n",
    "        \"Hey there! Wondering if there's any news on my application status?\",\n",
    "        \"Good morning! I hope you're doing well. Could you provide me with an update on my interview status?\",\n",
    "        \"Hi! Just checking in to see if there's any progress with my evaluation.\",\n",
    "        \"Hello! Hope you're having a good day. Any updates on my interview status?\",\n",
    "        \"Hey! Any chance I could get an update on my application status?\",\n",
    "        \"Hi! I hope you're doing well. Can you please let me know the status of my evaluation?\",\n",
    "        \"Hello! Just reaching out to see if there's any update on my interview status.\",\n",
    "        \"Hey there! Hoping to get an update on my application status.\",\n",
    "        \"Hi! I'm eager to know the status of my evaluation. Any updates?\",\n",
    "        \"Hello! Can you please provide me with an update on my interview status?\",\n",
    "        \"Hey! Just wanted to follow up on my application status. Any news?\",\n",
    "        \"Hi! I hope all is going smoothly. Could you provide me with an update on my evaluation status, please?\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "qa_1 = {\n",
    "    \"qa_1_responses\":  [\n",
    "        \"Sure, I have 3 years of experience working in a call center, handling customer inquiries and resolving issues efficiently.\",\n",
    "        \"Absolutely! I used to work in customer support for a tech company, helping clients with troubleshooting and product information.\",\n",
    "        \"Hey there! I spent 2 years at a call center, where I honed my skills in customer service and communication.\",\n",
    "        \"I've been in customer service for about 4 years now, mostly dealing with billing issues and service upgrades.\",\n",
    "        \"Yes, I worked as a customer service representative at a retail company, assisting customers with their orders and returns.\",\n",
    "        \"For sure! I have experience in a call center environment where I dealt with high-volume calls and customer complaints.\",\n",
    "        \"I used to handle customer queries and technical support for an ISP. It was challenging but rewarding!\",\n",
    "        \"Worked at a call center for 2 years, helping customers with account setups and troubleshooting issues.\",\n",
    "        \"Totally! My last job was in a call center, where I assisted customers with their service-related concerns.\",\n",
    "        \"Yes, I have experience in customer service, including resolving disputes and ensuring customer satisfaction.\",\n",
    "        \"Sure thing! I was a customer service agent at a financial institution, helping clients with their account management.\",\n",
    "        \"I’ve been in customer service roles for the past 5 years, focusing on resolving customer issues and enhancing their experience.\",\n",
    "        \"Definitely! I worked in a call center where I handled escalated calls and provided solutions to complex problems.\",\n",
    "        \"Yeah, I've got experience in customer service, mainly working in a support center for a telecom company.\",\n",
    "        \"I worked in a call center for 3 years, dealing with various customer issues and providing tech support.\",\n",
    "        \"In my previous job, I was responsible for managing customer inquiries and complaints in a busy call center.\",\n",
    "        \"Yes, I have a background in customer service, having worked in a call center environment for a couple of years.\",\n",
    "        \"I’ve done customer service for a software company, where I helped users with troubleshooting and product guidance.\",\n",
    "        \"My experience includes working in a call center where I provided assistance with billing, technical issues, and general inquiries.\",\n",
    "        \"👋 I've worked in customer service for 2 years, focusing on resolving customer issues and ensuring their satisfaction.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "qa_2 = {\n",
    "    \"qa_2_responses\":  [\n",
    "        \"I stay motivated by taking short breaks and listening to my favorite music.\",\n",
    "        \"Keeping a positive mindset and thinking about the happy customers I've helped keeps me going.\",\n",
    "        \"I remind myself of my goals and the rewards of hard work.\",\n",
    "        \"I take deep breaths and focus on one task at a time.\",\n",
    "        \"Honestly, a cup of strong coffee and some good vibes do the trick! ☕️✨\",\n",
    "        \"I stay energized by keeping a picture of my family on my desk.\",\n",
    "        \"Motivation comes from knowing I make a difference in someone's day.\",\n",
    "        \"Staying organized and having a plan helps me stay on track.\",\n",
    "        \"I chat with my coworkers and share a laugh when things get tough.\",\n",
    "        \"I keep motivated by setting small, achievable goals throughout the day.\",\n",
    "        \"I think about the end of the day and the satisfaction of a job well done.\",\n",
    "        \"I stay positive by celebrating little victories and milestones.\",\n",
    "        \"I listen to motivational podcasts during my breaks.\",\n",
    "        \"Remembering why I started this job in the first place helps a lot.\",\n",
    "        \"I keep a stash of my favorite snacks for a quick energy boost. 🍫\",\n",
    "        \"I stay focused by visualizing my career growth and future opportunities.\",\n",
    "        \"I find motivation in the supportive team and positive work environment.\",\n",
    "        \"Taking a moment to stretch and move around helps keep me energized.\",\n",
    "        \"I love hearing feedback from satisfied customers, it really lifts my spirits.\",\n",
    "        \"I remind myself that each call is a chance to learn something new.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "qa_3 = {\n",
    "    \"qa_3_responses\":  [\n",
    "        \"I always stay calm and listen to the customer's concerns carefully before offering a solution.\",\n",
    "        \"It's all about empathy and understanding their point of view, then finding a way to make things right.\",\n",
    "        \"First, I try to understand the problem from their perspective and then work towards a satisfactory resolution.\",\n",
    "        \"I usually take a deep breath, remain composed, and ensure the customer feels heard and valued.\",\n",
    "        \"I focus on active listening and try to resolve their issues promptly to keep them satisfied.\",\n",
    "        \"Handling tough situations involves staying positive, being patient, and finding effective solutions.\",\n",
    "        \"I make sure to acknowledge their frustration and then offer a step-by-step solution.\",\n",
    "        \"Gotta keep cool, listen up, and sort out their issue as best as I can.\",\n",
    "        \"First things first, I let them vent and then work on resolving their problem efficiently.\",\n",
    "        \"Staying calm and collected, I address their concerns and provide a swift resolution.\",\n",
    "        \"I ensure to empathize with them and address their issues in a professional manner.\",\n",
    "        \"Listening actively and offering practical solutions is my go-to approach.\",\n",
    "        \"I keep my cool and always make sure the customer feels understood and appreciated.\",\n",
    "        \"I apologize for any inconvenience caused and work diligently to fix the issue.\",\n",
    "        \"I stay patient and offer solutions that are both effective and timely.\",\n",
    "        \"My approach is to stay calm, understand their problem, and resolve it ASAP. 👍\",\n",
    "        \"I believe in listening carefully and addressing their concerns with empathy and efficiency.\",\n",
    "        \"I let them know I'm here to help and then provide a solution that meets their needs.\",\n",
    "        \"Handling it with a smile and a can-do attitude usually helps in resolving their issues. 😊\",\n",
    "        \"I stay professional, listen to their problems, and work towards a quick resolution.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "qa_4 = {\n",
    "    \"qa4_responses\": [\n",
    "        \"Hey! Absolutely, I thrive in team settings and have no problem following established procedures.\",\n",
    "        \"Sure thing! I'm great at collaborating with others and sticking to company policies.\",\n",
    "        \"Yep, I'm a team player and always follow the rules and procedures.\",\n",
    "        \"Definitely! I work well with others and adhere to established policies and procedures.\",\n",
    "        \"Of course! I'm all about teamwork and making sure everything runs smoothly according to the rules.\",\n",
    "        \"No doubt! I excel in team environments and am diligent about following policies and procedures.\",\n",
    "        \"Absolutely! Working in a team is my jam, and I'm all about following the rules.\",\n",
    "        \"You bet! Teamwork is key, and I'm committed to following established policies and procedures.\",\n",
    "        \"Yes, I'm quite comfortable working in a team and following all the necessary procedures.\",\n",
    "        \"Yep, team player here! I'm good at working collaboratively and sticking to procedures.\",\n",
    "        \"For sure! I'm a team player through and through, and I'm diligent about following policies and procedures.\",\n",
    "        \"Absolutely! I thrive in team environments and am committed to following all policies and procedures.\",\n",
    "        \"Definitely! Teamwork is my forte, and I'm dedicated to following established policies and procedures.\",\n",
    "        \"Sure thing! I'm all about teamwork and ensuring everything is done according to the rules.\",\n",
    "        \"Of course! I'm comfortable working in a team and following all procedures.\",\n",
    "        \"No problem at all! I'm great at collaborating with others and adhering to policies and procedures.\",\n",
    "        \"Absolutely! I'm a team player, and I take following policies and procedures seriously.\",\n",
    "        \"Yep, teamwork is my specialty! I'm good at following established procedures.\",\n",
    "        \"You got it! I work effectively in team environments and always stick to the policies and procedures.\",\n",
    "        \"Yes, indeed! I'm quite adept at working in teams and following all necessary procedures.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def merge_examples(sample_type: str, sample: dict):\n",
    "    return [dspy.Example({\"utterance\": f, \"utterance_type\": sample_type}).with_inputs(\"utterance\") for f in list(sample.values())[0]]\n",
    "\n",
    "    \n",
    "examples: List[dspy.Example] = []\n",
    "all_types = {\n",
    "    \"greetings\": greetings,\n",
    "    \"company_related\": company_related, \n",
    "    \"continue_related\": continue_related,\n",
    "    \"not_continue_related\": not_continue_related,\n",
    "    \"later_continue\": later_continue, \n",
    "    \"feedbacks\": feedbacks, \n",
    "    \"qa_1\": qa_1,\n",
    "    \"qa_2\": qa_2,\n",
    "    \"qa_3\": qa_3,\n",
    "    \"qa_4\": qa_4,\n",
    "}\n",
    "for sample_type, sample in all_types.items():\n",
    "    examples.extend(merge_examples(sample_type, sample))\n",
    "\n",
    "print(len(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b54ae3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer_embed = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_embed = AutoModel.from_pretrained('nomic-ai/nomic-embed-text-v1.5', trust_remote_code=True, safe_serialization=True)\n",
    "model_embed.eval()\n",
    "\n",
    "def embedd(text: str):\n",
    "    def mean_pooling(model_output, attention_mask):\n",
    "        token_embeddings = model_output[0]\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    encoded_input = tokenizer_embed(text, padding=True, truncation=True, return_tensors='pt')\n",
    "    # + matryoshka_dim = 512\n",
    "    with torch.no_grad():\n",
    "        model_output = model_embed(**encoded_input)\n",
    "\n",
    "    embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    # + embeddings = F.layer_norm(embeddings, normalized_shape=(embeddings.shape[1],))\n",
    "    # + embeddings = embeddings[:, :matryoshka_dim]\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    return np.array(embeddings)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "733db6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import dspy\n",
    "from dspy import settings\n",
    "from typing import Literal\n",
    "from dsp.modules.gpt3 import chat_request, completions_request, GPT3\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "secret = dotenv_values('../../.secret')\n",
    "\n",
    "MESSAGES = [] # TODO: It can be a conversation history from a database.\n",
    "MEM_SIZE = 8\n",
    "\n",
    "class ChatGPT(GPT3):\n",
    "    def __init__(self, model: str = \"gpt-3.5-turbo-instruct\", messages: list[str] = [], mem_size: int = 4, api_key: str | None = None, api_provider: Literal['openai'] = \"openai\", api_base: str | None = None, model_type: Literal['chat'] | Literal['text'] = None, system_prompt: str | None = None, **kwargs):\n",
    "      super().__init__(model, api_key, api_provider, api_base, model_type, system_prompt, **kwargs)\n",
    "      self.messages = messages\n",
    "      self.mem_size = mem_size * 2\n",
    "      \n",
    "    def basic_request(self, prompt: str, **kwargs):\n",
    "        raw_kwargs = kwargs\n",
    "\n",
    "        kwargs = {**self.kwargs, **kwargs}\n",
    "        if self.model_type == \"chat\":\n",
    "            if len(self.messages) > self.mem_size:\n",
    "                self.messages.pop(1) # keep instruction message\n",
    "            \n",
    "            if self.system_prompt:\n",
    "                self.messages.insert(0, {\"role\": \"system\", \"content\": self.system_prompt})\n",
    "            \n",
    "            memorize = kwargs.pop('__memorize', True)\n",
    "            user_input = kwargs.pop('__user_input')\n",
    "\n",
    "            # Prepare the messages with history\n",
    "            if len(self.history) == 0:\n",
    "                self.messages = [{\"role\": \"user\", \"content\": prompt}] # TODO: first input is contained in prompt!.....\n",
    "            \n",
    "            _msglist = [msg['content'] for msg in self.messages][-3:-1]\n",
    "\n",
    "            # pattern = r'\\n' + INPUT_FIELD + ':.+'\n",
    "            # matches = re.findall(pattern, prompt)\n",
    "            # user_input = matches[-1].replace(f'\\n{INPUT_FIELD}: ', '')\n",
    "\n",
    "            if memorize:\n",
    "                self.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "            \n",
    "            kwargs[\"messages\"] = self.messages\n",
    "            kwargs = {\"stringify_request\": json.dumps(kwargs)}\n",
    "            response = chat_request(**kwargs)\n",
    "\n",
    "            if user_input in _msglist and memorize:\n",
    "                self.messages.pop()\n",
    "\n",
    "            with open(\"chat_gpt_dump.json\", \"w\") as file:\n",
    "                json.dump(kwargs, file)\n",
    "\n",
    "            if user_input not in _msglist:\n",
    "                ans = response[\"choices\"][0]['message']['content']\n",
    "                pattern = r'\\n.+:.+'\n",
    "                matches = re.findall(pattern, ans)\n",
    "                if len(matches) > 0:\n",
    "                    # lm_answer = matches[-1].replace(f'\\n{OUTPUT_FIELD}: ', '')\n",
    "                    lm_answer = re.sub(r'\\n.+:\\ ', '', matches[-1])\n",
    "                else:\n",
    "                    lm_answer = ans\n",
    "\n",
    "                if lm_answer not in _msglist and memorize:\n",
    "                    self.messages.append({\"role\": \"assistant\", \"content\": lm_answer})\n",
    "        else:\n",
    "            kwargs[\"prompt\"] = prompt\n",
    "            response = completions_request(**kwargs)\n",
    "\n",
    "        history = {\n",
    "            \"prompt\": prompt,\n",
    "            \"response\": response,\n",
    "            \"kwargs\": kwargs,\n",
    "            \"raw_kwargs\": raw_kwargs,\n",
    "        }\n",
    "        self.history.append(history)\n",
    "\n",
    "        return response\n",
    "\n",
    "\n",
    "import copy\n",
    "import dsp\n",
    "from dsp.templates.template_v3 import Template\n",
    "from typing import Any, Callable, Optional\n",
    "from dsp.primitives.demonstrate import Example\n",
    "from dsp.primitives.predict import get_all_fields_following_missing_field, generate, Completions\n",
    "from dsp.utils.utils import dotdict\n",
    "\n",
    "\n",
    "def _generate(template: Template, **kwargs) -> Callable:\n",
    "    \"\"\"Returns a callable function that generates completions for a given example using the provided template.\"\"\"\n",
    "    if not dsp.settings.lm:\n",
    "        raise AssertionError(\"No LM is loaded.\")\n",
    "\n",
    "    generator = dsp.settings.lm\n",
    "\n",
    "    def extend_generation(completion: Example, field_names: list[str], stage:str, max_depth: int, original_example:Example):\n",
    "        \"\"\"If the required fields are not present in the completion, extend the generation.\"\"\"\n",
    "        assert max_depth > 0, \"Max depth exceeded - failed to complete in one pass - increase max_tokens\"\n",
    "        # remove content of last field to avoid half-completed content\n",
    "        for field_name in get_all_fields_following_missing_field(completion, field_names):\n",
    "            completion.pop(field_name, None)\n",
    "\n",
    "        # Recurse with greedy decoding and a shorter length.\n",
    "        max_tokens = (kwargs.get(\"max_tokens\") or \n",
    "                    kwargs.get(\"max_output_tokens\") or\n",
    "                    dsp.settings.lm.kwargs.get(\"max_tokens\") or \n",
    "                    dsp.settings.lm.kwargs.get('max_output_tokens'))\n",
    "\n",
    "\n",
    "        if max_tokens is None:\n",
    "            raise ValueError(\"Required 'max_tokens' or 'max_output_tokens' not specified in settings.\")\n",
    "        max_tokens = min(max(75, max_tokens // 2), max_tokens)\n",
    "        keys = list(kwargs.keys()) + list(dsp.settings.lm.kwargs.keys()) \n",
    "        max_tokens_key = \"max_tokens\" if \"max_tokens\" in keys else \"max_output_tokens\"\n",
    "        new_kwargs = {\n",
    "            **kwargs,\n",
    "            max_tokens_key: max_tokens,\n",
    "            \"n\": 1,\n",
    "            \"temperature\": 0.0,\n",
    "        }\n",
    "\n",
    "        _, finished_completion = generate(template, **new_kwargs)(\n",
    "            completion,\n",
    "            stage=stage,\n",
    "            max_depth=max_depth - 1,\n",
    "            original_example=original_example,\n",
    "        )\n",
    "        return finished_completion.data[0]\n",
    "        \n",
    "\n",
    "    def do_generate(\n",
    "        example: Example, stage: str, max_depth: int = 2, original_example=None,\n",
    "    ):\n",
    "        if not dsp.settings.lm:\n",
    "            raise AssertionError(\"No LM is loaded.\")\n",
    "        original_example = original_example or example\n",
    "        assert stage is not None\n",
    "\n",
    "        # Look up the appropriate fields in each demonstration.\n",
    "        example = example.demos_at(lambda d: d[stage])\n",
    "\n",
    "        # Generate and extract the fields.\n",
    "        prompt = template(example)\n",
    "        ex = copy.deepcopy(example)\n",
    "        ex.pop('demos', None)\n",
    "        ex.pop('context', None)\n",
    "        ex.pop('passages', None)\n",
    "        ex.pop('rationale', None)\n",
    "        kwargs['__memorize'] = ex.pop('__memorize', True)\n",
    "        kwargs['__user_input'] = ', '.join([ex[k] for k in ex.keys()])\n",
    "        completions: list[dict[str, Any]] = generator(prompt, **kwargs)\n",
    "        completions: list[Example] = [template.extract(example, p) for p in completions]\n",
    "\n",
    "        # Find the completions that are unfinished.\n",
    "        field_names: list[str] = [field.input_variable for field in template.fields]\n",
    "\n",
    "        finished_completions = []\n",
    "        for completion in completions:\n",
    "            if all((completion.get(key, \"\") != \"\") for key in field_names):\n",
    "                finished_completions.append(completion)\n",
    "                continue\n",
    "            finished_completions.append(\n",
    "                extend_generation(completion, field_names, stage, max_depth, original_example),\n",
    "            )\n",
    "\n",
    "        completions = Completions(finished_completions, template=template)\n",
    "        example = example.copy(completions=completions)\n",
    "\n",
    "        if len(completions) == 1:\n",
    "            completion = completions[0]\n",
    "            example[stage] = example.copy(**completion)\n",
    "\n",
    "            if dsp.settings.compiling:\n",
    "                inputs_ = set(original_example.keys())\n",
    "                inputs = [\n",
    "                    f.input_variable\n",
    "                    for f in template.fields\n",
    "                    if f.input_variable in inputs_\n",
    "                ]\n",
    "                outputs = [\n",
    "                    f.output_variable\n",
    "                    for f in template.fields\n",
    "                    if f.input_variable not in inputs_\n",
    "                ]\n",
    "\n",
    "                example.compiling_stages = example.get(\"compiling_stages\", [])\n",
    "                example.compiling_stages.append(\n",
    "                    {\n",
    "                        \"name\": stage,\n",
    "                        \"template\": template,\n",
    "                        \"inputs\": inputs,\n",
    "                        \"outputs\": outputs,\n",
    "                    },\n",
    "                )\n",
    "        else:\n",
    "            # assert not dsp.settings.compiling, \"TODO: At this point, cannot compile n>1 generations\"\n",
    "            example[stage] = dotdict(completions=completions)\n",
    "\n",
    "        return example, completions\n",
    "\n",
    "    return do_generate\n",
    "    \n",
    "\n",
    "#TODO: ovverride \n",
    "from dsp.primitives import predict\n",
    "# predict._generate = _generate\n",
    "\n",
    "\n",
    "    \n",
    "# system_prompt= \"IMPORTANT INSTRUCT AS A SYSTEM\"\n",
    "# custom_gtp = ChatGPT('gpt-3.5-turbo', messages=MESSAGES, mem_size=MEM_SIZE, api_key=secret['OPEN_AI_API_KEY'], model_type=\"chat\", max_tokens=250,)\n",
    "# settings.configure(lm=custom_gtp, )\n",
    "\n",
    "\n",
    "class ConversationalSignature(dspy.Signature):\n",
    "    \"\"\"You are a helpful assistant. Answer all questions to the best of your ability.\"\"\"\n",
    "    message = dspy.InputField(desc='Contains the user message input.', memorize=True)\n",
    "    # context = dspy.InputField(desc=\"Before responding, AI must consider relevant facts in the history of conversation.\")\n",
    "    answer = dspy.OutputField(desc='Contains the assistant message output, use a short response')\n",
    "\n",
    "\n",
    "class ConversationalModule(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conversation = dspy.ChainOfThought(ConversationalSignature)\n",
    "\n",
    "    def forward(self, message: str):\n",
    "        response = self.conversation(message=message)\n",
    "        return response\n",
    "    \n",
    "\n",
    "# compiled_module = ConversationalModule()\n",
    "# # compiled_module.load(\"samantha/notebook/conversational_module.json\")\n",
    "\n",
    "# response = compiled_module(message=\"Hi, my name is Rolando Espinal.\")\n",
    "# print(response)\n",
    "\n",
    "# response = compiled_module(message=\"Do you remember my lastname?\")\n",
    "# print(response)\n",
    "\n",
    "# response = compiled_module(message=\"Wilton prepares for a 15 km walk, advancing 1.5 km per hour. If Wilton starts at 7 am, how many kilometers has Wilton traveled at 9 am?\")\n",
    "# print(response)\n",
    "\n",
    "# response = compiled_module(message=\"His wife, Priscila, joins the walk at 10 am. How many kilometers has Wilton traveled?\")\n",
    "# print(response)\n",
    "\n",
    "# response = compiled_module(message=\"Priscila is fast and moves at a speed of 2 km per hour, when Wilton has already traveled 12 kilometers. How many kilometers has Priscila traveled?\")\n",
    "# print(response)\n",
    "\n",
    "# response = compiled_module(message=\"Do you remember my lastname?\")\n",
    "# print(response)\n",
    "\n",
    "# response = compiled_module(message=\"What is Wilton's wifes name?\")\n",
    "# print(response)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b967705c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>applicant<span style=\"font-weight: bold\">]</span>: What are the biggest challenges the company is currently facing?\n",
       "   utt_type: company_related  curr: new\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mapplicant\u001b[1m]\u001b[0m: What are the biggest challenges the company is currently facing?\n",
       "   utt_type: company_related  curr: new\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Adapting to industry-specific requirements, ensuring continuous agent training 📞'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'answer_is_in_context_provided'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'answer'\u001b[0m: \u001b[32m'Adapting to industry-specific requirements, ensuring continuous agent training 📞'\u001b[0m,\n",
       "    \u001b[32m'answer_is_in_context_provided'\u001b[0m: \u001b[3;92mTrue\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "from transitions import Machine\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "from pgvector.psycopg2 import register_vector\n",
    "import dspy\n",
    "from dspy.functional import TypedPredictor\n",
    "from dspy.retrieve.pgvector_rm import PgVectorRM\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from transitions import Machine\n",
    "from dotenv import dotenv_values\n",
    "from rich import print\n",
    "\n",
    "\n",
    "db_url = \"postgresql://drfadul:dROG%40dijoFadul@localhost/synaia\"\n",
    "retriever_model = PgVectorRM(\n",
    "    db_url=db_url, \n",
    "    pg_table_name=\"company_info\",\n",
    "    k=3,\n",
    "    embedding_func=embedd,\n",
    "    embedding_field=\"embedding\",\n",
    "    fields=[\"text\"],\n",
    "    include_similarity=True\n",
    ")\n",
    "\n",
    "MESSAGES = [] # TODO: It can be a conversation history from a database.\n",
    "MEM_SIZE = 8\n",
    "secret = dotenv_values('../../.secret')\n",
    "\n",
    "openai  = dspy.OpenAI(\n",
    "    model='gpt-3.5-turbo-0125',\n",
    "    # model='gpt-3.5-turbo',\n",
    "    # model='gpt-4',\n",
    "    # model='gpt-4o',\n",
    "    api_key=secret['OPEN_AI_API_KEY'],\n",
    "    max_tokens=4096,\n",
    "    model_type=\"chat\",\n",
    ")\n",
    "settings.configure(lm=openai, )\n",
    "\n",
    "# custom_gpt = ChatGPT('gpt-3.5-turbo', messages=MESSAGES, mem_size=MEM_SIZE, api_key=secret['OPEN_AI_API_KEY'], model_type=\"chat\", max_tokens=250,)\n",
    "# settings.configure(lm=custom_gpt, )\n",
    "\n",
    "# dspy.settings.configure(lm=custom_gpt)\n",
    "\n",
    "\n",
    "class NotFound(dspy.Signature):\n",
    "    \"\"\"Generates a denial response related to the question in context\"\"\"\n",
    "    context: str = dspy.InputField()\n",
    "    response: str = dspy.OutputField(desc=\"often between 3 and 7 words\")\n",
    "\n",
    "class Veracity(dspy.Signature):\n",
    "    context_provided: str = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    answer: str = dspy.InputField()\n",
    "    answer_is_in_context_provided: bool = dspy.OutputField(desc=\"verify that the answer is in the context_provided, respond True or False\")\n",
    "\n",
    "\n",
    "class CompanySignature(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers and friendly, use emoji. Answer should be in the context.\"\"\"\n",
    "    context: str = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question: str = dspy.InputField(desc=\"user question to be answered\")\n",
    "    answer: str = dspy.OutputField(desc=\"often between 6 and 12 words\")\n",
    "\n",
    "\n",
    "class CompanyRelated(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.retriever = retriever_model\n",
    "        self.predict = dspy.ChainOfThought(CompanySignature)\n",
    "        self.veracity = dspy.TypedChainOfThought(Veracity)\n",
    "        self.not_found = dspy.Predict(NotFound)\n",
    "    \n",
    "    def forward(self, question: str):\n",
    "        context = self.retriever(question)\n",
    "        context = [ctx['text'] for ctx in context]\n",
    "        response = self.predict(context=context, question=question)\n",
    "        veracity = self.veracity(context_provided=str(context), answer=response.answer)\n",
    "        if veracity.answer_is_in_context_provided:\n",
    "            r = response\n",
    "            return {\n",
    "                \"answer\": r.answer,\n",
    "                \"answer_is_in_context_provided\": veracity.answer_is_in_context_provided\n",
    "            }\n",
    "        else:\n",
    "            r = self.not_found(context=question)\n",
    "            return {\n",
    "                \"answer\": r.response,\n",
    "                \"answer_is_in_context_provided\": veracity.answer_is_in_context_provided\n",
    "            }\n",
    "        \n",
    "\n",
    "class AnswerComment(dspy.Signature):\n",
    "    \"\"\"Generate a positive or supportive comment to the response, use emoji.\"\"\"\n",
    "    response: str = dspy.InputField()\n",
    "    comment: str = dspy.OutputField(desc=\"often between 5 and 10 words\")\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "utterance_type_list = list(all_types.keys())\n",
    "utterance_type_list.append('out_of_scope')\n",
    "\n",
    "class UtteranceSignature(dspy.Signature):\n",
    "    \"\"\"A basic utterance classifier in a chat conversation.\"\"\"\n",
    "    utterance = dspy.InputField(desc=\"An user utterance\")\n",
    "    utterance_type = dspy.OutputField(desc=f\"One type in the following list {str(utterance_type_list)}\")\n",
    "\n",
    "\n",
    "class UtteranceClassificator(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cot = dspy.ChainOfThought(UtteranceSignature)\n",
    "\n",
    "    def forward(self, utterance: str) -> str:\n",
    "        kwargs = {\"__memorize\": False}\n",
    "        return self.cot(utterance=utterance)\n",
    "    \n",
    "\n",
    "class ActionSignature(dspy.Signature):\n",
    "    \"\"\"A basic notification\"\"\"\n",
    "    utterance = dspy.InputField(desc=\"An user utterance\")\n",
    "    response = dspy.OutputField()\n",
    "\n",
    "    \n",
    "class Action(dspy.Module):\n",
    "    def __init__(self, signature):\n",
    "        super().__init__()\n",
    "        self.action_push = dspy.ChainOfThought(signature)\n",
    "        \n",
    "    def forward(self, utterance: str):\n",
    "        return self.action_push(utterance=utterance)\n",
    "    \n",
    "\n",
    "\n",
    "class Stages(Machine):\n",
    "    def __init__(self, initial_state: str = 'new',) -> None:\n",
    "        states = [\"new\", \"question_1\", \"question_2\", \"question_3\", \"question_4\", \"recording\", \"evaluation\"]\n",
    "        self.utt_clasificator = UtteranceClassificator()\n",
    "        self.utt_clasificator.load(\"utterance_module_v2.json\")\n",
    "        self.utterance = \"\"\n",
    "        self.response: str = \"\"\n",
    "\n",
    "        self.company_related_module = CompanyRelated()\n",
    "        self.answer_comment = dspy.ChainOfThought(AnswerComment)\n",
    "\n",
    "        Machine.__init__(self, states=states, initial=initial_state)\n",
    "        self.add_transition(trigger='greetings', source='*', dest=None, prepare=self.move)\n",
    "        self.add_transition(trigger='continue_related', source='*', dest=None, prepare=self.move)\n",
    "        self.add_transition(trigger='later_continue', source='*', dest=None, prepare=self.later)\n",
    "        self.add_transition(trigger='not_continue_related', source='*', dest=None, prepare=self.later)\n",
    "        self.add_transition(trigger='company_related', source='*', dest=None, prepare=self.company)\n",
    "        self.add_transition(trigger='feedbacks', source='*', dest=None, prepare=self.feedback)\n",
    "        self.add_transition(trigger='out_of_scope', source='*', dest=None, prepare=self.outofscope)\n",
    "        self.add_transition(trigger='qa_1', source=['question_1', 'question_2', 'question_3', 'question_4'], dest=None, prepare=self.qa)\n",
    "        self.add_transition(trigger='qa_2', source=['question_1', 'question_2', 'question_3', 'question_4'], dest=None, prepare=self.qa)\n",
    "        self.add_transition(trigger='qa_3', source=['question_1', 'question_2', 'question_3', 'question_4'], dest=None, prepare=self.qa)\n",
    "        self.add_transition(trigger='qa_4', source=['question_1', 'question_2', 'question_3', 'question_4'], dest=None, prepare=self.qa)\n",
    "\n",
    "        self.add_ordered_transitions()\n",
    "\n",
    "        #TODO: continuar aqui .....\n",
    "        self.question_list = [\n",
    "            {'question_1': 'What is your previous experience in customer service or in a call center environment?'},\n",
    "            {'question_2': 'How do you stay motivated during long hours of customer service?'},\n",
    "            {'question_3': ''},\n",
    "            {'question_4': ''},\n",
    "        ]\n",
    "\n",
    "        self.signature_map = {\n",
    "            'greetings': {\n",
    "                '_signature': 'Back hello as a response acording to the context information. ',\n",
    "                'new': 'Ask the following question: What is your previous experience in customer service or in a call center environment?',\n",
    "                'question_1': 'tell the user to answer the question question_1.',\n",
    "                'question_2': 'tell the user to answer the question question_2.',\n",
    "                'question_3': 'tell the user to answer the question question_3.',\n",
    "                'question_4': 'tell the user to answer the question question_4.',\n",
    "                'recording':'Ask if is ready to continue with the recording step.',\n",
    "            },\n",
    "            'continue_related': {\n",
    "                '_signature': '',\n",
    "                'new': 'Ask the following question: What is your previous experience in customer service or in a call center environment?',\n",
    "                'qa_1': 'Ask the following question: How do you stay motivated during long hours of customer service?',\n",
    "                'qa_2': 'Answer the following: now can we start recording your voice?',\n",
    "                'recording': 'You should thank him or her for participating.',\n",
    "            },\n",
    "            'not_continue_related': {\n",
    "                '_signature': 'Reply we appreciate your time, If you change your mind, we will be gladly waiting for you. ',\n",
    "            },\n",
    "            'later_continue': {\n",
    "                '_signature': 'Reply we appreciate your time, it will only take a minute or two, if you can\\'t yet, when can I write to you? ',\n",
    "            },\n",
    "            'company_related': {\n",
    "                '_signature': 'Answer this company question probably using RAG. ',\n",
    "            },\n",
    "            'feedbacks': {\n",
    "                '_signature': 'Answer this user feedback question probably hitting the data base. ',\n",
    "            },\n",
    "            'out_of_scope': {\n",
    "                '_signature': 'Respond by saying that is not within your power and why don\\'t we go back to the prescreening process! ',\n",
    "            },\n",
    "            'qa_1': {\n",
    "                '_signature': 'question_1, Is it a valid answer according to the question \"{}\" ? ',\n",
    "            },\n",
    "            'qa_2': {\n",
    "                '_signature': 'question_2, Is it a valid answer according to the question \"{}\" ? ',\n",
    "            },\n",
    "            'qa_3': {\n",
    "                '_signature': 'question_3, Is it a valid answer according to the question \"{}\" ? ',\n",
    "            },\n",
    "            'qa_4': {\n",
    "                '_signature': 'question_4, Is it a valid answer according to the question \"{}\" ? ',\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def router(self, utterance: str):\n",
    "        self.utterance = utterance\n",
    "        response = self.utt_clasificator(utterance)\n",
    "        self.trigger(response.utterance_type, response.utterance_type)\n",
    "\n",
    "    def _pkg(self, utt_type: str):\n",
    "        if self.state in self.signature_map[utt_type]:\n",
    "            state_message = self.signature_map[utt_type][self.state]\n",
    "        else:\n",
    "            state_message = ''\n",
    "        signature = self.signature_map[utt_type]['_signature'] + state_message\n",
    "        ActionSignature.__doc__ = signature\n",
    "        action = Action(ActionSignature)\n",
    "        response = action(utterance=self.utterance)\n",
    "        self.response = response\n",
    "        return response\n",
    "\n",
    "\n",
    "    def push(self, utt_type: str):\n",
    "        response = self._pkg(utt_type)\n",
    "        print(response)\n",
    "\n",
    "    def move(self, utt_type: str):\n",
    "        response = self._pkg(utt_type)\n",
    "        #TODO: also move to the next state\n",
    "        prev = self.state\n",
    "        if \"new\" == self.state: self.next_state()\n",
    "        print(f\"\\[applicant]: {self.utterance}\\n   utt_type: {utt_type}  prev: {prev}  curr: {self.state}\")\n",
    "        print(response)\n",
    "        if \"question\" in prev: print('PIN to the last question.')\n",
    "       \n",
    "\n",
    "    def later(self, utt_type: str):\n",
    "        response = self._pkg(utt_type)\n",
    "        print(f\"\\[applicant]: {self.utterance}\\n   utt_type: {utt_type}  curr: {self.state}\")\n",
    "        print(response)\n",
    "\n",
    "    def company(self, utt_type: str):\n",
    "        signature = self.signature_map[utt_type]['_signature'] #TODO: not used\n",
    "        print(f\"\\[applicant]: {self.utterance}\\n   utt_type: {utt_type}  curr: {self.state}\")\n",
    "        response = self.company_related_module(question=self.utterance)\n",
    "        print(response)\n",
    "        if \"question\" in self.state: print('Ask to response the last question or TASK (recording), PIN to the last question.')\n",
    "\n",
    "    def feedback(self, utt_type: str):\n",
    "        #TODO: use ReACT/retriever and query in DB relevant user information status.\n",
    "        signature = self.signature_map[utt_type]['_signature']\n",
    "        print(f\"\\[applicant]: {self.utterance}\\n   utt_type: {utt_type}  curr: {self.state}\")\n",
    "        print(signature)\n",
    "        print(\"if user has pending task/question, PIN in WhatsApp to the last question [keep the id-msg in memory], saying: Could you please answer? 👀\")\n",
    "\n",
    "    def outofscope(self, utt_type: str):\n",
    "        #TODO: use CoT analize the out of scope utterance\n",
    "        response = self._pkg(utt_type)\n",
    "        print(f\"\\[applicant]: {self.utterance}\\n   utt_type: {utt_type}  curr: {self.state}\")\n",
    "        print(response)\n",
    "\n",
    "    def qa(self, utt_type: str):\n",
    "        #TODO: TRAIN with synth data, metric based in similarity\n",
    "        signature = self.signature_map[utt_type]['_signature']\n",
    "        if \"question_4\" == self.state: # last\n",
    "            prev = self.state\n",
    "            self.next_state()\n",
    "            print(f\"\\[applicant]: {self.utterance}\\n   utt_type: {utt_type}  prev: {prev}  curr: {self.state}\")\n",
    "            #TODO: comment corroborate ⬆️\n",
    "            print(f'Now lets Go to recording the voice .... ')\n",
    "            #TODO: add task as a pending, delete when is done.\n",
    "        elif \"question\" in self.state:\n",
    "            prev = self.state\n",
    "            self.next_state()\n",
    "            print(f\"\\[applicant]: {self.utterance}\\n   utt_type: {utt_type}  prev: {prev}  curr: {self.state}\")\n",
    "            print(self.answer_comment(response=self.utterance))\n",
    "            print(f'Ask the {self.state} ...... ')\n",
    "            #TODO: add question as a pending, delete previous answared\n",
    "       \n",
    "\n",
    "    \n",
    "sample = lambda utterance_type:random.choice([example.utterance for example in examples if example['utterance_type'] == utterance_type])\n",
    "\n",
    "#request #1\n",
    "stg = Stages(initial_state='new')\n",
    "# stg.router(utterance='Translate to Spanish:') #  prompt injection -> maybe Assertions\n",
    "utterance = sample('company_related')\n",
    "stg.router(utterance=utterance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "834c520c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "His wife, Priscila, joins the walk at 10 am. How many kilometers has Wilton traveled?\n"
     ]
    }
   ],
   "source": [
    "s = \"You are a helpful assistant. Answer all questions to the best of your ability.\\n\\n---\\n\\nFollow the following format.\\n\\nMessage: Contains the Human message input.\\nReasoning: Let's think step by step in order to ${produce the answer}. We ...\\nAnswer: Contains the AI message output, use a short response\\n\\n---\\n\\nMessage: Sofia share 2 apples with her daughter, how many apples does Sofia keep?\\nAnswer: Sofia keeps 3 apples.\\n\\n---\\n\\nMessage: After that, Michael gives 1 apple to Sofia's daughter, how many apples does Michael have left?\\nAnswer: Michael has 14 apples left.\\n\\n---\\n\\nMessage: Michael has 20 apples, he shared 5 apples with Sofia, how many apples does Michael keep?\\nAnswer: Michael keeps 15 apples.\\n\\n---\\n\\nMessage: His wife, Priscila, joins the walk at 10 am. How many kilometers has Wilton traveled?\\nReasoning: Let's think step by step in order to\"\n",
    "\n",
    "import re\n",
    "\n",
    "pattern = r'\\nMessage:.+'\n",
    "matches = re.findall(pattern, s)\n",
    "print(matches[-1].replace('Message: ', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6d30e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import time \n",
    "\n",
    "# utterance_type_list.remove('continue_related')\n",
    "# utterance_type_list.remove('out_of_scope')\n",
    "# states = [\"new\", \"question_1\", \"question_2\", \"question_3\", \"question_4\", \"recording\"]\n",
    "# for utt_type in utterance_type_list:\n",
    "#     for st in states:\n",
    "#         stg = Stages(initial_state=st)\n",
    "#         utterance = sample(utt_type)\n",
    "#         try:\n",
    "#             stg.router(utterance=utterance)\n",
    "#         except Exception as ex: \n",
    "#             print(ex)\n",
    "#         time.sleep(2)\n",
    "\n",
    "\n",
    "#request #2\n",
    "# stg = Stages(initial_state='new')\n",
    "# utterance = sample('company_related')\n",
    "# print(\"Applicant: \", utterance)\n",
    "# stg.router(utterance=utterance)\n",
    "\n",
    "#request #3\n",
    "# stg = Stages(initial_state='new')\n",
    "# utterance = sample('continue_related')\n",
    "# print(\"Applicant: \", utterance)\n",
    "# stg.router(utterance=utterance)\n",
    "\n",
    "# #request #4\n",
    "# stg = Stages(initial_state='qa_1')\n",
    "# utterance = \"I was working for more than 5 years in the industry of call centers\"\n",
    "# print(\"Applicant: \", utterance)\n",
    "# stg.router(utterance=utterance)\n",
    "\n",
    "# #request #5\n",
    "# stg = Stages(initial_state='qa_2')\n",
    "# utterance = sample('feedbacks')\n",
    "# print(\"Applicant: \", utterance)\n",
    "# stg.router(utterance=utterance)\n",
    "\n",
    "# #request #6\n",
    "# stg = Stages(initial_state='qa_2')\n",
    "# utterance = \"this is my accurate response to the qa_2 question about previous experience in customer service.\"\n",
    "# print(\"Applicant: \", utterance)\n",
    "# stg.router(utterance=utterance)\n",
    "\n",
    "# #request #7\n",
    "# stg = Stages(initial_state='recording')\n",
    "# utterance = \"Affirmative, let's go ahead.\"\n",
    "# print(\"Applicant: \", utterance)\n",
    "# stg.router(utterance=utterance)\n",
    "\n",
    "#TODO: revisar el foro.\n",
    "#TODO: leer el paper.\n",
    "#TODO: posible path: Memory -> RAG -> Nuevos Modulos para cada path.\n",
    "#TODO: agregar state inicial: draft, si está en draft que no permita hacer nada que no sea completar el form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e4bacea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>applicant<span style=\"font-weight: bold\">]</span>: How diverse is your team?\n",
       "   utt_type: company_related  curr: new\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mapplicant\u001b[1m]\u001b[0m: How diverse is your team?\n",
       "   utt_type: company_related  curr: new\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Answer this company question probably using RAG. \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Answer this company question probably using RAG. \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "stg = Stages(initial_state=\"new\")\n",
    "# utterance = \"How would you describe the company’s management style?\"\n",
    "# utterance = \"What tools and technologies will I be using?\"\n",
    "utterance = \"How diverse is your team?\"\n",
    "try:\n",
    "    stg.router(utterance=utterance)\n",
    "except Exception as ex: \n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a97ad5",
   "metadata": {},
   "source": [
    "### Evaluation of devset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 70 / 140  (50.0): 100%|██████████| 140/140 [02:18<00:00,  1.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f69d3 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f69d3 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f69d3_row0_col0, #T_f69d3_row0_col1, #T_f69d3_row0_col2, #T_f69d3_row0_col3, #T_f69d3_row0_col4, #T_f69d3_row1_col0, #T_f69d3_row1_col1, #T_f69d3_row1_col2, #T_f69d3_row1_col3, #T_f69d3_row1_col4, #T_f69d3_row2_col0, #T_f69d3_row2_col1, #T_f69d3_row2_col2, #T_f69d3_row2_col3, #T_f69d3_row2_col4, #T_f69d3_row3_col0, #T_f69d3_row3_col1, #T_f69d3_row3_col2, #T_f69d3_row3_col3, #T_f69d3_row3_col4, #T_f69d3_row4_col0, #T_f69d3_row4_col1, #T_f69d3_row4_col2, #T_f69d3_row4_col3, #T_f69d3_row4_col4, #T_f69d3_row5_col0, #T_f69d3_row5_col1, #T_f69d3_row5_col2, #T_f69d3_row5_col3, #T_f69d3_row5_col4, #T_f69d3_row6_col0, #T_f69d3_row6_col1, #T_f69d3_row6_col2, #T_f69d3_row6_col3, #T_f69d3_row6_col4, #T_f69d3_row7_col0, #T_f69d3_row7_col1, #T_f69d3_row7_col2, #T_f69d3_row7_col3, #T_f69d3_row7_col4, #T_f69d3_row8_col0, #T_f69d3_row8_col1, #T_f69d3_row8_col2, #T_f69d3_row8_col3, #T_f69d3_row8_col4, #T_f69d3_row9_col0, #T_f69d3_row9_col1, #T_f69d3_row9_col2, #T_f69d3_row9_col3, #T_f69d3_row9_col4, #T_f69d3_row10_col0, #T_f69d3_row10_col1, #T_f69d3_row10_col2, #T_f69d3_row10_col3, #T_f69d3_row10_col4, #T_f69d3_row11_col0, #T_f69d3_row11_col1, #T_f69d3_row11_col2, #T_f69d3_row11_col3, #T_f69d3_row11_col4, #T_f69d3_row12_col0, #T_f69d3_row12_col1, #T_f69d3_row12_col2, #T_f69d3_row12_col3, #T_f69d3_row12_col4, #T_f69d3_row13_col0, #T_f69d3_row13_col1, #T_f69d3_row13_col2, #T_f69d3_row13_col3, #T_f69d3_row13_col4, #T_f69d3_row14_col0, #T_f69d3_row14_col1, #T_f69d3_row14_col2, #T_f69d3_row14_col3, #T_f69d3_row14_col4, #T_f69d3_row15_col0, #T_f69d3_row15_col1, #T_f69d3_row15_col2, #T_f69d3_row15_col3, #T_f69d3_row15_col4, #T_f69d3_row16_col0, #T_f69d3_row16_col1, #T_f69d3_row16_col2, #T_f69d3_row16_col3, #T_f69d3_row16_col4, #T_f69d3_row17_col0, #T_f69d3_row17_col1, #T_f69d3_row17_col2, #T_f69d3_row17_col3, #T_f69d3_row17_col4, #T_f69d3_row18_col0, #T_f69d3_row18_col1, #T_f69d3_row18_col2, #T_f69d3_row18_col3, #T_f69d3_row18_col4, #T_f69d3_row19_col0, #T_f69d3_row19_col1, #T_f69d3_row19_col2, #T_f69d3_row19_col3, #T_f69d3_row19_col4, #T_f69d3_row20_col0, #T_f69d3_row20_col1, #T_f69d3_row20_col2, #T_f69d3_row20_col3, #T_f69d3_row20_col4, #T_f69d3_row21_col0, #T_f69d3_row21_col1, #T_f69d3_row21_col2, #T_f69d3_row21_col3, #T_f69d3_row21_col4, #T_f69d3_row22_col0, #T_f69d3_row22_col1, #T_f69d3_row22_col2, #T_f69d3_row22_col3, #T_f69d3_row22_col4, #T_f69d3_row23_col0, #T_f69d3_row23_col1, #T_f69d3_row23_col2, #T_f69d3_row23_col3, #T_f69d3_row23_col4, #T_f69d3_row24_col0, #T_f69d3_row24_col1, #T_f69d3_row24_col2, #T_f69d3_row24_col3, #T_f69d3_row24_col4, #T_f69d3_row25_col0, #T_f69d3_row25_col1, #T_f69d3_row25_col2, #T_f69d3_row25_col3, #T_f69d3_row25_col4, #T_f69d3_row26_col0, #T_f69d3_row26_col1, #T_f69d3_row26_col2, #T_f69d3_row26_col3, #T_f69d3_row26_col4, #T_f69d3_row27_col0, #T_f69d3_row27_col1, #T_f69d3_row27_col2, #T_f69d3_row27_col3, #T_f69d3_row27_col4, #T_f69d3_row28_col0, #T_f69d3_row28_col1, #T_f69d3_row28_col2, #T_f69d3_row28_col3, #T_f69d3_row28_col4, #T_f69d3_row29_col0, #T_f69d3_row29_col1, #T_f69d3_row29_col2, #T_f69d3_row29_col3, #T_f69d3_row29_col4, #T_f69d3_row30_col0, #T_f69d3_row30_col1, #T_f69d3_row30_col2, #T_f69d3_row30_col3, #T_f69d3_row30_col4, #T_f69d3_row31_col0, #T_f69d3_row31_col1, #T_f69d3_row31_col2, #T_f69d3_row31_col3, #T_f69d3_row31_col4, #T_f69d3_row32_col0, #T_f69d3_row32_col1, #T_f69d3_row32_col2, #T_f69d3_row32_col3, #T_f69d3_row32_col4, #T_f69d3_row33_col0, #T_f69d3_row33_col1, #T_f69d3_row33_col2, #T_f69d3_row33_col3, #T_f69d3_row33_col4, #T_f69d3_row34_col0, #T_f69d3_row34_col1, #T_f69d3_row34_col2, #T_f69d3_row34_col3, #T_f69d3_row34_col4, #T_f69d3_row35_col0, #T_f69d3_row35_col1, #T_f69d3_row35_col2, #T_f69d3_row35_col3, #T_f69d3_row35_col4, #T_f69d3_row36_col0, #T_f69d3_row36_col1, #T_f69d3_row36_col2, #T_f69d3_row36_col3, #T_f69d3_row36_col4, #T_f69d3_row37_col0, #T_f69d3_row37_col1, #T_f69d3_row37_col2, #T_f69d3_row37_col3, #T_f69d3_row37_col4, #T_f69d3_row38_col0, #T_f69d3_row38_col1, #T_f69d3_row38_col2, #T_f69d3_row38_col3, #T_f69d3_row38_col4, #T_f69d3_row39_col0, #T_f69d3_row39_col1, #T_f69d3_row39_col2, #T_f69d3_row39_col3, #T_f69d3_row39_col4, #T_f69d3_row40_col0, #T_f69d3_row40_col1, #T_f69d3_row40_col2, #T_f69d3_row40_col3, #T_f69d3_row40_col4, #T_f69d3_row41_col0, #T_f69d3_row41_col1, #T_f69d3_row41_col2, #T_f69d3_row41_col3, #T_f69d3_row41_col4, #T_f69d3_row42_col0, #T_f69d3_row42_col1, #T_f69d3_row42_col2, #T_f69d3_row42_col3, #T_f69d3_row42_col4, #T_f69d3_row43_col0, #T_f69d3_row43_col1, #T_f69d3_row43_col2, #T_f69d3_row43_col3, #T_f69d3_row43_col4, #T_f69d3_row44_col0, #T_f69d3_row44_col1, #T_f69d3_row44_col2, #T_f69d3_row44_col3, #T_f69d3_row44_col4, #T_f69d3_row45_col0, #T_f69d3_row45_col1, #T_f69d3_row45_col2, #T_f69d3_row45_col3, #T_f69d3_row45_col4, #T_f69d3_row46_col0, #T_f69d3_row46_col1, #T_f69d3_row46_col2, #T_f69d3_row46_col3, #T_f69d3_row46_col4, #T_f69d3_row47_col0, #T_f69d3_row47_col1, #T_f69d3_row47_col2, #T_f69d3_row47_col3, #T_f69d3_row47_col4, #T_f69d3_row48_col0, #T_f69d3_row48_col1, #T_f69d3_row48_col2, #T_f69d3_row48_col3, #T_f69d3_row48_col4, #T_f69d3_row49_col0, #T_f69d3_row49_col1, #T_f69d3_row49_col2, #T_f69d3_row49_col3, #T_f69d3_row49_col4, #T_f69d3_row50_col0, #T_f69d3_row50_col1, #T_f69d3_row50_col2, #T_f69d3_row50_col3, #T_f69d3_row50_col4, #T_f69d3_row51_col0, #T_f69d3_row51_col1, #T_f69d3_row51_col2, #T_f69d3_row51_col3, #T_f69d3_row51_col4, #T_f69d3_row52_col0, #T_f69d3_row52_col1, #T_f69d3_row52_col2, #T_f69d3_row52_col3, #T_f69d3_row52_col4, #T_f69d3_row53_col0, #T_f69d3_row53_col1, #T_f69d3_row53_col2, #T_f69d3_row53_col3, #T_f69d3_row53_col4, #T_f69d3_row54_col0, #T_f69d3_row54_col1, #T_f69d3_row54_col2, #T_f69d3_row54_col3, #T_f69d3_row54_col4, #T_f69d3_row55_col0, #T_f69d3_row55_col1, #T_f69d3_row55_col2, #T_f69d3_row55_col3, #T_f69d3_row55_col4, #T_f69d3_row56_col0, #T_f69d3_row56_col1, #T_f69d3_row56_col2, #T_f69d3_row56_col3, #T_f69d3_row56_col4, #T_f69d3_row57_col0, #T_f69d3_row57_col1, #T_f69d3_row57_col2, #T_f69d3_row57_col3, #T_f69d3_row57_col4, #T_f69d3_row58_col0, #T_f69d3_row58_col1, #T_f69d3_row58_col2, #T_f69d3_row58_col3, #T_f69d3_row58_col4, #T_f69d3_row59_col0, #T_f69d3_row59_col1, #T_f69d3_row59_col2, #T_f69d3_row59_col3, #T_f69d3_row59_col4, #T_f69d3_row60_col0, #T_f69d3_row60_col1, #T_f69d3_row60_col2, #T_f69d3_row60_col3, #T_f69d3_row60_col4, #T_f69d3_row61_col0, #T_f69d3_row61_col1, #T_f69d3_row61_col2, #T_f69d3_row61_col3, #T_f69d3_row61_col4, #T_f69d3_row62_col0, #T_f69d3_row62_col1, #T_f69d3_row62_col2, #T_f69d3_row62_col3, #T_f69d3_row62_col4, #T_f69d3_row63_col0, #T_f69d3_row63_col1, #T_f69d3_row63_col2, #T_f69d3_row63_col3, #T_f69d3_row63_col4, #T_f69d3_row64_col0, #T_f69d3_row64_col1, #T_f69d3_row64_col2, #T_f69d3_row64_col3, #T_f69d3_row64_col4, #T_f69d3_row65_col0, #T_f69d3_row65_col1, #T_f69d3_row65_col2, #T_f69d3_row65_col3, #T_f69d3_row65_col4, #T_f69d3_row66_col0, #T_f69d3_row66_col1, #T_f69d3_row66_col2, #T_f69d3_row66_col3, #T_f69d3_row66_col4, #T_f69d3_row67_col0, #T_f69d3_row67_col1, #T_f69d3_row67_col2, #T_f69d3_row67_col3, #T_f69d3_row67_col4, #T_f69d3_row68_col0, #T_f69d3_row68_col1, #T_f69d3_row68_col2, #T_f69d3_row68_col3, #T_f69d3_row68_col4, #T_f69d3_row69_col0, #T_f69d3_row69_col1, #T_f69d3_row69_col2, #T_f69d3_row69_col3, #T_f69d3_row69_col4, #T_f69d3_row70_col0, #T_f69d3_row70_col1, #T_f69d3_row70_col2, #T_f69d3_row70_col3, #T_f69d3_row70_col4, #T_f69d3_row71_col0, #T_f69d3_row71_col1, #T_f69d3_row71_col2, #T_f69d3_row71_col3, #T_f69d3_row71_col4, #T_f69d3_row72_col0, #T_f69d3_row72_col1, #T_f69d3_row72_col2, #T_f69d3_row72_col3, #T_f69d3_row72_col4, #T_f69d3_row73_col0, #T_f69d3_row73_col1, #T_f69d3_row73_col2, #T_f69d3_row73_col3, #T_f69d3_row73_col4, #T_f69d3_row74_col0, #T_f69d3_row74_col1, #T_f69d3_row74_col2, #T_f69d3_row74_col3, #T_f69d3_row74_col4, #T_f69d3_row75_col0, #T_f69d3_row75_col1, #T_f69d3_row75_col2, #T_f69d3_row75_col3, #T_f69d3_row75_col4, #T_f69d3_row76_col0, #T_f69d3_row76_col1, #T_f69d3_row76_col2, #T_f69d3_row76_col3, #T_f69d3_row76_col4, #T_f69d3_row77_col0, #T_f69d3_row77_col1, #T_f69d3_row77_col2, #T_f69d3_row77_col3, #T_f69d3_row77_col4, #T_f69d3_row78_col0, #T_f69d3_row78_col1, #T_f69d3_row78_col2, #T_f69d3_row78_col3, #T_f69d3_row78_col4, #T_f69d3_row79_col0, #T_f69d3_row79_col1, #T_f69d3_row79_col2, #T_f69d3_row79_col3, #T_f69d3_row79_col4, #T_f69d3_row80_col0, #T_f69d3_row80_col1, #T_f69d3_row80_col2, #T_f69d3_row80_col3, #T_f69d3_row80_col4, #T_f69d3_row81_col0, #T_f69d3_row81_col1, #T_f69d3_row81_col2, #T_f69d3_row81_col3, #T_f69d3_row81_col4, #T_f69d3_row82_col0, #T_f69d3_row82_col1, #T_f69d3_row82_col2, #T_f69d3_row82_col3, #T_f69d3_row82_col4, #T_f69d3_row83_col0, #T_f69d3_row83_col1, #T_f69d3_row83_col2, #T_f69d3_row83_col3, #T_f69d3_row83_col4, #T_f69d3_row84_col0, #T_f69d3_row84_col1, #T_f69d3_row84_col2, #T_f69d3_row84_col3, #T_f69d3_row84_col4, #T_f69d3_row85_col0, #T_f69d3_row85_col1, #T_f69d3_row85_col2, #T_f69d3_row85_col3, #T_f69d3_row85_col4, #T_f69d3_row86_col0, #T_f69d3_row86_col1, #T_f69d3_row86_col2, #T_f69d3_row86_col3, #T_f69d3_row86_col4, #T_f69d3_row87_col0, #T_f69d3_row87_col1, #T_f69d3_row87_col2, #T_f69d3_row87_col3, #T_f69d3_row87_col4, #T_f69d3_row88_col0, #T_f69d3_row88_col1, #T_f69d3_row88_col2, #T_f69d3_row88_col3, #T_f69d3_row88_col4, #T_f69d3_row89_col0, #T_f69d3_row89_col1, #T_f69d3_row89_col2, #T_f69d3_row89_col3, #T_f69d3_row89_col4, #T_f69d3_row90_col0, #T_f69d3_row90_col1, #T_f69d3_row90_col2, #T_f69d3_row90_col3, #T_f69d3_row90_col4, #T_f69d3_row91_col0, #T_f69d3_row91_col1, #T_f69d3_row91_col2, #T_f69d3_row91_col3, #T_f69d3_row91_col4, #T_f69d3_row92_col0, #T_f69d3_row92_col1, #T_f69d3_row92_col2, #T_f69d3_row92_col3, #T_f69d3_row92_col4, #T_f69d3_row93_col0, #T_f69d3_row93_col1, #T_f69d3_row93_col2, #T_f69d3_row93_col3, #T_f69d3_row93_col4, #T_f69d3_row94_col0, #T_f69d3_row94_col1, #T_f69d3_row94_col2, #T_f69d3_row94_col3, #T_f69d3_row94_col4, #T_f69d3_row95_col0, #T_f69d3_row95_col1, #T_f69d3_row95_col2, #T_f69d3_row95_col3, #T_f69d3_row95_col4, #T_f69d3_row96_col0, #T_f69d3_row96_col1, #T_f69d3_row96_col2, #T_f69d3_row96_col3, #T_f69d3_row96_col4, #T_f69d3_row97_col0, #T_f69d3_row97_col1, #T_f69d3_row97_col2, #T_f69d3_row97_col3, #T_f69d3_row97_col4, #T_f69d3_row98_col0, #T_f69d3_row98_col1, #T_f69d3_row98_col2, #T_f69d3_row98_col3, #T_f69d3_row98_col4, #T_f69d3_row99_col0, #T_f69d3_row99_col1, #T_f69d3_row99_col2, #T_f69d3_row99_col3, #T_f69d3_row99_col4, #T_f69d3_row100_col0, #T_f69d3_row100_col1, #T_f69d3_row100_col2, #T_f69d3_row100_col3, #T_f69d3_row100_col4, #T_f69d3_row101_col0, #T_f69d3_row101_col1, #T_f69d3_row101_col2, #T_f69d3_row101_col3, #T_f69d3_row101_col4, #T_f69d3_row102_col0, #T_f69d3_row102_col1, #T_f69d3_row102_col2, #T_f69d3_row102_col3, #T_f69d3_row102_col4, #T_f69d3_row103_col0, #T_f69d3_row103_col1, #T_f69d3_row103_col2, #T_f69d3_row103_col3, #T_f69d3_row103_col4, #T_f69d3_row104_col0, #T_f69d3_row104_col1, #T_f69d3_row104_col2, #T_f69d3_row104_col3, #T_f69d3_row104_col4, #T_f69d3_row105_col0, #T_f69d3_row105_col1, #T_f69d3_row105_col2, #T_f69d3_row105_col3, #T_f69d3_row105_col4, #T_f69d3_row106_col0, #T_f69d3_row106_col1, #T_f69d3_row106_col2, #T_f69d3_row106_col3, #T_f69d3_row106_col4, #T_f69d3_row107_col0, #T_f69d3_row107_col1, #T_f69d3_row107_col2, #T_f69d3_row107_col3, #T_f69d3_row107_col4, #T_f69d3_row108_col0, #T_f69d3_row108_col1, #T_f69d3_row108_col2, #T_f69d3_row108_col3, #T_f69d3_row108_col4, #T_f69d3_row109_col0, #T_f69d3_row109_col1, #T_f69d3_row109_col2, #T_f69d3_row109_col3, #T_f69d3_row109_col4, #T_f69d3_row110_col0, #T_f69d3_row110_col1, #T_f69d3_row110_col2, #T_f69d3_row110_col3, #T_f69d3_row110_col4, #T_f69d3_row111_col0, #T_f69d3_row111_col1, #T_f69d3_row111_col2, #T_f69d3_row111_col3, #T_f69d3_row111_col4, #T_f69d3_row112_col0, #T_f69d3_row112_col1, #T_f69d3_row112_col2, #T_f69d3_row112_col3, #T_f69d3_row112_col4, #T_f69d3_row113_col0, #T_f69d3_row113_col1, #T_f69d3_row113_col2, #T_f69d3_row113_col3, #T_f69d3_row113_col4, #T_f69d3_row114_col0, #T_f69d3_row114_col1, #T_f69d3_row114_col2, #T_f69d3_row114_col3, #T_f69d3_row114_col4, #T_f69d3_row115_col0, #T_f69d3_row115_col1, #T_f69d3_row115_col2, #T_f69d3_row115_col3, #T_f69d3_row115_col4, #T_f69d3_row116_col0, #T_f69d3_row116_col1, #T_f69d3_row116_col2, #T_f69d3_row116_col3, #T_f69d3_row116_col4, #T_f69d3_row117_col0, #T_f69d3_row117_col1, #T_f69d3_row117_col2, #T_f69d3_row117_col3, #T_f69d3_row117_col4, #T_f69d3_row118_col0, #T_f69d3_row118_col1, #T_f69d3_row118_col2, #T_f69d3_row118_col3, #T_f69d3_row118_col4, #T_f69d3_row119_col0, #T_f69d3_row119_col1, #T_f69d3_row119_col2, #T_f69d3_row119_col3, #T_f69d3_row119_col4, #T_f69d3_row120_col0, #T_f69d3_row120_col1, #T_f69d3_row120_col2, #T_f69d3_row120_col3, #T_f69d3_row120_col4, #T_f69d3_row121_col0, #T_f69d3_row121_col1, #T_f69d3_row121_col2, #T_f69d3_row121_col3, #T_f69d3_row121_col4, #T_f69d3_row122_col0, #T_f69d3_row122_col1, #T_f69d3_row122_col2, #T_f69d3_row122_col3, #T_f69d3_row122_col4, #T_f69d3_row123_col0, #T_f69d3_row123_col1, #T_f69d3_row123_col2, #T_f69d3_row123_col3, #T_f69d3_row123_col4, #T_f69d3_row124_col0, #T_f69d3_row124_col1, #T_f69d3_row124_col2, #T_f69d3_row124_col3, #T_f69d3_row124_col4, #T_f69d3_row125_col0, #T_f69d3_row125_col1, #T_f69d3_row125_col2, #T_f69d3_row125_col3, #T_f69d3_row125_col4, #T_f69d3_row126_col0, #T_f69d3_row126_col1, #T_f69d3_row126_col2, #T_f69d3_row126_col3, #T_f69d3_row126_col4, #T_f69d3_row127_col0, #T_f69d3_row127_col1, #T_f69d3_row127_col2, #T_f69d3_row127_col3, #T_f69d3_row127_col4, #T_f69d3_row128_col0, #T_f69d3_row128_col1, #T_f69d3_row128_col2, #T_f69d3_row128_col3, #T_f69d3_row128_col4, #T_f69d3_row129_col0, #T_f69d3_row129_col1, #T_f69d3_row129_col2, #T_f69d3_row129_col3, #T_f69d3_row129_col4, #T_f69d3_row130_col0, #T_f69d3_row130_col1, #T_f69d3_row130_col2, #T_f69d3_row130_col3, #T_f69d3_row130_col4, #T_f69d3_row131_col0, #T_f69d3_row131_col1, #T_f69d3_row131_col2, #T_f69d3_row131_col3, #T_f69d3_row131_col4, #T_f69d3_row132_col0, #T_f69d3_row132_col1, #T_f69d3_row132_col2, #T_f69d3_row132_col3, #T_f69d3_row132_col4, #T_f69d3_row133_col0, #T_f69d3_row133_col1, #T_f69d3_row133_col2, #T_f69d3_row133_col3, #T_f69d3_row133_col4, #T_f69d3_row134_col0, #T_f69d3_row134_col1, #T_f69d3_row134_col2, #T_f69d3_row134_col3, #T_f69d3_row134_col4, #T_f69d3_row135_col0, #T_f69d3_row135_col1, #T_f69d3_row135_col2, #T_f69d3_row135_col3, #T_f69d3_row135_col4, #T_f69d3_row136_col0, #T_f69d3_row136_col1, #T_f69d3_row136_col2, #T_f69d3_row136_col3, #T_f69d3_row136_col4, #T_f69d3_row137_col0, #T_f69d3_row137_col1, #T_f69d3_row137_col2, #T_f69d3_row137_col3, #T_f69d3_row137_col4, #T_f69d3_row138_col0, #T_f69d3_row138_col1, #T_f69d3_row138_col2, #T_f69d3_row138_col3, #T_f69d3_row138_col4, #T_f69d3_row139_col0, #T_f69d3_row139_col1, #T_f69d3_row139_col2, #T_f69d3_row139_col3, #T_f69d3_row139_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f69d3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f69d3_level0_col0\" class=\"col_heading level0 col0\" >utterance</th>\n",
       "      <th id=\"T_f69d3_level0_col1\" class=\"col_heading level0 col1\" >example_utterance_type</th>\n",
       "      <th id=\"T_f69d3_level0_col2\" class=\"col_heading level0 col2\" >rationale</th>\n",
       "      <th id=\"T_f69d3_level0_col3\" class=\"col_heading level0 col3\" >pred_utterance_type</th>\n",
       "      <th id=\"T_f69d3_level0_col4\" class=\"col_heading level0 col4\" >validate_exact_utterance_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f69d3_row0_col0\" class=\"data row0 col0\" >I’m out, but thanks for the opportunity.</td>\n",
       "      <td id=\"T_f69d3_row0_col1\" class=\"data row0 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row0_col2\" class=\"data row0 col2\" >produce the utterance type. We see that the user is expressing gratitude for an opportunity but also indicating that they are leaving. This does not...</td>\n",
       "      <td id=\"T_f69d3_row0_col3\" class=\"data row0 col3\" >out_of_scope</td>\n",
       "      <td id=\"T_f69d3_row0_col4\" class=\"data row0 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f69d3_row1_col0\" class=\"data row1 col0\" >Absolutely! I thrive in team environments and am committed to following all policies and procedures.</td>\n",
       "      <td id=\"T_f69d3_row1_col1\" class=\"data row1 col1\" >qa_4</td>\n",
       "      <td id=\"T_f69d3_row1_col2\" class=\"data row1 col2\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row1_col3\" class=\"data row1 col3\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row1_col4\" class=\"data row1 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f69d3_row2_col0\" class=\"data row2 col0\" >Handling tough situations involves staying positive, being patient, and finding effective solutions.</td>\n",
       "      <td id=\"T_f69d3_row2_col1\" class=\"data row2 col1\" >qa_3</td>\n",
       "      <td id=\"T_f69d3_row2_col2\" class=\"data row2 col2\" >produce the utterance_type. We see that the user is discussing strategies for handling tough situations, which is not related to the conversation at hand.</td>\n",
       "      <td id=\"T_f69d3_row2_col3\" class=\"data row2 col3\" >out_of_scope</td>\n",
       "      <td id=\"T_f69d3_row2_col4\" class=\"data row2 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f69d3_row3_col0\" class=\"data row3 col0\" >Any news on my job application?</td>\n",
       "      <td id=\"T_f69d3_row3_col1\" class=\"data row3 col1\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row3_col2\" class=\"data row3 col2\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row3_col3\" class=\"data row3 col3\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row3_col4\" class=\"data row3 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f69d3_row4_col0\" class=\"data row4 col0\" >Unfortunately, I have to say no.</td>\n",
       "      <td id=\"T_f69d3_row4_col1\" class=\"data row4 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row4_col2\" class=\"data row4 col2\" >produce the utterance type. We see that the user is declining or refusing something.</td>\n",
       "      <td id=\"T_f69d3_row4_col3\" class=\"data row4 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row4_col4\" class=\"data row4 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_f69d3_row5_col0\" class=\"data row5 col0\" >Yes, I worked as a customer service representative at a retail company, assisting customers with their orders and returns.</td>\n",
       "      <td id=\"T_f69d3_row5_col1\" class=\"data row5 col1\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row5_col2\" class=\"data row5 col2\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row5_col3\" class=\"data row5 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row5_col4\" class=\"data row5 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_f69d3_row6_col0\" class=\"data row6 col0\" >I keep a stash of my favorite snacks for a quick energy boost. 🍫</td>\n",
       "      <td id=\"T_f69d3_row6_col1\" class=\"data row6 col1\" >qa_2</td>\n",
       "      <td id=\"T_f69d3_row6_col2\" class=\"data row6 col2\" >identify the utterance type. We see that the user is sharing personal information about keeping a stash of favorite snacks for a quick energy boost....</td>\n",
       "      <td id=\"T_f69d3_row6_col3\" class=\"data row6 col3\" >out_of_scope</td>\n",
       "      <td id=\"T_f69d3_row6_col4\" class=\"data row6 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_f69d3_row7_col0\" class=\"data row7 col0\" >Hey! I'm juggling multiple tasks at the moment. Can we continue this at a more convenient time?</td>\n",
       "      <td id=\"T_f69d3_row7_col1\" class=\"data row7 col1\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row7_col2\" class=\"data row7 col2\" >determine the utterance type. The user starts with a greeting \"Hey!\" and then mentions that they are busy with multiple tasks and would like to...</td>\n",
       "      <td id=\"T_f69d3_row7_col3\" class=\"data row7 col3\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row7_col4\" class=\"data row7 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_f69d3_row8_col0\" class=\"data row8 col0\" >Totally! My last job was in a call center, where I assisted customers with their service-related concerns.</td>\n",
       "      <td id=\"T_f69d3_row8_col1\" class=\"data row8 col1\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row8_col2\" class=\"data row8 col2\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row8_col3\" class=\"data row8 col3\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row8_col4\" class=\"data row8 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_f69d3_row9_col0\" class=\"data row9 col0\" >Sorry, but I’m not interested in this.</td>\n",
       "      <td id=\"T_f69d3_row9_col1\" class=\"data row9 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row9_col2\" class=\"data row9 col2\" >produce the utterance type. We see that the user is expressing disinterest in the current topic. They are politely declining further engagement.</td>\n",
       "      <td id=\"T_f69d3_row9_col3\" class=\"data row9 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row9_col4\" class=\"data row9 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_f69d3_row10_col0\" class=\"data row10 col0\" >Hey there! Could you tell me more about the company's history?</td>\n",
       "      <td id=\"T_f69d3_row10_col1\" class=\"data row10 col1\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row10_col2\" class=\"data row10 col2\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row10_col3\" class=\"data row10 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row10_col4\" class=\"data row10 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_f69d3_row11_col0\" class=\"data row11 col0\" >I'm on board with that. Let's proceed.</td>\n",
       "      <td id=\"T_f69d3_row11_col1\" class=\"data row11 col1\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row11_col2\" class=\"data row11 col2\" >continue the conversation. The user is expressing agreement and readiness to move forward.</td>\n",
       "      <td id=\"T_f69d3_row11_col3\" class=\"data row11 col3\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row11_col4\" class=\"data row11 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_f69d3_row12_col0\" class=\"data row12 col0\" >Not agreeing with this, sorry.</td>\n",
       "      <td id=\"T_f69d3_row12_col1\" class=\"data row12 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row12_col2\" class=\"data row12 col2\" >produce the utterance_type. We see that the user is expressing disagreement with a previous statement.</td>\n",
       "      <td id=\"T_f69d3_row12_col3\" class=\"data row12 col3\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row12_col4\" class=\"data row12 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_f69d3_row13_col0\" class=\"data row13 col0\" >Oki</td>\n",
       "      <td id=\"T_f69d3_row13_col1\" class=\"data row13 col1\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row13_col2\" class=\"data row13 col2\" >produce the utterance_type. We see that \"Oki\" is a casual and informal way of saying \"okay\", which is often used as a response to indicate...</td>\n",
       "      <td id=\"T_f69d3_row13_col3\" class=\"data row13 col3\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row13_col4\" class=\"data row13 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_f69d3_row14_col0\" class=\"data row14 col0\" >I’m not on board with this.</td>\n",
       "      <td id=\"T_f69d3_row14_col1\" class=\"data row14 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row14_col2\" class=\"data row14 col2\" >produce the utterance type. We see that the user is expressing disagreement or disapproval with something.</td>\n",
       "      <td id=\"T_f69d3_row14_col3\" class=\"data row14 col3\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row14_col4\" class=\"data row14 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_f69d3_row15_col0\" class=\"data row15 col0\" >Hey! Any news? 📰</td>\n",
       "      <td id=\"T_f69d3_row15_col1\" class=\"data row15 col1\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row15_col2\" class=\"data row15 col2\" >produce the utterance_type. We see the user starting with a greeting \"Hey!\" and then asking about any news, indicating a desire for updates or information....</td>\n",
       "      <td id=\"T_f69d3_row15_col3\" class=\"data row15 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row15_col4\" class=\"data row15 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_f69d3_row16_col0\" class=\"data row16 col0\" >Staying organized and having a plan helps me stay on track.</td>\n",
       "      <td id=\"T_f69d3_row16_col1\" class=\"data row16 col1\" >qa_2</td>\n",
       "      <td id=\"T_f69d3_row16_col2\" class=\"data row16 col2\" >produce the utterance_type. We see that the user is talking about their personal strategy for staying on track, which is not directly related to the...</td>\n",
       "      <td id=\"T_f69d3_row16_col3\" class=\"data row16 col3\" >out_of_scope</td>\n",
       "      <td id=\"T_f69d3_row16_col4\" class=\"data row16 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_f69d3_row17_col0\" class=\"data row17 col0\" >Hi! Can you provide some insights into the company culture?</td>\n",
       "      <td id=\"T_f69d3_row17_col1\" class=\"data row17 col1\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row17_col2\" class=\"data row17 col2\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row17_col3\" class=\"data row17 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row17_col4\" class=\"data row17 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_f69d3_row18_col0\" class=\"data row18 col0\" >Do you offer any training programs for new hires?</td>\n",
       "      <td id=\"T_f69d3_row18_col1\" class=\"data row18 col1\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row18_col2\" class=\"data row18 col2\" >answer a specific question related to the services offered by the company. The user is inquiring about training programs for new hires, which indicates they...</td>\n",
       "      <td id=\"T_f69d3_row18_col3\" class=\"data row18 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row18_col4\" class=\"data row18 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_f69d3_row19_col0\" class=\"data row19 col0\" >I'm with you on that. What's next?</td>\n",
       "      <td id=\"T_f69d3_row19_col1\" class=\"data row19 col1\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row19_col2\" class=\"data row19 col2\" >produce the utterance type. We see that the user is expressing agreement and asking for the next step in the conversation. This indicates a continuation...</td>\n",
       "      <td id=\"T_f69d3_row19_col3\" class=\"data row19 col3\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row19_col4\" class=\"data row19 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_f69d3_row20_col0\" class=\"data row20 col0\" >How's my application doing? 🤔</td>\n",
       "      <td id=\"T_f69d3_row20_col1\" class=\"data row20 col1\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row20_col2\" class=\"data row20 col2\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row20_col3\" class=\"data row20 col3\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row20_col4\" class=\"data row20 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_f69d3_row21_col0\" class=\"data row21 col0\" >Hi! How's your day going? 😊</td>\n",
       "      <td id=\"T_f69d3_row21_col1\" class=\"data row21 col1\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row21_col2\" class=\"data row21 col2\" >produce the utterance_type. We see that the user is starting the conversation with a greeting and asking about the other person's day.</td>\n",
       "      <td id=\"T_f69d3_row21_col3\" class=\"data row21 col3\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row21_col4\" class=\"data row21 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_f69d3_row22_col0\" class=\"data row22 col0\" >This isn't the right fit for me, so no.</td>\n",
       "      <td id=\"T_f69d3_row22_col1\" class=\"data row22 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row22_col2\" class=\"data row22 col2\" >produce the utterance_type. We see that the user is expressing a negative sentiment towards the topic at hand and clearly stating their decision not to...</td>\n",
       "      <td id=\"T_f69d3_row22_col3\" class=\"data row22 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row22_col4\" class=\"data row22 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_f69d3_row23_col0\" class=\"data row23 col0\" >Hey there! I spent 2 years at a call center, where I honed my skills in customer service and communication.</td>\n",
       "      <td id=\"T_f69d3_row23_col1\" class=\"data row23 col1\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row23_col2\" class=\"data row23 col2\" >'company_related'. We see that the user is introducing themselves and mentioning their experience at a call center, which is related to their skills and work...</td>\n",
       "      <td id=\"T_f69d3_row23_col3\" class=\"data row23 col3\" >'company_related'</td>\n",
       "      <td id=\"T_f69d3_row23_col4\" class=\"data row23 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_f69d3_row24_col0\" class=\"data row24 col0\" >Hey, what's the work environment like at the company?</td>\n",
       "      <td id=\"T_f69d3_row24_col1\" class=\"data row24 col1\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row24_col2\" class=\"data row24 col2\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row24_col3\" class=\"data row24 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row24_col4\" class=\"data row24 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_f69d3_row25_col0\" class=\"data row25 col0\" >Hello! How are you today? 😄</td>\n",
       "      <td id=\"T_f69d3_row25_col1\" class=\"data row25 col1\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row25_col2\" class=\"data row25 col2\" >produce the utterance_type. We see that the user is starting the conversation with a greeting and asking about the other person's well-being.</td>\n",
       "      <td id=\"T_f69d3_row25_col3\" class=\"data row25 col3\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row25_col4\" class=\"data row25 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_f69d3_row26_col0\" class=\"data row26 col0\" >Can I get an update on my interview?</td>\n",
       "      <td id=\"T_f69d3_row26_col1\" class=\"data row26 col1\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row26_col2\" class=\"data row26 col2\" >'qa_1'. We see that the user is asking for an update on their interview, which falls under the category of a specific question related to...</td>\n",
       "      <td id=\"T_f69d3_row26_col3\" class=\"data row26 col3\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row26_col4\" class=\"data row26 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_f69d3_row27_col0\" class=\"data row27 col0\" >Hi, how's your day going?</td>\n",
       "      <td id=\"T_f69d3_row27_col1\" class=\"data row27 col1\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row27_col2\" class=\"data row27 col2\" >produce the utterance_type. We see that the user is initiating a conversation by asking about the other person's day. This indicates a greeting and an...</td>\n",
       "      <td id=\"T_f69d3_row27_col3\" class=\"data row27 col3\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row27_col4\" class=\"data row27 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_f69d3_row28_col0\" class=\"data row28 col0\" >Hey, what benefits does the company offer to its employees?</td>\n",
       "      <td id=\"T_f69d3_row28_col1\" class=\"data row28 col1\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row28_col2\" class=\"data row28 col2\" >produce the utterance_type. We see that the user is asking about benefits offered by the company, indicating a question related to the company.</td>\n",
       "      <td id=\"T_f69d3_row28_col3\" class=\"data row28 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row28_col4\" class=\"data row28 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_f69d3_row29_col0\" class=\"data row29 col0\" >I'm stepping away for a bit, be back soon!</td>\n",
       "      <td id=\"T_f69d3_row29_col1\" class=\"data row29 col1\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row29_col2\" class=\"data row29 col2\" >not_continue_related. We can see that the user is informing that they will be away for a bit and will be back soon, indicating that the...</td>\n",
       "      <td id=\"T_f69d3_row29_col3\" class=\"data row29 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row29_col4\" class=\"data row29 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_f69d3_row30_col0\" class=\"data row30 col0\" >Honestly, a cup of strong coffee and some good vibes do the trick! ☕️✨</td>\n",
       "      <td id=\"T_f69d3_row30_col1\" class=\"data row30 col1\" >qa_2</td>\n",
       "      <td id=\"T_f69d3_row30_col2\" class=\"data row30 col2\" >produce the utterance_type. We see that the user is expressing their personal preference for how they like to feel energized, mentioning coffee and good vibes....</td>\n",
       "      <td id=\"T_f69d3_row30_col3\" class=\"data row30 col3\" >out_of_scope</td>\n",
       "      <td id=\"T_f69d3_row30_col4\" class=\"data row30 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_f69d3_row31_col0\" class=\"data row31 col0\" >This doesn’t work for me, so I’m saying no.</td>\n",
       "      <td id=\"T_f69d3_row31_col1\" class=\"data row31 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row31_col2\" class=\"data row31 col2\" >produce the utterance_type. We see that the user is expressing dissatisfaction with something not working for them and explicitly stating their decision to say no....</td>\n",
       "      <td id=\"T_f69d3_row31_col3\" class=\"data row31 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row31_col4\" class=\"data row31 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_f69d3_row32_col0\" class=\"data row32 col0\" >Hey there! 😊 How's it going?</td>\n",
       "      <td id=\"T_f69d3_row32_col1\" class=\"data row32 col1\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row32_col2\" class=\"data row32 col2\" >produce the utterance_type. We see that the user is starting the conversation with a friendly greeting and asking about the other person's well-being. This indicates...</td>\n",
       "      <td id=\"T_f69d3_row32_col3\" class=\"data row32 col3\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row32_col4\" class=\"data row32 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_f69d3_row33_col0\" class=\"data row33 col0\" >That's a great idea! Let's run with it.</td>\n",
       "      <td id=\"T_f69d3_row33_col1\" class=\"data row33 col1\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row33_col2\" class=\"data row33 col2\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row33_col3\" class=\"data row33 col3\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row33_col4\" class=\"data row33 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_f69d3_row34_col0\" class=\"data row34 col0\" >Definitely! I worked in a call center where I handled escalated calls and provided solutions to complex problems.</td>\n",
       "      <td id=\"T_f69d3_row34_col1\" class=\"data row34 col1\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row34_col2\" class=\"data row34 col2\" >produce the utterance_type. We see that the user is sharing their past work experience in a call center, specifically mentioning handling escalated calls and providing...</td>\n",
       "      <td id=\"T_f69d3_row34_col3\" class=\"data row34 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row34_col4\" class=\"data row34 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_f69d3_row35_col0\" class=\"data row35 col0\" >I'm interested in the customer service role, can you send me more info?</td>\n",
       "      <td id=\"T_f69d3_row35_col1\" class=\"data row35 col1\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row35_col2\" class=\"data row35 col2\" >'qa_1'. We see that the user is asking for more information about a specific role, which falls under the category of a question related to...</td>\n",
       "      <td id=\"T_f69d3_row35_col3\" class=\"data row35 col3\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row35_col4\" class=\"data row35 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_f69d3_row36_col0\" class=\"data row36 col0\" >Hey! What's the latest? 📢</td>\n",
       "      <td id=\"T_f69d3_row36_col1\" class=\"data row36 col1\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row36_col2\" class=\"data row36 col2\" >produce the utterance_type. We see that the user is initiating a conversation with a friendly greeting and asking for an update. This indicates a 'greetings'...</td>\n",
       "      <td id=\"T_f69d3_row36_col3\" class=\"data row36 col3\" >greetings, company_related</td>\n",
       "      <td id=\"T_f69d3_row36_col4\" class=\"data row36 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "      <td id=\"T_f69d3_row37_col0\" class=\"data row37 col0\" >Good evening! 🌙 How was your day?</td>\n",
       "      <td id=\"T_f69d3_row37_col1\" class=\"data row37 col1\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row37_col2\" class=\"data row37 col2\" >produce the utterance type. We see that the user starts with a greeting \"Good evening!\" followed by a question about the other person's day. This...</td>\n",
       "      <td id=\"T_f69d3_row37_col3\" class=\"data row37 col3\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row37_col4\" class=\"data row37 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "      <td id=\"T_f69d3_row38_col0\" class=\"data row38 col0\" >I'm not able to chat right now, will talk to you soon!</td>\n",
       "      <td id=\"T_f69d3_row38_col1\" class=\"data row38 col1\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row38_col2\" class=\"data row38 col2\" >produce the utterance_type. We see that the user is indicating that they are unable to chat at the moment but will talk later. This suggests...</td>\n",
       "      <td id=\"T_f69d3_row38_col3\" class=\"data row38 col3\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row38_col4\" class=\"data row38 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "      <td id=\"T_f69d3_row39_col0\" class=\"data row39 col0\" >I remind myself that each call is a chance to learn something new.</td>\n",
       "      <td id=\"T_f69d3_row39_col1\" class=\"data row39 col1\" >qa_2</td>\n",
       "      <td id=\"T_f69d3_row39_col2\" class=\"data row39 col2\" >produce the utterance_type. We see that the user is reflecting on their mindset towards phone calls and emphasizing the opportunity for learning. This does not...</td>\n",
       "      <td id=\"T_f69d3_row39_col3\" class=\"data row39 col3\" >out_of_scope</td>\n",
       "      <td id=\"T_f69d3_row39_col4\" class=\"data row39 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "      <td id=\"T_f69d3_row40_col0\" class=\"data row40 col0\" >That's correct! 👍</td>\n",
       "      <td id=\"T_f69d3_row40_col1\" class=\"data row40 col1\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row40_col2\" class=\"data row40 col2\" >produce the utterance_type. We see that the user is affirming something positively with an emoji. This indicates agreement or approval.</td>\n",
       "      <td id=\"T_f69d3_row40_col3\" class=\"data row40 col3\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row40_col4\" class=\"data row40 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "      <td id=\"T_f69d3_row41_col0\" class=\"data row41 col0\" >Hi! Can you tell me about the company's financial performance?</td>\n",
       "      <td id=\"T_f69d3_row41_col1\" class=\"data row41 col1\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row41_col2\" class=\"data row41 col2\" >produce the utterance_type. We see that the user starts with a greeting \"Hi!\" which indicates a polite opening. Then, the user asks about the company's...</td>\n",
       "      <td id=\"T_f69d3_row41_col3\" class=\"data row41 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row41_col4\" class=\"data row41 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "      <td id=\"T_f69d3_row42_col0\" class=\"data row42 col0\" >You bet! Teamwork is key, and I'm committed to following established policies and procedures.</td>\n",
       "      <td id=\"T_f69d3_row42_col1\" class=\"data row42 col1\" >qa_4</td>\n",
       "      <td id=\"T_f69d3_row42_col2\" class=\"data row42 col2\" >produce the utterance_type. We see that the user is expressing their commitment to teamwork and following established policies and procedures. This indicates a positive attitude...</td>\n",
       "      <td id=\"T_f69d3_row42_col3\" class=\"data row42 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row42_col4\" class=\"data row42 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "      <td id=\"T_f69d3_row43_col0\" class=\"data row43 col0\" >Hi, it's nice to meet you.</td>\n",
       "      <td id=\"T_f69d3_row43_col1\" class=\"data row43 col1\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row43_col2\" class=\"data row43 col2\" >produce the utterance_type. We see that the user is initiating a conversation and expressing a positive sentiment towards meeting the other person.</td>\n",
       "      <td id=\"T_f69d3_row43_col3\" class=\"data row43 col3\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row43_col4\" class=\"data row43 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "      <td id=\"T_f69d3_row44_col0\" class=\"data row44 col0\" >Am I still in the running for this position?</td>\n",
       "      <td id=\"T_f69d3_row44_col1\" class=\"data row44 col1\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row44_col2\" class=\"data row44 col2\" >determine if the user is asking about their application status for a job position. The user is inquiring about their current status in the hiring...</td>\n",
       "      <td id=\"T_f69d3_row44_col3\" class=\"data row44 col3\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row44_col4\" class=\"data row44 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "      <td id=\"T_f69d3_row45_col0\" class=\"data row45 col0\" >Sorry, but I don’t agree with this approach.</td>\n",
       "      <td id=\"T_f69d3_row45_col1\" class=\"data row45 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row45_col2\" class=\"data row45 col2\" >produce the utterance_type. We see that the user is expressing disagreement with a certain approach.</td>\n",
       "      <td id=\"T_f69d3_row45_col3\" class=\"data row45 col3\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row45_col4\" class=\"data row45 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "      <td id=\"T_f69d3_row46_col0\" class=\"data row46 col0\" >What are the working hours for the inbound sales team?</td>\n",
       "      <td id=\"T_f69d3_row46_col1\" class=\"data row46 col1\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row46_col2\" class=\"data row46 col2\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row46_col3\" class=\"data row46 col3\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row46_col4\" class=\"data row46 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "      <td id=\"T_f69d3_row47_col0\" class=\"data row47 col0\" >My experience includes working in a call center where I provided assistance with billing, technical issues, and general inquiries.</td>\n",
       "      <td id=\"T_f69d3_row47_col1\" class=\"data row47 col1\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row47_col2\" class=\"data row47 col2\" >identify the type of information being shared. The user is describing their work experience in a call center, mentioning the tasks they were responsible for....</td>\n",
       "      <td id=\"T_f69d3_row47_col3\" class=\"data row47 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row47_col4\" class=\"data row47 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "      <td id=\"T_f69d3_row48_col0\" class=\"data row48 col0\" >What sets this company apart from other call centers?</td>\n",
       "      <td id=\"T_f69d3_row48_col1\" class=\"data row48 col1\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row48_col2\" class=\"data row48 col2\" >company_related. We can identify this as a question about the unique qualities of the company compared to others in the same industry.</td>\n",
       "      <td id=\"T_f69d3_row48_col3\" class=\"data row48 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row48_col4\" class=\"data row48 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "      <td id=\"T_f69d3_row49_col0\" class=\"data row49 col0\" >I apologize for any inconvenience caused and work diligently to fix the issue.</td>\n",
       "      <td id=\"T_f69d3_row49_col1\" class=\"data row49 col1\" >qa_3</td>\n",
       "      <td id=\"T_f69d3_row49_col2\" class=\"data row49 col2\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row49_col3\" class=\"data row49 col3\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row49_col4\" class=\"data row49 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "      <td id=\"T_f69d3_row50_col0\" class=\"data row50 col0\" >Yes, I'm quite comfortable working in a team and following all the necessary procedures.</td>\n",
       "      <td id=\"T_f69d3_row50_col1\" class=\"data row50 col1\" >qa_4</td>\n",
       "      <td id=\"T_f69d3_row50_col2\" class=\"data row50 col2\" >produce the utterance_type. We see that the user is expressing their comfort level with working in a team and following procedures. This indicates a response...</td>\n",
       "      <td id=\"T_f69d3_row50_col3\" class=\"data row50 col3\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row50_col4\" class=\"data row50 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "      <td id=\"T_f69d3_row51_col0\" class=\"data row51 col0\" >Hello! What's up?</td>\n",
       "      <td id=\"T_f69d3_row51_col1\" class=\"data row51 col1\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row51_col2\" class=\"data row51 col2\" >produce the utterance_type. We see that the user is initiating a conversation by greeting and asking a question about the other person's well-being.</td>\n",
       "      <td id=\"T_f69d3_row51_col3\" class=\"data row51 col3\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row51_col4\" class=\"data row51 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "      <td id=\"T_f69d3_row52_col0\" class=\"data row52 col0\" >Got it! Next steps are...</td>\n",
       "      <td id=\"T_f69d3_row52_col1\" class=\"data row52 col1\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row52_col2\" class=\"data row52 col2\" >continue_related. We can see that the user is mentioning \"next steps,\" indicating a continuation of the conversation.</td>\n",
       "      <td id=\"T_f69d3_row52_col3\" class=\"data row52 col3\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row52_col4\" class=\"data row52 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "      <td id=\"T_f69d3_row53_col0\" class=\"data row53 col0\" >Affirmative, let's go ahead.</td>\n",
       "      <td id=\"T_f69d3_row53_col1\" class=\"data row53 col1\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row53_col2\" class=\"data row53 col2\" >produce the utterance type. We see that the user is agreeing to proceed with something, indicating a positive response.</td>\n",
       "      <td id=\"T_f69d3_row53_col3\" class=\"data row53 col3\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row53_col4\" class=\"data row53 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "      <td id=\"T_f69d3_row54_col0\" class=\"data row54 col0\" >Is there any update on my application status?</td>\n",
       "      <td id=\"T_f69d3_row54_col1\" class=\"data row54 col1\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row54_col2\" class=\"data row54 col2\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row54_col3\" class=\"data row54 col3\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row54_col4\" class=\"data row54 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "      <td id=\"T_f69d3_row55_col0\" class=\"data row55 col0\" >In my previous job, I was responsible for managing customer inquiries and complaints in a busy call center.</td>\n",
       "      <td id=\"T_f69d3_row55_col1\" class=\"data row55 col1\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row55_col2\" class=\"data row55 col2\" >identify the type of utterance. The user is providing information about their previous job responsibilities. This does not relate to continuing the conversation or asking...</td>\n",
       "      <td id=\"T_f69d3_row55_col3\" class=\"data row55 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row55_col4\" class=\"data row55 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
       "      <td id=\"T_f69d3_row56_col0\" class=\"data row56 col0\" >Hello! How are things? 🌟</td>\n",
       "      <td id=\"T_f69d3_row56_col1\" class=\"data row56 col1\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row56_col2\" class=\"data row56 col2\" >produce the utterance type. We see that the user is starting the conversation with a greeting \"Hello!\" and asking about the other person's well-being \"How...</td>\n",
       "      <td id=\"T_f69d3_row56_col3\" class=\"data row56 col3\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row56_col4\" class=\"data row56 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row57\" class=\"row_heading level0 row57\" >57</th>\n",
       "      <td id=\"T_f69d3_row57_col0\" class=\"data row57 col0\" >I'm disconnecting for now, talk to you soon!</td>\n",
       "      <td id=\"T_f69d3_row57_col1\" class=\"data row57 col1\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row57_col2\" class=\"data row57 col2\" >produce the utterance_type. We see that the user is indicating that they are disconnecting for now but will talk to the other person soon. This...</td>\n",
       "      <td id=\"T_f69d3_row57_col3\" class=\"data row57 col3\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row57_col4\" class=\"data row57 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row58\" class=\"row_heading level0 row58\" >58</th>\n",
       "      <td id=\"T_f69d3_row58_col0\" class=\"data row58 col0\" >How does the company approach work-life balance?</td>\n",
       "      <td id=\"T_f69d3_row58_col1\" class=\"data row58 col1\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row58_col2\" class=\"data row58 col2\" >produce the utterance_type. We see that the user is asking about the company's approach to work-life balance, which is related to the company's policies and...</td>\n",
       "      <td id=\"T_f69d3_row58_col3\" class=\"data row58 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row58_col4\" class=\"data row58 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row59\" class=\"row_heading level0 row59\" >59</th>\n",
       "      <td id=\"T_f69d3_row59_col0\" class=\"data row59 col0\" >I'm on the same page. Please proceed.</td>\n",
       "      <td id=\"T_f69d3_row59_col1\" class=\"data row59 col1\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row59_col2\" class=\"data row59 col2\" >produce the utterance_type. We see that the user is indicating agreement and giving permission to continue the conversation.</td>\n",
       "      <td id=\"T_f69d3_row59_col3\" class=\"data row59 col3\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row59_col4\" class=\"data row59 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row60\" class=\"row_heading level0 row60\" >60</th>\n",
       "      <td id=\"T_f69d3_row60_col0\" class=\"data row60 col0\" >I’m going to decline, but I appreciate the offer.</td>\n",
       "      <td id=\"T_f69d3_row60_col1\" class=\"data row60 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row60_col2\" class=\"data row60 col2\" >produce the utterance type. We see that the user is politely declining an offer but also expressing gratitude. This indicates that the utterance is related...</td>\n",
       "      <td id=\"T_f69d3_row60_col3\" class=\"data row60 col3\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row60_col4\" class=\"data row60 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row61\" class=\"row_heading level0 row61\" >61</th>\n",
       "      <td id=\"T_f69d3_row61_col0\" class=\"data row61 col0\" >Hey, what's cracking? 😄</td>\n",
       "      <td id=\"T_f69d3_row61_col1\" class=\"data row61 col1\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row61_col2\" class=\"data row61 col2\" >produce the utterance_type. We see that the user is initiating a conversation in a friendly and casual manner, asking a general question. This indicates a...</td>\n",
       "      <td id=\"T_f69d3_row61_col3\" class=\"data row61 col3\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row61_col4\" class=\"data row61 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row62\" class=\"row_heading level0 row62\" >62</th>\n",
       "      <td id=\"T_f69d3_row62_col0\" class=\"data row62 col0\" >What is the average salary for a customer service rep?</td>\n",
       "      <td id=\"T_f69d3_row62_col1\" class=\"data row62 col1\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row62_col2\" class=\"data row62 col2\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row62_col3\" class=\"data row62 col3\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row62_col4\" class=\"data row62 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row63\" class=\"row_heading level0 row63\" >63</th>\n",
       "      <td id=\"T_f69d3_row63_col0\" class=\"data row63 col0\" >Yep, team player here! I'm good at working collaboratively and sticking to procedures.</td>\n",
       "      <td id=\"T_f69d3_row63_col1\" class=\"data row63 col1\" >qa_4</td>\n",
       "      <td id=\"T_f69d3_row63_col2\" class=\"data row63 col2\" >produce the utterance_type. We see the user mentioning their ability to work collaboratively and stick to procedures, indicating a focus on their skills and work...</td>\n",
       "      <td id=\"T_f69d3_row63_col3\" class=\"data row63 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row63_col4\" class=\"data row63 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row64\" class=\"row_heading level0 row64\" >64</th>\n",
       "      <td id=\"T_f69d3_row64_col0\" class=\"data row64 col0\" >Good morning! What are the company's main products or services?</td>\n",
       "      <td id=\"T_f69d3_row64_col1\" class=\"data row64 col1\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row64_col2\" class=\"data row64 col2\" >'company_related'. We see the user starts with a 'greeting' which indicates politeness and then asks about the company's main products or services, showing interest in...</td>\n",
       "      <td id=\"T_f69d3_row64_col3\" class=\"data row64 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row64_col4\" class=\"data row64 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row65\" class=\"row_heading level0 row65\" >65</th>\n",
       "      <td id=\"T_f69d3_row65_col0\" class=\"data row65 col0\" >Hey! Can you provide some information about the company's technology stack?</td>\n",
       "      <td id=\"T_f69d3_row65_col1\" class=\"data row65 col1\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row65_col2\" class=\"data row65 col2\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row65_col3\" class=\"data row65 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row65_col4\" class=\"data row65 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row66\" class=\"row_heading level0 row66\" >66</th>\n",
       "      <td id=\"T_f69d3_row66_col0\" class=\"data row66 col0\" >Thanks, but I’ll have to decline.</td>\n",
       "      <td id=\"T_f69d3_row66_col1\" class=\"data row66 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row66_col2\" class=\"data row66 col2\" >produce the utterance_type. We see that the user is expressing gratitude but also declining something. This indicates that the utterance is related to feedbacks.</td>\n",
       "      <td id=\"T_f69d3_row66_col3\" class=\"data row66 col3\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row66_col4\" class=\"data row66 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row67\" class=\"row_heading level0 row67\" >67</th>\n",
       "      <td id=\"T_f69d3_row67_col0\" class=\"data row67 col0\" >I’m not continuing with this, sorry.</td>\n",
       "      <td id=\"T_f69d3_row67_col1\" class=\"data row67 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row67_col2\" class=\"data row67 col2\" >not_continue_related. We can see that the user explicitly states that they are not continuing with the conversation.</td>\n",
       "      <td id=\"T_f69d3_row67_col3\" class=\"data row67 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row67_col4\" class=\"data row67 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row68\" class=\"row_heading level0 row68\" >68</th>\n",
       "      <td id=\"T_f69d3_row68_col0\" class=\"data row68 col0\" >I need some time to myself, talk to you later!</td>\n",
       "      <td id=\"T_f69d3_row68_col1\" class=\"data row68 col1\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row68_col2\" class=\"data row68 col2\" >not_continue_related. We can see that the user is indicating that they need some time alone and will talk later, so this utterance is not related...</td>\n",
       "      <td id=\"T_f69d3_row68_col3\" class=\"data row68 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row68_col4\" class=\"data row68 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row69\" class=\"row_heading level0 row69\" >69</th>\n",
       "      <td id=\"T_f69d3_row69_col0\" class=\"data row69 col0\" >I believe in listening carefully and addressing their concerns with empathy and efficiency.</td>\n",
       "      <td id=\"T_f69d3_row69_col1\" class=\"data row69 col1\" >qa_3</td>\n",
       "      <td id=\"T_f69d3_row69_col2\" class=\"data row69 col2\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row69_col3\" class=\"data row69 col3\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row69_col4\" class=\"data row69 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row70\" class=\"row_heading level0 row70\" >70</th>\n",
       "      <td id=\"T_f69d3_row70_col0\" class=\"data row70 col0\" >Hi! I'm really sorry, but I have to step out unexpectedly. Can we continue this discussion later?</td>\n",
       "      <td id=\"T_f69d3_row70_col1\" class=\"data row70 col1\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row70_col2\" class=\"data row70 col2\" >produce the utterance type. We see that the user starts with a greeting \"Hi!\", then apologizes for having to leave unexpectedly, and finally asks to...</td>\n",
       "      <td id=\"T_f69d3_row70_col3\" class=\"data row70 col3\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row70_col4\" class=\"data row70 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row71\" class=\"row_heading level0 row71\" >71</th>\n",
       "      <td id=\"T_f69d3_row71_col0\" class=\"data row71 col0\" >Hello! How does the company foster employee growth and development?</td>\n",
       "      <td id=\"T_f69d3_row71_col1\" class=\"data row71 col1\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row71_col2\" class=\"data row71 col2\" >produce the utterance_type. We see that the user starts with a greeting \"Hello!\" and then asks a question related to the company's practices. This indicates...</td>\n",
       "      <td id=\"T_f69d3_row71_col3\" class=\"data row71 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row71_col4\" class=\"data row71 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row72\" class=\"row_heading level0 row72\" >72</th>\n",
       "      <td id=\"T_f69d3_row72_col0\" class=\"data row72 col0\" >Hi! How does the company encourage innovation among its employees?</td>\n",
       "      <td id=\"T_f69d3_row72_col1\" class=\"data row72 col1\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row72_col2\" class=\"data row72 col2\" >company_related. We see that the user is asking about how the company encourages innovation among its employees, which is directly related to the company's practices...</td>\n",
       "      <td id=\"T_f69d3_row72_col3\" class=\"data row72 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row72_col4\" class=\"data row72 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row73\" class=\"row_heading level0 row73\" >73</th>\n",
       "      <td id=\"T_f69d3_row73_col0\" class=\"data row73 col0\" >Hey! How's life treating you?</td>\n",
       "      <td id=\"T_f69d3_row73_col1\" class=\"data row73 col1\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row73_col2\" class=\"data row73 col2\" >produce the utterance_type. We see that the user is starting the conversation with a friendly greeting and asking about the other person's well-being. This indicates...</td>\n",
       "      <td id=\"T_f69d3_row73_col3\" class=\"data row73 col3\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row73_col4\" class=\"data row73 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row74\" class=\"row_heading level0 row74\" >74</th>\n",
       "      <td id=\"T_f69d3_row74_col0\" class=\"data row74 col0\" >What kind of support does the company offer for professional development?</td>\n",
       "      <td id=\"T_f69d3_row74_col1\" class=\"data row74 col1\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row74_col2\" class=\"data row74 col2\" >produce the utterance_type. We see that the user is asking about the support offered by the company for professional development, indicating an interest in company-related...</td>\n",
       "      <td id=\"T_f69d3_row74_col3\" class=\"data row74 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row74_col4\" class=\"data row74 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row75\" class=\"row_heading level0 row75\" >75</th>\n",
       "      <td id=\"T_f69d3_row75_col0\" class=\"data row75 col0\" >I’ve done customer service for a software company, where I helped users with troubleshooting and product guidance.</td>\n",
       "      <td id=\"T_f69d3_row75_col1\" class=\"data row75 col1\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row75_col2\" class=\"data row75 col2\" >identify the type of utterance. The user is providing information about their past experience in customer service for a software company. This does not directly...</td>\n",
       "      <td id=\"T_f69d3_row75_col3\" class=\"data row75 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row75_col4\" class=\"data row75 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row76\" class=\"row_heading level0 row76\" >76</th>\n",
       "      <td id=\"T_f69d3_row76_col0\" class=\"data row76 col0\" >Hi! I'm looking forward to talking to you.</td>\n",
       "      <td id=\"T_f69d3_row76_col1\" class=\"data row76 col1\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row76_col2\" class=\"data row76 col2\" >produce the utterance_type. We see that the user is initiating the conversation with a greeting and expressing anticipation for the conversation.</td>\n",
       "      <td id=\"T_f69d3_row76_col3\" class=\"data row76 col3\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row76_col4\" class=\"data row76 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row77\" class=\"row_heading level0 row77\" >77</th>\n",
       "      <td id=\"T_f69d3_row77_col0\" class=\"data row77 col0\" >Excellent, what's the next question?</td>\n",
       "      <td id=\"T_f69d3_row77_col1\" class=\"data row77 col1\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row77_col2\" class=\"data row77 col2\" >produce the utterance type. We see the user expressing satisfaction with the previous question and asking for the next one. This indicates a desire to...</td>\n",
       "      <td id=\"T_f69d3_row77_col3\" class=\"data row77 col3\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row77_col4\" class=\"data row77 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row78\" class=\"row_heading level0 row78\" >78</th>\n",
       "      <td id=\"T_f69d3_row78_col0\" class=\"data row78 col0\" >I have to go, but we can continue this on WhatsApp later</td>\n",
       "      <td id=\"T_f69d3_row78_col1\" class=\"data row78 col1\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row78_col2\" class=\"data row78 col2\" >produce the utterance_type. We see that the user mentions having to go but suggests continuing the conversation on WhatsApp later. This indicates that the user...</td>\n",
       "      <td id=\"T_f69d3_row78_col3\" class=\"data row78 col3\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row78_col4\" class=\"data row78 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row79\" class=\"row_heading level0 row79\" >79</th>\n",
       "      <td id=\"T_f69d3_row79_col0\" class=\"data row79 col0\" >I always stay calm and listen to the customer's concerns carefully before offering a solution.</td>\n",
       "      <td id=\"T_f69d3_row79_col1\" class=\"data row79 col1\" >qa_3</td>\n",
       "      <td id=\"T_f69d3_row79_col2\" class=\"data row79 col2\" >produce the utterance_type. We see that the user is describing their approach to customer service, indicating a general behavior or attitude.</td>\n",
       "      <td id=\"T_f69d3_row79_col3\" class=\"data row79 col3\" >out_of_scope</td>\n",
       "      <td id=\"T_f69d3_row79_col4\" class=\"data row79 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row80\" class=\"row_heading level0 row80\" >80</th>\n",
       "      <td id=\"T_f69d3_row80_col0\" class=\"data row80 col0\" >First, I try to understand the problem from their perspective and then work towards a satisfactory resolution.</td>\n",
       "      <td id=\"T_f69d3_row80_col1\" class=\"data row80 col1\" >qa_3</td>\n",
       "      <td id=\"T_f69d3_row80_col2\" class=\"data row80 col2\" >produce the utterance_type. We see that the user is discussing their approach to problem-solving, indicating a general statement about their work process.</td>\n",
       "      <td id=\"T_f69d3_row80_col3\" class=\"data row80 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row80_col4\" class=\"data row80 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row81\" class=\"row_heading level0 row81\" >81</th>\n",
       "      <td id=\"T_f69d3_row81_col0\" class=\"data row81 col0\" >Okay, I'm ready to move forward.</td>\n",
       "      <td id=\"T_f69d3_row81_col1\" class=\"data row81 col1\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row81_col2\" class=\"data row81 col2\" >produce the utterance_type. We see that the user is indicating readiness to continue the conversation.</td>\n",
       "      <td id=\"T_f69d3_row81_col3\" class=\"data row81 col3\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row81_col4\" class=\"data row81 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row82\" class=\"row_heading level0 row82\" >82</th>\n",
       "      <td id=\"T_f69d3_row82_col0\" class=\"data row82 col0\" >I’ve decided not to move forward with this process.</td>\n",
       "      <td id=\"T_f69d3_row82_col1\" class=\"data row82 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row82_col2\" class=\"data row82 col2\" >produce the utterance_type. We can see that the user is explicitly stating that they do not want to continue with a certain process.</td>\n",
       "      <td id=\"T_f69d3_row82_col3\" class=\"data row82 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row82_col4\" class=\"data row82 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row83\" class=\"row_heading level0 row83\" >83</th>\n",
       "      <td id=\"T_f69d3_row83_col0\" class=\"data row83 col0\" >Hi! What's the company's approach to employee wellness?</td>\n",
       "      <td id=\"T_f69d3_row83_col1\" class=\"data row83 col1\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row83_col2\" class=\"data row83 col2\" >company_related. We see that the user is asking about the company's approach to employee wellness, which is related to the company's policies and practices.</td>\n",
       "      <td id=\"T_f69d3_row83_col3\" class=\"data row83 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row83_col4\" class=\"data row83 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row84\" class=\"row_heading level0 row84\" >84</th>\n",
       "      <td id=\"T_f69d3_row84_col0\" class=\"data row84 col0\" >Hey! Any chance I could get an update on my application status?</td>\n",
       "      <td id=\"T_f69d3_row84_col1\" class=\"data row84 col1\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row84_col2\" class=\"data row84 col2\" >determine the utterance type. The user starts with a greeting \"Hey!\" and then asks for an update on their application status. This indicates that the...</td>\n",
       "      <td id=\"T_f69d3_row84_col3\" class=\"data row84 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row84_col4\" class=\"data row84 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row85\" class=\"row_heading level0 row85\" >85</th>\n",
       "      <td id=\"T_f69d3_row85_col0\" class=\"data row85 col0\" >What kind of benefits do you offer to employees?</td>\n",
       "      <td id=\"T_f69d3_row85_col1\" class=\"data row85 col1\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row85_col2\" class=\"data row85 col2\" >answer a question related to company benefits. The user is asking about the benefits offered to employees, which is a common inquiry related to the...</td>\n",
       "      <td id=\"T_f69d3_row85_col3\" class=\"data row85 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row85_col4\" class=\"data row85 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row86\" class=\"row_heading level0 row86\" >86</th>\n",
       "      <td id=\"T_f69d3_row86_col0\" class=\"data row86 col0\" >Absolutely! I'm a team player, and I take following policies and procedures seriously.</td>\n",
       "      <td id=\"T_f69d3_row86_col1\" class=\"data row86 col1\" >qa_4</td>\n",
       "      <td id=\"T_f69d3_row86_col2\" class=\"data row86 col2\" >produce the utterance_type. We see that the user is expressing their willingness to follow policies and procedures, indicating a positive attitude towards teamwork. This response...</td>\n",
       "      <td id=\"T_f69d3_row86_col3\" class=\"data row86 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row86_col4\" class=\"data row86 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row87\" class=\"row_heading level0 row87\" >87</th>\n",
       "      <td id=\"T_f69d3_row87_col0\" class=\"data row87 col0\" >Is my application still being considered?</td>\n",
       "      <td id=\"T_f69d3_row87_col1\" class=\"data row87 col1\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row87_col2\" class=\"data row87 col2\" >determine the type of utterance. The user is asking about the status of their application, which is related to the progress of a process.</td>\n",
       "      <td id=\"T_f69d3_row87_col3\" class=\"data row87 col3\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row87_col4\" class=\"data row87 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row88\" class=\"row_heading level0 row88\" >88</th>\n",
       "      <td id=\"T_f69d3_row88_col0\" class=\"data row88 col0\" >Hey there! Just checking in to see if there's any update on my interview status?</td>\n",
       "      <td id=\"T_f69d3_row88_col1\" class=\"data row88 col1\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row88_col2\" class=\"data row88 col2\" >produce the utterance type. We see that the user is greeting and asking about the status of their interview. This indicates that the user is...</td>\n",
       "      <td id=\"T_f69d3_row88_col3\" class=\"data row88 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row88_col4\" class=\"data row88 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row89\" class=\"row_heading level0 row89\" >89</th>\n",
       "      <td id=\"T_f69d3_row89_col0\" class=\"data row89 col0\" >Hey there! Thanks for reaching out. I'm currently tied up with a meeting, can we continue this later?</td>\n",
       "      <td id=\"T_f69d3_row89_col1\" class=\"data row89 col1\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row89_col2\" class=\"data row89 col2\" >produce the utterance type. We see that the user starts with a greeting (\"Hey there!\") and expresses gratitude (\"Thanks for reaching out\"). The user then...</td>\n",
       "      <td id=\"T_f69d3_row89_col3\" class=\"data row89 col3\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row89_col4\" class=\"data row89 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row90\" class=\"row_heading level0 row90\" >90</th>\n",
       "      <td id=\"T_f69d3_row90_col0\" class=\"data row90 col0\" >I focus on active listening and try to resolve their issues promptly to keep them satisfied.</td>\n",
       "      <td id=\"T_f69d3_row90_col1\" class=\"data row90 col1\" >qa_3</td>\n",
       "      <td id=\"T_f69d3_row90_col2\" class=\"data row90 col2\" >produce the utterance_type. We see that the user is talking about their approach to customer service, mentioning active listening and resolving issues promptly. This indicates...</td>\n",
       "      <td id=\"T_f69d3_row90_col3\" class=\"data row90 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row90_col4\" class=\"data row90 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row91\" class=\"row_heading level0 row91\" >91</th>\n",
       "      <td id=\"T_f69d3_row91_col0\" class=\"data row91 col0\" >Hi! Let's catch up.</td>\n",
       "      <td id=\"T_f69d3_row91_col1\" class=\"data row91 col1\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row91_col2\" class=\"data row91 col2\" >produce the utterance_type. We see the word \"Hi\" which is a common greeting and the phrase \"Let's catch up\" indicates a desire to continue a...</td>\n",
       "      <td id=\"T_f69d3_row91_col3\" class=\"data row91 col3\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row91_col4\" class=\"data row91 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row92\" class=\"row_heading level0 row92\" >92</th>\n",
       "      <td id=\"T_f69d3_row92_col0\" class=\"data row92 col0\" >👍 I'm in.</td>\n",
       "      <td id=\"T_f69d3_row92_col1\" class=\"data row92 col1\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row92_col2\" class=\"data row92 col2\" >determine the utterance type. The user is expressing agreement and willingness to participate in something.</td>\n",
       "      <td id=\"T_f69d3_row92_col3\" class=\"data row92 col3\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row92_col4\" class=\"data row92 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row93\" class=\"row_heading level0 row93\" >93</th>\n",
       "      <td id=\"T_f69d3_row93_col0\" class=\"data row93 col0\" >Hi! 👋 What's up?</td>\n",
       "      <td id=\"T_f69d3_row93_col1\" class=\"data row93 col1\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row93_col2\" class=\"data row93 col2\" >produce the utterance_type. We see that the user is initiating a conversation with a greeting and asking a casual question about the other person's well-being.</td>\n",
       "      <td id=\"T_f69d3_row93_col3\" class=\"data row93 col3\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row93_col4\" class=\"data row93 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row94\" class=\"row_heading level0 row94\" >94</th>\n",
       "      <td id=\"T_f69d3_row94_col0\" class=\"data row94 col0\" >Taking a moment to stretch and move around helps keep me energized.</td>\n",
       "      <td id=\"T_f69d3_row94_col1\" class=\"data row94 col1\" >qa_2</td>\n",
       "      <td id=\"T_f69d3_row94_col2\" class=\"data row94 col2\" >produce the utterance_type. We see that the user is talking about taking a break to stretch and move around, which is related to personal well-being...</td>\n",
       "      <td id=\"T_f69d3_row94_col3\" class=\"data row94 col3\" >out_of_scope</td>\n",
       "      <td id=\"T_f69d3_row94_col4\" class=\"data row94 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row95\" class=\"row_heading level0 row95\" >95</th>\n",
       "      <td id=\"T_f69d3_row95_col0\" class=\"data row95 col0\" >Sure thing! I'm great at collaborating with others and sticking to company policies.</td>\n",
       "      <td id=\"T_f69d3_row95_col1\" class=\"data row95 col1\" >qa_4</td>\n",
       "      <td id=\"T_f69d3_row95_col2\" class=\"data row95 col2\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row95_col3\" class=\"data row95 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row95_col4\" class=\"data row95 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row96\" class=\"row_heading level0 row96\" >96</th>\n",
       "      <td id=\"T_f69d3_row96_col0\" class=\"data row96 col0\" >Hey! I'm really sorry, but I have to step away for a moment. Can we continue this in an hour?</td>\n",
       "      <td id=\"T_f69d3_row96_col1\" class=\"data row96 col1\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row96_col2\" class=\"data row96 col2\" >not_continue_related. We can see that the user is apologizing for needing to step away and is requesting to continue the conversation at a later time....</td>\n",
       "      <td id=\"T_f69d3_row96_col3\" class=\"data row96 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row96_col4\" class=\"data row96 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row97\" class=\"row_heading level0 row97\" >97</th>\n",
       "      <td id=\"T_f69d3_row97_col0\" class=\"data row97 col0\" >I'd love to know where I stand in the process.</td>\n",
       "      <td id=\"T_f69d3_row97_col1\" class=\"data row97 col1\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row97_col2\" class=\"data row97 col2\" >produce the utterance type. We see that the user is asking for information about their current status in a process. This indicates that the user...</td>\n",
       "      <td id=\"T_f69d3_row97_col3\" class=\"data row97 col3\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row97_col4\" class=\"data row97 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row98\" class=\"row_heading level0 row98\" >98</th>\n",
       "      <td id=\"T_f69d3_row98_col0\" class=\"data row98 col0\" >No problem at all! I'm great at collaborating with others and adhering to policies and procedures.</td>\n",
       "      <td id=\"T_f69d3_row98_col1\" class=\"data row98 col1\" >qa_4</td>\n",
       "      <td id=\"T_f69d3_row98_col2\" class=\"data row98 col2\" >produce the utterance_type. We see that the user is expressing their skills and abilities in collaborating with others and following policies and procedures. This does...</td>\n",
       "      <td id=\"T_f69d3_row98_col3\" class=\"data row98 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row98_col4\" class=\"data row98 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row99\" class=\"row_heading level0 row99\" >99</th>\n",
       "      <td id=\"T_f69d3_row99_col0\" class=\"data row99 col0\" >I have to go, but we can pick this up later</td>\n",
       "      <td id=\"T_f69d3_row99_col1\" class=\"data row99 col1\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row99_col2\" class=\"data row99 col2\" >produce the utterance type. We see that the user is indicating that they have to leave but are open to continuing the conversation later. They...</td>\n",
       "      <td id=\"T_f69d3_row99_col3\" class=\"data row99 col3\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row99_col4\" class=\"data row99 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row100\" class=\"row_heading level0 row100\" >100</th>\n",
       "      <td id=\"T_f69d3_row100_col0\" class=\"data row100 col0\" >Count me in!</td>\n",
       "      <td id=\"T_f69d3_row100_col1\" class=\"data row100 col1\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row100_col2\" class=\"data row100 col2\" >produce the utterance_type. We see that the user is expressing interest in joining something or participating in an activity.</td>\n",
       "      <td id=\"T_f69d3_row100_col3\" class=\"data row100 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row100_col4\" class=\"data row100 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row101\" class=\"row_heading level0 row101\" >101</th>\n",
       "      <td id=\"T_f69d3_row101_col0\" class=\"data row101 col0\" >Hey there! Wondering if there's any news on my application status?</td>\n",
       "      <td id=\"T_f69d3_row101_col1\" class=\"data row101 col1\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row101_col2\" class=\"data row101 col2\" >determine the utterance type. The user starts with a greeting \"Hey there!\" and then asks about the status of their application. This indicates that the...</td>\n",
       "      <td id=\"T_f69d3_row101_col3\" class=\"data row101 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row101_col4\" class=\"data row101 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row102\" class=\"row_heading level0 row102\" >102</th>\n",
       "      <td id=\"T_f69d3_row102_col0\" class=\"data row102 col0\" >Handling it with a smile and a can-do attitude usually helps in resolving their issues. 😊</td>\n",
       "      <td id=\"T_f69d3_row102_col1\" class=\"data row102 col1\" >qa_3</td>\n",
       "      <td id=\"T_f69d3_row102_col2\" class=\"data row102 col2\" >produce the utterance_type. We see that the user is talking about resolving issues with a positive attitude, which is not directly related to the conversation...</td>\n",
       "      <td id=\"T_f69d3_row102_col3\" class=\"data row102 col3\" >out_of_scope</td>\n",
       "      <td id=\"T_f69d3_row102_col4\" class=\"data row102 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row103\" class=\"row_heading level0 row103\" >103</th>\n",
       "      <td id=\"T_f69d3_row103_col0\" class=\"data row103 col0\" >Of course! I'm all about teamwork and making sure everything runs smoothly according to the rules.</td>\n",
       "      <td id=\"T_f69d3_row103_col1\" class=\"data row103 col1\" >qa_4</td>\n",
       "      <td id=\"T_f69d3_row103_col2\" class=\"data row103 col2\" >produce the utterance_type. We see that the user is expressing their willingness to work as a team and ensure smooth operations according to rules. This...</td>\n",
       "      <td id=\"T_f69d3_row103_col3\" class=\"data row103 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row103_col4\" class=\"data row103 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row104\" class=\"row_heading level0 row104\" >104</th>\n",
       "      <td id=\"T_f69d3_row104_col0\" class=\"data row104 col0\" >Hi! It's nice to reconnect.</td>\n",
       "      <td id=\"T_f69d3_row104_col1\" class=\"data row104 col1\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row104_col2\" class=\"data row104 col2\" >produce the utterance_type. We see that the user is initiating the conversation with a friendly greeting, expressing pleasure in reconnecting.</td>\n",
       "      <td id=\"T_f69d3_row104_col3\" class=\"data row104 col3\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row104_col4\" class=\"data row104 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row105\" class=\"row_heading level0 row105\" >105</th>\n",
       "      <td id=\"T_f69d3_row105_col0\" class=\"data row105 col0\" >Of course, I'm in favor.</td>\n",
       "      <td id=\"T_f69d3_row105_col1\" class=\"data row105 col1\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row105_col2\" class=\"data row105 col2\" >produce the utterance type. We see that the user is expressing agreement with something.</td>\n",
       "      <td id=\"T_f69d3_row105_col3\" class=\"data row105 col3\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row105_col4\" class=\"data row105 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row106\" class=\"row_heading level0 row106\" >106</th>\n",
       "      <td id=\"T_f69d3_row106_col0\" class=\"data row106 col0\" >Yo! What's the company's mission and values?</td>\n",
       "      <td id=\"T_f69d3_row106_col1\" class=\"data row106 col1\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row106_col2\" class=\"data row106 col2\" >produce the utterance_type. We see that the user is starting with a casual greeting \"Yo!\" followed by a question about the company's mission and values....</td>\n",
       "      <td id=\"T_f69d3_row106_col3\" class=\"data row106 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row106_col4\" class=\"data row106 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row107\" class=\"row_heading level0 row107\" >107</th>\n",
       "      <td id=\"T_f69d3_row107_col0\" class=\"data row107 col0\" >I'm excited to see what's next!</td>\n",
       "      <td id=\"T_f69d3_row107_col1\" class=\"data row107 col1\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row107_col2\" class=\"data row107 col2\" >produce the utterance_type. We see that the user is expressing excitement about something upcoming. This indicates a positive sentiment and anticipation for the future.</td>\n",
       "      <td id=\"T_f69d3_row107_col3\" class=\"data row107 col3\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row107_col4\" class=\"data row107 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row108\" class=\"row_heading level0 row108\" >108</th>\n",
       "      <td id=\"T_f69d3_row108_col0\" class=\"data row108 col0\" >Hey! What's on your mind?</td>\n",
       "      <td id=\"T_f69d3_row108_col1\" class=\"data row108 col1\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row108_col2\" class=\"data row108 col2\" >produce the utterance_type. We see that the user is initiating a conversation with a friendly greeting and asking a question about the other person's thoughts....</td>\n",
       "      <td id=\"T_f69d3_row108_col3\" class=\"data row108 col3\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row108_col4\" class=\"data row108 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row109\" class=\"row_heading level0 row109\" >109</th>\n",
       "      <td id=\"T_f69d3_row109_col0\" class=\"data row109 col0\" >Hi! Unfortunately, I've hit a roadblock in the process. Can we revisit this tomorrow?</td>\n",
       "      <td id=\"T_f69d3_row109_col1\" class=\"data row109 col1\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row109_col2\" class=\"data row109 col2\" >produce the utterance_type. We see the user starting with a greeting \"Hi!\", then mentioning a roadblock in the process, and finally asking to revisit the...</td>\n",
       "      <td id=\"T_f69d3_row109_col3\" class=\"data row109 col3\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row109_col4\" class=\"data row109 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row110\" class=\"row_heading level0 row110\" >110</th>\n",
       "      <td id=\"T_f69d3_row110_col0\" class=\"data row110 col0\" >Hi! What's the company's strategy for growth and expansion?</td>\n",
       "      <td id=\"T_f69d3_row110_col1\" class=\"data row110 col1\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row110_col2\" class=\"data row110 col2\" >produce the utterance_type. We see that the user starts with a greeting \"Hi!\" which indicates a friendly tone. Then, the user asks about the company's...</td>\n",
       "      <td id=\"T_f69d3_row110_col3\" class=\"data row110 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row110_col4\" class=\"data row110 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row111\" class=\"row_heading level0 row111\" >111</th>\n",
       "      <td id=\"T_f69d3_row111_col0\" class=\"data row111 col0\" >Absolutely! I used to work in customer support for a tech company, helping clients with troubleshooting and product information.</td>\n",
       "      <td id=\"T_f69d3_row111_col1\" class=\"data row111 col1\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row111_col2\" class=\"data row111 col2\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row111_col3\" class=\"data row111 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row111_col4\" class=\"data row111 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row112\" class=\"row_heading level0 row112\" >112</th>\n",
       "      <td id=\"T_f69d3_row112_col0\" class=\"data row112 col0\" >Hey! What's happening? 🤷‍♂️</td>\n",
       "      <td id=\"T_f69d3_row112_col1\" class=\"data row112 col1\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row112_col2\" class=\"data row112 col2\" >produce the utterance_type. We see that the user is initiating a conversation with a greeting and asking about the current situation.</td>\n",
       "      <td id=\"T_f69d3_row112_col3\" class=\"data row112 col3\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row112_col4\" class=\"data row112 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row113\" class=\"row_heading level0 row113\" >113</th>\n",
       "      <td id=\"T_f69d3_row113_col0\" class=\"data row113 col0\" >Yo! Any chance I could get an update on how things are progressing with my evaluation?</td>\n",
       "      <td id=\"T_f69d3_row113_col1\" class=\"data row113 col1\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row113_col2\" class=\"data row113 col2\" >determine the utterance type. The user starts with a greeting \"Yo!\" and then asks for an update on the progress of their evaluation. This indicates...</td>\n",
       "      <td id=\"T_f69d3_row113_col3\" class=\"data row113 col3\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row113_col4\" class=\"data row113 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row114\" class=\"row_heading level0 row114\" >114</th>\n",
       "      <td id=\"T_f69d3_row114_col0\" class=\"data row114 col0\" >I'm down for this!</td>\n",
       "      <td id=\"T_f69d3_row114_col1\" class=\"data row114 col1\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row114_col2\" class=\"data row114 col2\" >produce the utterance_type. We see that the user is expressing enthusiasm and agreement towards something.</td>\n",
       "      <td id=\"T_f69d3_row114_col3\" class=\"data row114 col3\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row114_col4\" class=\"data row114 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row115\" class=\"row_heading level0 row115\" >115</th>\n",
       "      <td id=\"T_f69d3_row115_col0\" class=\"data row115 col0\" >I’m declining to move forward, thanks.</td>\n",
       "      <td id=\"T_f69d3_row115_col1\" class=\"data row115 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row115_col2\" class=\"data row115 col2\" >produce the utterance type. We see that the user is explicitly stating that they do not want to continue, which indicates a decision to not...</td>\n",
       "      <td id=\"T_f69d3_row115_col3\" class=\"data row115 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row115_col4\" class=\"data row115 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row116\" class=\"row_heading level0 row116\" >116</th>\n",
       "      <td id=\"T_f69d3_row116_col0\" class=\"data row116 col0\" >Yep, I'm a team player and always follow the rules and procedures.</td>\n",
       "      <td id=\"T_f69d3_row116_col1\" class=\"data row116 col1\" >qa_4</td>\n",
       "      <td id=\"T_f69d3_row116_col2\" class=\"data row116 col2\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row116_col3\" class=\"data row116 col3\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row116_col4\" class=\"data row116 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row117\" class=\"row_heading level0 row117\" >117</th>\n",
       "      <td id=\"T_f69d3_row117_col0\" class=\"data row117 col0\" >I stay focused by visualizing my career growth and future opportunities.</td>\n",
       "      <td id=\"T_f69d3_row117_col1\" class=\"data row117 col1\" >qa_2</td>\n",
       "      <td id=\"T_f69d3_row117_col2\" class=\"data row117 col2\" >produce the utterance_type. We see that the user is talking about their personal habits and mindset regarding career growth and future opportunities. This does not...</td>\n",
       "      <td id=\"T_f69d3_row117_col3\" class=\"data row117 col3\" >out_of_scope</td>\n",
       "      <td id=\"T_f69d3_row117_col4\" class=\"data row117 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row118\" class=\"row_heading level0 row118\" >118</th>\n",
       "      <td id=\"T_f69d3_row118_col0\" class=\"data row118 col0\" >Hey there! Hoping to get an update on my application status.</td>\n",
       "      <td id=\"T_f69d3_row118_col1\" class=\"data row118 col1\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row118_col2\" class=\"data row118 col2\" >'continue_related'. We see that the user is starting with a greeting (\"Hey there!\") and then directly asking for an update on their application status. This...</td>\n",
       "      <td id=\"T_f69d3_row118_col3\" class=\"data row118 col3\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row118_col4\" class=\"data row118 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row119\" class=\"row_heading level0 row119\" >119</th>\n",
       "      <td id=\"T_f69d3_row119_col0\" class=\"data row119 col0\" >I’ll be bowing out of this process.</td>\n",
       "      <td id=\"T_f69d3_row119_col1\" class=\"data row119 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row119_col2\" class=\"data row119 col2\" >produce the utterance type. We see that the user is indicating that they will no longer be participating in the process. This suggests that the...</td>\n",
       "      <td id=\"T_f69d3_row119_col3\" class=\"data row119 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row119_col4\" class=\"data row119 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row120\" class=\"row_heading level0 row120\" >120</th>\n",
       "      <td id=\"T_f69d3_row120_col0\" class=\"data row120 col0\" >Is there opportunity for growth within the company?</td>\n",
       "      <td id=\"T_f69d3_row120_col1\" class=\"data row120 col1\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row120_col2\" class=\"data row120 col2\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row120_col3\" class=\"data row120 col3\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row120_col4\" class=\"data row120 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row121\" class=\"row_heading level0 row121\" >121</th>\n",
       "      <td id=\"T_f69d3_row121_col0\" class=\"data row121 col0\" >Fine by me, let's move forward.</td>\n",
       "      <td id=\"T_f69d3_row121_col1\" class=\"data row121 col1\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row121_col2\" class=\"data row121 col2\" >produce the utterance type. We see that the user is expressing agreement and willingness to continue the conversation.</td>\n",
       "      <td id=\"T_f69d3_row121_col3\" class=\"data row121 col3\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row121_col4\" class=\"data row121 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row122\" class=\"row_heading level0 row122\" >122</th>\n",
       "      <td id=\"T_f69d3_row122_col0\" class=\"data row122 col0\" >I remind myself of my goals and the rewards of hard work.</td>\n",
       "      <td id=\"T_f69d3_row122_col1\" class=\"data row122 col1\" >qa_2</td>\n",
       "      <td id=\"T_f69d3_row122_col2\" class=\"data row122 col2\" >produce the utterance_type. We see that the user is reflecting on their goals and the rewards of hard work, indicating a personal reflection or motivation.</td>\n",
       "      <td id=\"T_f69d3_row122_col3\" class=\"data row122 col3\" >out_of_scope</td>\n",
       "      <td id=\"T_f69d3_row122_col4\" class=\"data row122 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row123\" class=\"row_heading level0 row123\" >123</th>\n",
       "      <td id=\"T_f69d3_row123_col0\" class=\"data row123 col0\" >That's okay, let's try again.</td>\n",
       "      <td id=\"T_f69d3_row123_col1\" class=\"data row123 col1\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row123_col2\" class=\"data row123 col2\" >produce the utterance_type. We see that the user is acknowledging a mistake or failure and expressing a willingness to try again. This indicates a positive...</td>\n",
       "      <td id=\"T_f69d3_row123_col3\" class=\"data row123 col3\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row123_col4\" class=\"data row123 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row124\" class=\"row_heading level0 row124\" >124</th>\n",
       "      <td id=\"T_f69d3_row124_col0\" class=\"data row124 col0\" >Certainly, I agree.</td>\n",
       "      <td id=\"T_f69d3_row124_col1\" class=\"data row124 col1\" >continue_related</td>\n",
       "      <td id=\"T_f69d3_row124_col2\" class=\"data row124 col2\" >produce the utterance_type. We see that the user is expressing agreement with a previous statement.</td>\n",
       "      <td id=\"T_f69d3_row124_col3\" class=\"data row124 col3\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row124_col4\" class=\"data row124 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row125\" class=\"row_heading level0 row125\" >125</th>\n",
       "      <td id=\"T_f69d3_row125_col0\" class=\"data row125 col0\" >Hi! I'm looking forward to chatting with you.</td>\n",
       "      <td id=\"T_f69d3_row125_col1\" class=\"data row125 col1\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row125_col2\" class=\"data row125 col2\" >produce the utterance_type. We see that the user is initiating the conversation with a greeting and expressing their excitement to chat.</td>\n",
       "      <td id=\"T_f69d3_row125_col3\" class=\"data row125 col3\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row125_col4\" class=\"data row125 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row126\" class=\"row_heading level0 row126\" >126</th>\n",
       "      <td id=\"T_f69d3_row126_col0\" class=\"data row126 col0\" >Hi! I'm afraid I won't be able to proceed with the evaluation at the moment. Can we reconvene tomorrow?</td>\n",
       "      <td id=\"T_f69d3_row126_col1\" class=\"data row126 col1\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row126_col2\" class=\"data row126 col2\" >produce the utterance type. We see that the user starts with a greeting \"Hi!\", then mentions that they can't proceed with the evaluation at the...</td>\n",
       "      <td id=\"T_f69d3_row126_col3\" class=\"data row126 col3\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row126_col4\" class=\"data row126 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row127\" class=\"row_heading level0 row127\" >127</th>\n",
       "      <td id=\"T_f69d3_row127_col0\" class=\"data row127 col0\" >Hey, how are you today?</td>\n",
       "      <td id=\"T_f69d3_row127_col1\" class=\"data row127 col1\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row127_col2\" class=\"data row127 col2\" >produce the utterance_type. We see that the user is initiating a conversation by asking about the other person's well-being. This indicates a greeting.</td>\n",
       "      <td id=\"T_f69d3_row127_col3\" class=\"data row127 col3\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row127_col4\" class=\"data row127 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row128\" class=\"row_heading level0 row128\" >128</th>\n",
       "      <td id=\"T_f69d3_row128_col0\" class=\"data row128 col0\" >Hello! I hope you're doing well. Could you please let me know the current status of my interview?</td>\n",
       "      <td id=\"T_f69d3_row128_col1\" class=\"data row128 col1\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row128_col2\" class=\"data row128 col2\" >produce the utterance_type. We see that the user starts with a greeting, expresses concern for the other person's well-being, and then asks about the current...</td>\n",
       "      <td id=\"T_f69d3_row128_col3\" class=\"data row128 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row128_col4\" class=\"data row128 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row129\" class=\"row_heading level0 row129\" >129</th>\n",
       "      <td id=\"T_f69d3_row129_col0\" class=\"data row129 col0\" >What's the current stage of my hiring process?</td>\n",
       "      <td id=\"T_f69d3_row129_col1\" class=\"data row129 col1\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row129_col2\" class=\"data row129 col2\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row129_col3\" class=\"data row129 col3\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row129_col4\" class=\"data row129 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row130\" class=\"row_heading level0 row130\" >130</th>\n",
       "      <td id=\"T_f69d3_row130_col0\" class=\"data row130 col0\" >Hey! I'm happy to connect with you.</td>\n",
       "      <td id=\"T_f69d3_row130_col1\" class=\"data row130 col1\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row130_col2\" class=\"data row130 col2\" >produce the utterance_type. We see the user starting the conversation with a friendly greeting, expressing happiness, and indicating a desire to connect.</td>\n",
       "      <td id=\"T_f69d3_row130_col3\" class=\"data row130 col3\" >greetings</td>\n",
       "      <td id=\"T_f69d3_row130_col4\" class=\"data row130 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row131\" class=\"row_heading level0 row131\" >131</th>\n",
       "      <td id=\"T_f69d3_row131_col0\" class=\"data row131 col0\" >I’ve thought about it, and I’m not interested.</td>\n",
       "      <td id=\"T_f69d3_row131_col1\" class=\"data row131 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row131_col2\" class=\"data row131 col2\" >produce the utterance type. We see that the user is expressing a lack of interest in something. This indicates that the utterance falls under the...</td>\n",
       "      <td id=\"T_f69d3_row131_col3\" class=\"data row131 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row131_col4\" class=\"data row131 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row132\" class=\"row_heading level0 row132\" >132</th>\n",
       "      <td id=\"T_f69d3_row132_col0\" class=\"data row132 col0\" >Worked at a call center for 2 years, helping customers with account setups and troubleshooting issues.</td>\n",
       "      <td id=\"T_f69d3_row132_col1\" class=\"data row132 col1\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row132_col2\" class=\"data row132 col2\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row132_col3\" class=\"data row132 col3\" >qa_1</td>\n",
       "      <td id=\"T_f69d3_row132_col4\" class=\"data row132 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row133\" class=\"row_heading level0 row133\" >133</th>\n",
       "      <td id=\"T_f69d3_row133_col0\" class=\"data row133 col0\" >Hi! What's the company's stance on sustainability?</td>\n",
       "      <td id=\"T_f69d3_row133_col1\" class=\"data row133 col1\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row133_col2\" class=\"data row133 col2\" >produce the utterance_type. We see that the user starts with a greeting \"Hi!\" and then asks about the company's stance on sustainability. This indicates that...</td>\n",
       "      <td id=\"T_f69d3_row133_col3\" class=\"data row133 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row133_col4\" class=\"data row133 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row134\" class=\"row_heading level0 row134\" >134</th>\n",
       "      <td id=\"T_f69d3_row134_col0\" class=\"data row134 col0\" >Good morning! I'm running a bit behind schedule today. Can we continue this conversation later?</td>\n",
       "      <td id=\"T_f69d3_row134_col1\" class=\"data row134 col1\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row134_col2\" class=\"data row134 col2\" >produce the utterance_type. We see that the user starts with a greeting ('Good morning!') which indicates a 'greetings' type. Then, the user mentions being behind...</td>\n",
       "      <td id=\"T_f69d3_row134_col3\" class=\"data row134 col3\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row134_col4\" class=\"data row134 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row135\" class=\"row_heading level0 row135\" >135</th>\n",
       "      <td id=\"T_f69d3_row135_col0\" class=\"data row135 col0\" >I'm bored with this convo, will catch you later</td>\n",
       "      <td id=\"T_f69d3_row135_col1\" class=\"data row135 col1\" >later_continue</td>\n",
       "      <td id=\"T_f69d3_row135_col2\" class=\"data row135 col2\" >not_continue_related. We see that the user is expressing boredom with the conversation and indicating that they will leave and come back later. This does not...</td>\n",
       "      <td id=\"T_f69d3_row135_col3\" class=\"data row135 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row135_col4\" class=\"data row135 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row136\" class=\"row_heading level0 row136\" >136</th>\n",
       "      <td id=\"T_f69d3_row136_col0\" class=\"data row136 col0\" >This isn’t something I want to do, sorry.</td>\n",
       "      <td id=\"T_f69d3_row136_col1\" class=\"data row136 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row136_col2\" class=\"data row136 col2\" >not_continue_related. We can see that the user is expressing a lack of interest or willingness to do something.</td>\n",
       "      <td id=\"T_f69d3_row136_col3\" class=\"data row136 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row136_col4\" class=\"data row136 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row137\" class=\"row_heading level0 row137\" >137</th>\n",
       "      <td id=\"T_f69d3_row137_col0\" class=\"data row137 col0\" >I’m not feeling this, so I’m out.</td>\n",
       "      <td id=\"T_f69d3_row137_col1\" class=\"data row137 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_f69d3_row137_col2\" class=\"data row137 col2\" >produce the utterance type. We see that the user is expressing a lack of interest and a desire to leave the conversation.</td>\n",
       "      <td id=\"T_f69d3_row137_col3\" class=\"data row137 col3\" >out_of_scope</td>\n",
       "      <td id=\"T_f69d3_row137_col4\" class=\"data row137 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row138\" class=\"row_heading level0 row138\" >138</th>\n",
       "      <td id=\"T_f69d3_row138_col0\" class=\"data row138 col0\" >Feedback on my interview would be appreciated, thanks!</td>\n",
       "      <td id=\"T_f69d3_row138_col1\" class=\"data row138 col1\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row138_col2\" class=\"data row138 col2\" >produce the utterance_type. We see that the user is asking for feedback on their interview, showing appreciation at the end. This indicates that the user...</td>\n",
       "      <td id=\"T_f69d3_row138_col3\" class=\"data row138 col3\" >feedbacks</td>\n",
       "      <td id=\"T_f69d3_row138_col4\" class=\"data row138 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f69d3_level0_row139\" class=\"row_heading level0 row139\" >139</th>\n",
       "      <td id=\"T_f69d3_row139_col0\" class=\"data row139 col0\" >I stay professional, listen to their problems, and work towards a quick resolution.</td>\n",
       "      <td id=\"T_f69d3_row139_col1\" class=\"data row139 col1\" >qa_3</td>\n",
       "      <td id=\"T_f69d3_row139_col2\" class=\"data row139 col2\" >produce the utterance_type. We see that the user is describing their approach to handling customer issues in a professional manner. This indicates a focus on...</td>\n",
       "      <td id=\"T_f69d3_row139_col3\" class=\"data row139 col3\" >company_related</td>\n",
       "      <td id=\"T_f69d3_row139_col4\" class=\"data row139 col4\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x160852050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "def validate_exact_utterance_type(example, pred, trace=None):\n",
    "    return example.utterance_type.lower() == pred.utterance_type.lower()\n",
    "\n",
    "\n",
    "NUM_THREADS = 1\n",
    "trainset, devset = train_test_split(examples, train_size=0.6, random_state=42)\n",
    "\n",
    "evaluate = Evaluate( devset=devset, metric=validate_exact_utterance_type, num_threads=NUM_THREADS, display_progress=True, display_table=True)\n",
    "evaluate(UtteranceClassificator(), devset=devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 114 / 210  (54.3): 100%|██████████| 210/210 [00:53<00:00,  3.93it/s]\n",
      "Average Metric: 62 / 78  (79.5):  37%|███▋      | 78/210 [00:19<00:28,  4.60it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55998, Requested 4096. Please try again in 94ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 63 / 79  (79.7):  38%|███▊      | 79/210 [00:19<00:37,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 70 / 88  (79.5):  41%|████▏     | 87/210 [00:22<00:44,  2.74it/s]INFO:backoff:Backing off request(...) for 1.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58489, Requested 4096. Please try again in 2.585s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 74 / 93  (79.6):  44%|████▍     | 93/210 [00:25<00:57,  2.03it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56374, Requested 4096. Please try again in 469ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 77 / 98  (78.6):  47%|████▋     | 98/210 [00:29<01:23,  1.34it/s]INFO:backoff:Backing off request(...) for 1.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59675, Requested 4096. Please try again in 3.771s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 78 / 99  (78.8):  47%|████▋     | 99/210 [00:29<01:15,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 84 / 108  (77.8):  51%|█████▏    | 108/210 [00:37<01:34,  1.08it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56545, Requested 4096. Please try again in 641ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 84 / 109  (77.1):  52%|█████▏    | 109/210 [00:37<01:16,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58082, Requested 4096. Please try again in 2.178s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 85 / 111  (76.6):  53%|█████▎    | 111/210 [00:39<01:25,  1.15it/s]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57508, Requested 4096. Please try again in 1.604s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 86 / 112  (76.8):  53%|█████▎    | 112/210 [00:40<01:21,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 86 / 113  (76.1):  54%|█████▍    | 113/210 [00:41<01:21,  1.19it/s]INFO:backoff:Backing off request(...) for 1.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55975, Requested 4096. Please try again in 71ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 86 / 114  (75.4):  54%|█████▍    | 114/210 [00:42<01:20,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 87 / 115  (75.7):  55%|█████▍    | 115/210 [00:43<01:22,  1.15it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57485, Requested 4096. Please try again in 1.581s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 88 / 116  (75.9):  55%|█████▌    | 116/210 [00:43<01:21,  1.15it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56413, Requested 4096. Please try again in 509ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 3.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59874, Requested 4096. Please try again in 3.97s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 95 / 126  (75.4):  60%|██████    | 126/210 [00:52<00:56,  1.48it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56819, Requested 4096. Please try again in 915ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 2.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56774, Requested 4096. Please try again in 870ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 96 / 127  (75.6):  60%|██████    | 127/210 [00:53<00:59,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 97 / 128  (75.8):  61%|██████    | 128/210 [00:54<01:08,  1.21it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56396, Requested 4096. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 98 / 130  (75.4):  62%|██████▏   | 130/210 [00:56<01:14,  1.07it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56355, Requested 4096. Please try again in 451ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 99 / 131  (75.6):  62%|██████▏   | 131/210 [00:57<00:57,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 100 / 133  (75.2):  63%|██████▎   | 133/210 [00:58<00:47,  1.62it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56403, Requested 4096. Please try again in 499ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 101 / 134  (75.4):  64%|██████▍   | 134/210 [00:59<00:58,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56387, Requested 4096. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 4.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56404, Requested 4096. Please try again in 500ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.4 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 101 / 135  (74.8):  64%|██████▍   | 135/210 [01:00<01:10,  1.07it/s]INFO:backoff:Backing off request(...) for 1.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56411, Requested 4096. Please try again in 506ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 103 / 137  (75.2):  65%|██████▌   | 137/210 [01:02<01:13,  1.01s/it]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59879, Requested 4096. Please try again in 3.975s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 106 / 142  (74.6):  68%|██████▊   | 142/210 [01:05<00:50,  1.34it/s]INFO:backoff:Backing off request(...) for 3.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55928, Requested 4096. Please try again in 24ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55914, Requested 4096. Please try again in 10ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.5 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 110 / 147  (74.8):  70%|███████   | 147/210 [01:09<00:50,  1.25it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56974, Requested 4096. Please try again in 1.07s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 111 / 148  (75.0):  70%|███████   | 148/210 [01:10<00:51,  1.21it/s]INFO:backoff:Backing off request(...) for 1.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56957, Requested 4096. Please try again in 1.053s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 115 / 154  (74.7):  73%|███████▎  | 154/210 [01:14<00:43,  1.30it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56994, Requested 4096. Please try again in 1.09s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56962, Requested 4096. Please try again in 1.058s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 118 / 157  (75.2):  75%|███████▍  | 157/210 [01:17<00:48,  1.10it/s]INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56419, Requested 4096. Please try again in 515ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56433, Requested 4096. Please try again in 529ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 1.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56299, Requested 4096. Please try again in 395ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 125 / 164  (76.2):  78%|███████▊  | 164/210 [01:22<00:35,  1.29it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58021, Requested 4096. Please try again in 2.117s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 126 / 166  (75.9):  79%|███████▉  | 166/210 [01:24<00:33,  1.32it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58371, Requested 4096. Please try again in 2.467s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 128 / 169  (75.7):  80%|████████  | 169/210 [01:27<00:33,  1.21it/s]INFO:backoff:Backing off request(...) for 1.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58086, Requested 4096. Please try again in 2.182s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 128 / 171  (74.9):  81%|████████▏ | 171/210 [01:28<00:33,  1.18it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56497, Requested 4096. Please try again in 593ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56486, Requested 4096. Please try again in 582ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 128 / 172  (74.4):  82%|████████▏ | 172/210 [01:29<00:33,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 132 / 178  (74.2):  85%|████████▍ | 178/210 [01:34<00:27,  1.17it/s]INFO:backoff:Backing off request(...) for 2.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57474, Requested 4096. Please try again in 1.57s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 133 / 179  (74.3):  85%|████████▌ | 179/210 [01:36<00:31,  1.01s/it]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56448, Requested 4096. Please try again in 544ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 134 / 181  (74.0):  86%|████████▌ | 181/210 [01:37<00:28,  1.03it/s]INFO:backoff:Backing off request(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58922, Requested 4096. Please try again in 3.018s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56916, Requested 4096. Please try again in 1.011s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 135 / 182  (74.2):  87%|████████▋ | 182/210 [01:38<00:25,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 141 / 189  (74.6):  90%|█████████ | 189/210 [01:44<00:16,  1.28it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56936, Requested 4096. Please try again in 1.032s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 142 / 190  (74.7):  90%|█████████ | 190/210 [01:45<00:17,  1.14it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59461, Requested 4096. Please try again in 3.557s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 143 / 191  (74.9):  91%|█████████ | 191/210 [01:46<00:13,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 144 / 193  (74.6):  92%|█████████▏| 193/210 [01:47<00:13,  1.30it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56377, Requested 4096. Please try again in 472ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 145 / 194  (74.7):  92%|█████████▏| 194/210 [01:48<00:12,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 145 / 196  (74.0):  93%|█████████▎| 196/210 [01:49<00:10,  1.30it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56906, Requested 4096. Please try again in 1.002s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 146 / 197  (74.1):  94%|█████████▍| 197/210 [01:50<00:07,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 147 / 199  (73.9):  95%|█████████▍| 199/210 [01:51<00:07,  1.41it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56385, Requested 4096. Please try again in 481ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 148 / 200  (74.0):  95%|█████████▌| 200/210 [01:52<00:08,  1.25it/s]INFO:backoff:Backing off request(...) for 3.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57448, Requested 4096. Please try again in 1.544s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.1 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 148 / 202  (73.3):  96%|█████████▌| 202/210 [01:53<00:04,  1.62it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56437, Requested 4096. Please try again in 533ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 148 / 203  (72.9):  97%|█████████▋| 203/210 [01:54<00:04,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 149 / 204  (73.0):  97%|█████████▋| 204/210 [01:55<00:04,  1.32it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58018, Requested 4096. Please try again in 2.114s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 150 / 207  (72.5):  99%|█████████▊| 207/210 [01:59<00:02,  1.03it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56361, Requested 4096. Please try again in 457ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 151 / 210  (71.9): 100%|██████████| 210/210 [02:01<00:00,  1.72it/s]\n",
      "  3%|▎         | 7/210 [00:00<00:00, 1999.33it/s]\n",
      "Average Metric: 4 / 4  (100.0):   2%|▏         | 4/210 [00:02<02:12,  1.56it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57244, Requested 4096. Please try again in 1.34s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57197, Requested 4096. Please try again in 1.293s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5 / 5  (100.0):   2%|▏         | 5/210 [00:03<02:29,  1.37it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57240, Requested 4096. Please try again in 1.336s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 8 / 8  (100.0):   4%|▍         | 8/210 [00:05<02:22,  1.42it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57215, Requested 4096. Please try again in 1.311s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 1.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57216, Requested 4096. Please try again in 1.312s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 9 / 9  (100.0):   4%|▍         | 9/210 [00:05<02:07,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57209, Requested 4096. Please try again in 1.305s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 16 / 16  (100.0):   8%|▊         | 16/210 [00:10<02:10,  1.48it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57929, Requested 4096. Please try again in 2.025s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 17 / 17  (100.0):   8%|▊         | 17/210 [00:10<02:01,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57937, Requested 4096. Please try again in 2.033s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 1.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57941, Requested 4096. Please try again in 2.037s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 1.4 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 25 / 26  (96.2):  12%|█▏        | 26/210 [00:16<01:41,  1.82it/s] INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58636, Requested 4096. Please try again in 2.732s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 26 / 27  (96.3):  13%|█▎        | 27/210 [00:17<01:47,  1.70it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58584, Requested 4096. Please try again in 2.68s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 33 / 34  (97.1):  16%|█▌        | 34/210 [00:21<01:50,  1.59it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59351, Requested 4096. Please try again in 3.447s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 40 / 41  (97.6):  20%|█▉        | 41/210 [00:27<01:59,  1.41it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58660, Requested 4096. Please try again in 2.756s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 44 / 45  (97.8):  21%|██▏       | 45/210 [00:31<02:14,  1.22it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57933, Requested 4096. Please try again in 2.029s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 45 / 46  (97.8):  22%|██▏       | 46/210 [00:31<01:57,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 46 / 47  (97.9):  22%|██▏       | 47/210 [00:32<01:46,  1.53it/s]INFO:backoff:Backing off request(...) for 1.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57956, Requested 4096. Please try again in 2.052s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 47 / 48  (97.9):  23%|██▎       | 48/210 [00:33<02:01,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 49 / 50  (98.0):  24%|██▍       | 50/210 [00:34<01:41,  1.57it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58611, Requested 4096. Please try again in 2.707s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 52 / 54  (96.3):  26%|██▌       | 54/210 [00:36<01:47,  1.45it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58685, Requested 4096. Please try again in 2.781s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 53 / 55  (96.4):  26%|██▌       | 55/210 [00:37<01:40,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 57 / 59  (96.6):  28%|██▊       | 59/210 [00:39<01:38,  1.54it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59332, Requested 4096. Please try again in 3.428s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 63 / 65  (96.9):  31%|███       | 65/210 [00:43<01:32,  1.56it/s]INFO:backoff:Backing off request(...) for 2.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59389, Requested 4096. Please try again in 3.485s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 69 / 71  (97.2):  34%|███▍      | 71/210 [00:47<01:30,  1.53it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55954, Requested 4096. Please try again in 50ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 70 / 72  (97.2):  34%|███▍      | 72/210 [00:48<01:30,  1.52it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55919, Requested 4096. Please try again in 15ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 72 / 74  (97.3):  35%|███▌      | 74/210 [00:51<02:05,  1.08it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58610, Requested 4096. Please try again in 2.706s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 78 / 80  (97.5):  38%|███▊      | 80/210 [00:54<01:21,  1.59it/s]INFO:backoff:Backing off request(...) for 1.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59263, Requested 4096. Please try again in 3.359s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 79 / 81  (97.5):  39%|███▊      | 81/210 [00:55<01:20,  1.60it/s]INFO:backoff:Backing off request(...) for 1.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59329, Requested 4096. Please try again in 3.425s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 88 / 90  (97.8):  43%|████▎     | 90/210 [01:01<01:15,  1.59it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59349, Requested 4096. Please try again in 3.445s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 89 / 91  (97.8):  43%|████▎     | 90/210 [01:02<01:15,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 90 / 92  (97.8):  44%|████▍     | 92/210 [01:03<01:30,  1.30it/s]INFO:backoff:Backing off request(...) for 3.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59389, Requested 4096. Please try again in 3.485s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.6 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 91 / 93  (97.8):  44%|████▍     | 93/210 [01:03<01:29,  1.31it/s]INFO:backoff:Backing off request(...) for 2.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59399, Requested 4096. Please try again in 3.495s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 99 / 101  (98.0):  48%|████▊     | 101/210 [01:09<01:18,  1.39it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59378, Requested 4096. Please try again in 3.474s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 105 / 107  (98.1):  51%|█████     | 107/210 [01:13<01:16,  1.34it/s]INFO:backoff:Backing off request(...) for 5.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59389, Requested 4096. Please try again in 3.485s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 2.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59307, Requested 4096. Please try again in 3.403s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.6 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 2.0 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 110 / 112  (98.2):  53%|█████▎    | 112/210 [01:17<01:11,  1.37it/s]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59336, Requested 4096. Please try again in 3.432s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 116 / 120  (96.7):  57%|█████▋    | 120/210 [01:22<01:09,  1.29it/s]INFO:backoff:Backing off request(...) for 9.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59379, Requested 4096. Please try again in 3.475s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 117 / 121  (96.7):  58%|█████▊    | 121/210 [01:23<01:03,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 9.4 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 119 / 123  (96.7):  59%|█████▊    | 123/210 [01:26<01:20,  1.08it/s]INFO:backoff:Backing off request(...) for 6.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58607, Requested 4096. Please try again in 2.703s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.2 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 120 / 125  (96.0):  60%|█████▉    | 125/210 [01:27<01:03,  1.35it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58624, Requested 4096. Please try again in 2.72s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 121 / 126  (96.0):  60%|██████    | 126/210 [01:27<00:55,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 128 / 134  (95.5):  64%|██████▍   | 134/210 [01:33<00:55,  1.36it/s]INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58677, Requested 4096. Please try again in 2.773s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 134 / 141  (95.0):  67%|██████▋   | 141/210 [01:37<00:38,  1.79it/s]INFO:backoff:Backing off request(...) for 27.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59395, Requested 4096. Please try again in 3.491s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 135 / 142  (95.1):  68%|██████▊   | 142/210 [01:38<00:37,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 27.8 seconds after 6 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 137 / 144  (95.1):  69%|██████▊   | 144/210 [01:41<01:14,  1.13s/it]INFO:backoff:Backing off request(...) for 2.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57948, Requested 4096. Please try again in 2.044s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 138 / 145  (95.2):  69%|██████▉   | 145/210 [01:41<01:02,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 143 / 150  (95.3):  71%|███████▏  | 150/210 [01:44<00:38,  1.57it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58689, Requested 4096. Please try again in 2.785s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 144 / 151  (95.4):  72%|███████▏  | 151/210 [01:45<00:36,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 149 / 156  (95.5):  74%|███████▍  | 156/210 [01:50<00:53,  1.01it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57956, Requested 4096. Please try again in 2.052s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 151 / 158  (95.6):  75%|███████▌  | 158/210 [01:51<00:45,  1.14it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57949, Requested 4096. Please try again in 2.045s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 157 / 164  (95.7):  78%|███████▊  | 164/210 [01:55<00:29,  1.56it/s]INFO:backoff:Backing off request(...) for 1.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58554, Requested 4096. Please try again in 2.65s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 162 / 170  (95.3):  81%|████████  | 170/210 [02:00<00:33,  1.19it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57981, Requested 4096. Please try again in 2.077s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 164 / 172  (95.3):  82%|████████▏ | 172/210 [02:01<00:28,  1.31it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57978, Requested 4096. Please try again in 2.074s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 178 / 186  (95.7):  89%|████████▊ | 186/210 [02:10<00:12,  1.86it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59333, Requested 4096. Please try again in 3.429s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 179 / 187  (95.7):  89%|████████▉ | 187/210 [02:10<00:12,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 183 / 192  (95.3):  91%|█████████▏| 192/210 [02:13<00:11,  1.60it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55982, Requested 4096. Please try again in 78ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 185 / 194  (95.4):  92%|█████████▏| 194/210 [02:15<00:10,  1.49it/s]INFO:backoff:Backing off request(...) for 1.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59877, Requested 4096. Please try again in 3.972s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 186 / 195  (95.4):  93%|█████████▎| 195/210 [02:16<00:10,  1.48it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55948, Requested 4096. Please try again in 44ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 191 / 200  (95.5):  95%|█████████▌| 200/210 [02:20<00:08,  1.23it/s]INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58656, Requested 4096. Please try again in 2.752s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 194 / 204  (95.1):  97%|█████████▋| 204/210 [02:23<00:03,  1.67it/s]INFO:backoff:Backing off request(...) for 3.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59317, Requested 4096. Please try again in 3.413s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.6 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 200 / 210  (95.2): 100%|██████████| 210/210 [02:29<00:00,  1.40it/s]\n",
      "  2%|▏         | 4/210 [00:03<02:47,  1.23it/s]\n",
      "Average Metric: 2 / 2  (100.0):   1%|          | 2/210 [00:01<02:27,  1.41it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56524, Requested 4096. Please try again in 620ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56538, Requested 4096. Please try again in 634ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56495, Requested 4096. Please try again in 591ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 4  (75.0):   2%|▏         | 4/210 [00:03<02:48,  1.22it/s] INFO:backoff:Backing off request(...) for 1.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56529, Requested 4096. Please try again in 625ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56506, Requested 4096. Please try again in 602ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 5  (80.0):   2%|▏         | 5/210 [00:04<02:52,  1.19it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56532, Requested 4096. Please try again in 628ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59891, Requested 4096. Please try again in 3.986s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 5 / 6  (83.3):   3%|▎         | 6/210 [00:04<02:56,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 6 / 7  (85.7):   3%|▎         | 7/210 [00:05<02:38,  1.28it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56524, Requested 4096. Please try again in 620ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 7 / 8  (87.5):   4%|▍         | 8/210 [00:06<02:38,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 8 / 9  (88.9):   4%|▍         | 9/210 [00:07<02:31,  1.33it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56536, Requested 4096. Please try again in 632ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 14 / 15  (93.3):   7%|▋         | 15/210 [00:11<02:15,  1.44it/s]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56512, Requested 4096. Please try again in 608ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 6.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56051, Requested 4096. Please try again in 147ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56025, Requested 4096. Please try again in 121ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.7 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 23 / 27  (85.2):  13%|█▎        | 27/210 [00:19<02:04,  1.47it/s]INFO:backoff:Backing off request(...) for 12.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56534, Requested 4096. Please try again in 630ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 12.6 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55993, Requested 4096. Please try again in 89ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 24 / 28  (85.7):  13%|█▎        | 28/210 [00:20<02:06,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 25 / 29  (86.2):  14%|█▍        | 29/210 [00:21<02:08,  1.40it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59801, Requested 4096. Please try again in 3.896s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 26 / 30  (86.7):  14%|█▍        | 30/210 [00:22<02:25,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 31 / 36  (86.1):  17%|█▋        | 36/210 [00:26<02:02,  1.42it/s]INFO:backoff:Backing off request(...) for 2.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56041, Requested 4096. Please try again in 137ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 37 / 42  (88.1):  20%|██        | 42/210 [00:30<01:39,  1.69it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56522, Requested 4096. Please try again in 618ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 38 / 43  (88.4):  20%|██        | 43/210 [00:31<01:46,  1.56it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56515, Requested 4096. Please try again in 611ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 39 / 46  (84.8):  22%|██▏       | 46/210 [00:33<01:53,  1.45it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56561, Requested 4096. Please try again in 657ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 41 / 49  (83.7):  23%|██▎       | 49/210 [00:35<01:48,  1.48it/s]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56036, Requested 4096. Please try again in 132ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 42 / 50  (84.0):  24%|██▍       | 50/210 [00:36<01:44,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 45 / 53  (84.9):  25%|██▌       | 53/210 [00:38<01:44,  1.51it/s]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56011, Requested 4096. Please try again in 107ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 45 / 54  (83.3):  26%|██▌       | 54/210 [00:39<01:35,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 51 / 61  (83.6):  29%|██▉       | 61/210 [00:44<01:37,  1.53it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56056, Requested 4096. Please try again in 152ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 52 / 62  (83.9):  30%|██▉       | 62/210 [00:45<01:40,  1.47it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56063, Requested 4096. Please try again in 159ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 54 / 64  (84.4):  30%|███       | 64/210 [00:46<01:38,  1.48it/s]INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59897, Requested 4096. Please try again in 3.993s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 54 / 65  (83.1):  31%|███       | 65/210 [00:47<01:47,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 57 / 68  (83.8):  32%|███▏      | 68/210 [00:49<01:38,  1.44it/s]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56070, Requested 4096. Please try again in 166ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 57 / 69  (82.6):  33%|███▎      | 69/210 [00:50<01:40,  1.40it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59878, Requested 4096. Please try again in 3.974s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 63 / 76  (82.9):  36%|███▌      | 76/210 [00:55<01:25,  1.56it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59924, Requested 4096. Please try again in 4.02s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59890, Requested 4096. Please try again in 3.986s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 69 / 85  (81.2):  40%|████      | 85/210 [01:03<01:52,  1.11it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58707, Requested 4096. Please try again in 2.803s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58683, Requested 4096. Please try again in 2.779s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 77 / 94  (81.9):  45%|████▍     | 94/210 [01:08<01:10,  1.65it/s]INFO:backoff:Backing off request(...) for 1.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56503, Requested 4096. Please try again in 599ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 77 / 95  (81.1):  45%|████▌     | 95/210 [01:08<01:13,  1.56it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56478, Requested 4096. Please try again in 574ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 80 / 98  (81.6):  47%|████▋     | 98/210 [01:11<01:20,  1.39it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56049, Requested 4096. Please try again in 145ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59896, Requested 4096. Please try again in 3.992s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 81 / 99  (81.8):  47%|████▋     | 99/210 [01:12<01:22,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 82 / 100  (82.0):  48%|████▊     | 100/210 [01:12<01:16,  1.44it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59872, Requested 4096. Please try again in 3.968s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 82 / 101  (81.2):  48%|████▊     | 101/210 [01:13<01:20,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 87 / 106  (82.1):  50%|█████     | 106/210 [01:17<01:20,  1.30it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56100, Requested 4096. Please try again in 196ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 89 / 108  (82.4):  51%|█████▏    | 108/210 [01:18<01:08,  1.50it/s]INFO:backoff:Backing off request(...) for 2.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56078, Requested 4096. Please try again in 174ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 90 / 109  (82.6):  52%|█████▏    | 109/210 [01:19<01:08,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 93 / 112  (83.0):  53%|█████▎    | 112/210 [01:21<01:10,  1.39it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56039, Requested 4096. Please try again in 135ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 96 / 115  (83.5):  55%|█████▍    | 115/210 [01:23<01:08,  1.39it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56502, Requested 4096. Please try again in 598ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 97 / 116  (83.6):  55%|█████▌    | 116/210 [01:23<01:00,  1.56it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59897, Requested 4096. Please try again in 3.993s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 98 / 117  (83.8):  55%|█████▌    | 116/210 [01:25<01:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 99 / 118  (83.9):  56%|█████▌    | 118/210 [01:25<01:04,  1.44it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56034, Requested 4096. Please try again in 130ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 103 / 124  (83.1):  59%|█████▉    | 124/210 [01:30<00:54,  1.57it/s]INFO:backoff:Backing off request(...) for 1.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56083, Requested 4096. Please try again in 179ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 103 / 125  (82.4):  60%|█████▉    | 125/210 [01:30<00:57,  1.49it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56079, Requested 4096. Please try again in 175ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 104 / 126  (82.5):  60%|██████    | 126/210 [01:31<00:53,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 105 / 127  (82.7):  60%|██████    | 127/210 [01:32<00:55,  1.50it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56423, Requested 4096. Please try again in 519ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 106 / 128  (82.8):  61%|██████    | 128/210 [01:32<00:55,  1.48it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56508, Requested 4096. Please try again in 604ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 110 / 133  (82.7):  63%|██████▎   | 133/210 [01:36<00:52,  1.46it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56517, Requested 4096. Please try again in 613ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 111 / 134  (82.8):  64%|██████▍   | 134/210 [01:37<00:58,  1.31it/s]INFO:backoff:Backing off request(...) for 2.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55993, Requested 4096. Please try again in 89ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 3.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59915, Requested 4096. Please try again in 4.011s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 113 / 137  (82.5):  65%|██████▌   | 137/210 [01:39<00:46,  1.56it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56527, Requested 4096. Please try again in 623ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 116 / 141  (82.3):  67%|██████▋   | 141/210 [01:42<00:49,  1.40it/s]INFO:backoff:Backing off request(...) for 2.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59885, Requested 4096. Please try again in 3.981s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 116 / 142  (81.7):  68%|██████▊   | 142/210 [01:43<00:51,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.9 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 117 / 144  (81.2):  69%|██████▊   | 144/210 [01:44<00:46,  1.42it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56069, Requested 4096. Please try again in 165ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 120 / 148  (81.1):  70%|███████   | 148/210 [01:47<00:44,  1.40it/s]INFO:backoff:Backing off request(...) for 8.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56511, Requested 4096. Please try again in 607ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 8.1 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 123 / 151  (81.5):  72%|███████▏  | 151/210 [01:49<00:41,  1.42it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56015, Requested 4096. Please try again in 111ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 124 / 152  (81.6):  72%|███████▏  | 152/210 [01:50<00:41,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56512, Requested 4096. Please try again in 608ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 130 / 159  (81.8):  76%|███████▌  | 159/210 [01:55<00:39,  1.29it/s]INFO:backoff:Backing off request(...) for 1.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56037, Requested 4096. Please try again in 133ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 133 / 163  (81.6):  78%|███████▊  | 163/210 [01:58<00:32,  1.46it/s]INFO:backoff:Backing off request(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56526, Requested 4096. Please try again in 622ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56531, Requested 4096. Please try again in 627ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 135 / 165  (81.8):  79%|███████▊  | 165/210 [01:59<00:33,  1.34it/s]INFO:backoff:Backing off request(...) for 29.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56064, Requested 4096. Please try again in 160ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 29.9 seconds after 6 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 136 / 167  (81.4):  80%|███████▉  | 167/210 [02:00<00:27,  1.56it/s]INFO:backoff:Backing off request(...) for 4.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56485, Requested 4096. Please try again in 581ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.7 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 142 / 175  (81.1):  83%|████████▎ | 175/210 [02:06<00:24,  1.45it/s]INFO:backoff:Backing off request(...) for 8.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56515, Requested 4096. Please try again in 611ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 8.0 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 154 / 189  (81.5):  90%|█████████ | 189/210 [02:16<00:15,  1.37it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56513, Requested 4096. Please try again in 609ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 159 / 195  (81.5):  93%|█████████▎| 195/210 [02:21<00:10,  1.40it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56021, Requested 4096. Please try again in 117ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 165 / 203  (81.3):  97%|█████████▋| 203/210 [02:26<00:04,  1.54it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56056, Requested 4096. Please try again in 152ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 166 / 204  (81.4):  97%|█████████▋| 204/210 [02:27<00:04,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 169 / 207  (81.6):  99%|█████████▊| 207/210 [02:29<00:02,  1.40it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56547, Requested 4096. Please try again in 643ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 172 / 210  (81.9): 100%|██████████| 210/210 [02:35<00:00,  1.35it/s]\n",
      "  1%|          | 2/210 [00:02<03:42,  1.07s/it]\n",
      "Average Metric: 5 / 5  (100.0):   2%|▏         | 4/210 [00:01<01:37,  2.12it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57186, Requested 4096. Please try again in 1.282s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 9 / 9  (100.0):   4%|▍         | 9/210 [00:03<01:22,  2.44it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57887, Requested 4096. Please try again in 1.983s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 10 / 10  (100.0):   5%|▍         | 10/210 [00:04<01:39,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 13 / 13  (100.0):   6%|▌         | 13/210 [00:05<01:23,  2.35it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58592, Requested 4096. Please try again in 2.688s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 14 / 14  (100.0):   7%|▋         | 14/210 [00:06<01:39,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 32 / 33  (97.0):  16%|█▌        | 33/210 [00:18<02:12,  1.34it/s] INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59883, Requested 4096. Please try again in 3.978s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 34 / 36  (94.4):  17%|█▋        | 36/210 [00:20<01:50,  1.58it/s]INFO:backoff:Backing off request(...) for 1.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56395, Requested 4096. Please try again in 491ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 53 / 55  (96.4):  26%|██▌       | 55/210 [00:34<01:56,  1.34it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55909, Requested 4096. Please try again in 5ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 63 / 67  (94.0):  32%|███▏      | 67/210 [00:42<01:32,  1.54it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59888, Requested 4096. Please try again in 3.984s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 64 / 68  (94.1):  32%|███▏      | 68/210 [00:42<01:33,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 70 / 75  (93.3):  36%|███▌      | 75/210 [00:47<01:27,  1.54it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59892, Requested 4096. Please try again in 3.987s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 70 / 76  (92.1):  36%|███▌      | 76/210 [00:48<01:32,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 78 / 84  (92.9):  40%|████      | 84/210 [00:53<01:14,  1.69it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56445, Requested 4096. Please try again in 541ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 101 / 108  (93.5):  51%|█████▏    | 108/210 [01:10<01:20,  1.27it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55960, Requested 4096. Please try again in 56ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 103 / 111  (92.8):  53%|█████▎    | 111/210 [01:12<01:02,  1.59it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55952, Requested 4096. Please try again in 48ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 105 / 113  (92.9):  54%|█████▍    | 113/210 [01:13<01:04,  1.51it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59903, Requested 4096. Please try again in 3.999s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 106 / 114  (93.0):  54%|█████▍    | 114/210 [01:14<01:04,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 119 / 128  (93.0):  61%|██████    | 128/210 [01:24<00:51,  1.61it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59877, Requested 4096. Please try again in 3.972s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 123 / 132  (93.2):  63%|██████▎   | 132/210 [01:27<00:53,  1.46it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59920, Requested 4096. Please try again in 4.016s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 124 / 133  (93.2):  63%|██████▎   | 133/210 [01:27<00:54,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 129 / 140  (92.1):  67%|██████▋   | 140/210 [01:32<00:44,  1.57it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55908, Requested 4096. Please try again in 4ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 131 / 142  (92.3):  68%|██████▊   | 142/210 [01:34<00:52,  1.29it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55905, Requested 4096. Please try again in 1ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 138 / 149  (92.6):  71%|███████   | 149/210 [01:38<00:42,  1.45it/s]INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55905, Requested 4096. Please try again in 1ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 141 / 152  (92.8):  72%|███████▏  | 152/210 [01:41<00:38,  1.49it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55913, Requested 4096. Please try again in 9ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 143 / 154  (92.9):  73%|███████▎  | 154/210 [01:42<00:32,  1.72it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59902, Requested 4096. Please try again in 3.998s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 144 / 155  (92.9):  74%|███████▍  | 155/210 [01:43<00:37,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 157 / 169  (92.9):  80%|████████  | 169/210 [01:52<00:26,  1.55it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59926, Requested 4096. Please try again in 4.022s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 159 / 171  (93.0):  81%|████████▏ | 171/210 [01:54<00:26,  1.46it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59871, Requested 4096. Please try again in 3.967s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 160 / 172  (93.0):  82%|████████▏ | 172/210 [01:54<00:26,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 170 / 182  (93.4):  87%|████████▋ | 182/210 [02:01<00:19,  1.46it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59274, Requested 4096. Please try again in 3.37s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 179 / 193  (92.7):  92%|█████████▏| 193/210 [02:09<00:10,  1.61it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59872, Requested 4096. Please try again in 3.968s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 180 / 194  (92.8):  92%|█████████▏| 194/210 [02:10<00:10,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 189 / 203  (93.1):  97%|█████████▋| 203/210 [02:16<00:05,  1.37it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55930, Requested 4096. Please try again in 26ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 190 / 204  (93.1):  97%|█████████▋| 204/210 [02:17<00:03,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 194 / 210  (92.4): 100%|██████████| 210/210 [02:24<00:00,  1.46it/s]\n",
      "  0%|          | 1/210 [00:01<03:50,  1.10s/it]\n",
      "Average Metric: 9 / 9  (100.0):   4%|▍         | 9/210 [00:04<01:14,  2.69it/s]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59121, Requested 4096. Please try again in 3.217s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 10 / 10  (100.0):   5%|▍         | 10/210 [00:04<01:20,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 16 / 16  (100.0):   8%|▊         | 16/210 [00:07<01:46,  1.83it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56337, Requested 4096. Please try again in 433ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 23 / 24  (95.8):  11%|█▏        | 24/210 [00:12<02:00,  1.55it/s] INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56373, Requested 4096. Please try again in 469ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 1.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56220, Requested 4096. Please try again in 316ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 25 / 26  (96.2):  12%|█▏        | 26/210 [00:14<01:57,  1.57it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59880, Requested 4096. Please try again in 3.976s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 32 / 33  (97.0):  16%|█▌        | 33/210 [00:18<01:49,  1.61it/s]INFO:backoff:Backing off request(...) for 2.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59876, Requested 4096. Please try again in 3.971s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 1.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59853, Requested 4096. Please try again in 3.948s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 33 / 34  (97.1):  16%|█▌        | 34/210 [00:19<02:03,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.5 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 37 / 38  (97.4):  18%|█▊        | 38/210 [00:22<01:49,  1.56it/s]INFO:backoff:Backing off request(...) for 2.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56465, Requested 4096. Please try again in 561ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 39 / 40  (97.5):  19%|█▊        | 39/210 [00:23<01:55,  1.48it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59879, Requested 4096. Please try again in 3.975s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 39 / 40  (97.5):  19%|█▉        | 40/210 [00:23<01:55,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 41 / 42  (97.6):  20%|██        | 42/210 [00:24<01:53,  1.48it/s]INFO:backoff:Backing off request(...) for 1.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56471, Requested 4096. Please try again in 567ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56455, Requested 4096. Please try again in 551ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 48 / 50  (96.0):  24%|██▍       | 50/210 [00:30<01:44,  1.53it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56311, Requested 4096. Please try again in 407ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 53 / 57  (93.0):  27%|██▋       | 57/210 [00:34<01:29,  1.71it/s]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56361, Requested 4096. Please try again in 457ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 54 / 58  (93.1):  28%|██▊       | 58/210 [00:35<01:27,  1.74it/s]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56401, Requested 4096. Please try again in 497ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 61 / 65  (93.8):  31%|███       | 65/210 [00:39<01:27,  1.66it/s]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56362, Requested 4096. Please try again in 458ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 62 / 66  (93.9):  31%|███▏      | 66/210 [00:40<01:32,  1.56it/s]INFO:backoff:Backing off request(...) for 2.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56282, Requested 4096. Please try again in 378ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 64 / 68  (94.1):  32%|███▏      | 68/210 [00:41<01:26,  1.64it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56409, Requested 4096. Please try again in 504ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 67 / 72  (93.1):  34%|███▍      | 72/210 [00:44<01:27,  1.57it/s]INFO:backoff:Backing off request(...) for 7.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56446, Requested 4096. Please try again in 542ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.7 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 70 / 75  (93.3):  36%|███▌      | 75/210 [00:46<01:27,  1.55it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56312, Requested 4096. Please try again in 408ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 72 / 77  (93.5):  37%|███▋      | 77/210 [00:48<01:30,  1.48it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59894, Requested 4096. Please try again in 3.99s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 73 / 78  (93.6):  37%|███▋      | 78/210 [00:48<01:30,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 77 / 82  (93.9):  39%|███▉      | 82/210 [00:51<01:23,  1.53it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56461, Requested 4096. Please try again in 557ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 79 / 84  (94.0):  40%|███▉      | 83/210 [00:52<01:18,  1.61it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56464, Requested 4096. Please try again in 560ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 79 / 84  (94.0):  40%|████      | 84/210 [00:52<01:25,  1.48it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56341, Requested 4096. Please try again in 437ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 81 / 86  (94.2):  41%|████      | 86/210 [00:53<01:18,  1.59it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56489, Requested 4096. Please try again in 585ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56450, Requested 4096. Please try again in 546ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 87 / 93  (93.5):  44%|████▍     | 93/210 [00:59<01:37,  1.19it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59795, Requested 4096. Please try again in 3.891s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 4.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59758, Requested 4096. Please try again in 3.854s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 4.1 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 90 / 96  (93.8):  46%|████▌     | 96/210 [01:00<01:07,  1.69it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56429, Requested 4096. Please try again in 525ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 97 / 104  (93.3):  50%|████▉     | 104/210 [01:05<01:07,  1.56it/s]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59787, Requested 4096. Please try again in 3.883s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 98 / 105  (93.3):  50%|█████     | 105/210 [01:06<01:14,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 100 / 107  (93.5):  51%|█████     | 107/210 [01:07<01:10,  1.45it/s]INFO:backoff:Backing off request(...) for 7.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56283, Requested 4096. Please try again in 379ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.5 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 105 / 113  (92.9):  54%|█████▍    | 113/210 [01:11<01:03,  1.53it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56376, Requested 4096. Please try again in 471ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 111 / 120  (92.5):  57%|█████▋    | 120/210 [01:16<00:56,  1.59it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56326, Requested 4096. Please try again in 422ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 112 / 121  (92.6):  58%|█████▊    | 121/210 [01:17<00:59,  1.49it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56446, Requested 4096. Please try again in 542ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 115 / 125  (92.0):  60%|█████▉    | 125/210 [01:19<00:56,  1.49it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56320, Requested 4096. Please try again in 416ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 118 / 129  (91.5):  61%|██████▏   | 129/210 [01:22<00:50,  1.60it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59900, Requested 4096. Please try again in 3.996s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 119 / 130  (91.5):  62%|██████▏   | 130/210 [01:23<00:54,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 122 / 133  (91.7):  63%|██████▎   | 133/210 [01:24<00:46,  1.64it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56285, Requested 4096. Please try again in 381ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 123 / 134  (91.8):  64%|██████▍   | 134/210 [01:25<00:48,  1.58it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56457, Requested 4096. Please try again in 553ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 127 / 138  (92.0):  66%|██████▌   | 138/210 [01:28<00:49,  1.46it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56298, Requested 4096. Please try again in 394ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 130 / 141  (92.2):  67%|██████▋   | 141/210 [01:30<00:46,  1.50it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56329, Requested 4096. Please try again in 425ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 134 / 145  (92.4):  69%|██████▉   | 145/210 [01:32<00:41,  1.55it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59847, Requested 4096. Please try again in 3.943s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 135 / 146  (92.5):  70%|██████▉   | 146/210 [01:33<00:45,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 136 / 148  (91.9):  70%|███████   | 148/210 [01:34<00:40,  1.54it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59884, Requested 4096. Please try again in 3.979s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 137 / 149  (91.9):  71%|███████   | 149/210 [01:35<00:41,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 139 / 151  (92.1):  72%|███████▏  | 151/210 [01:36<00:34,  1.69it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56480, Requested 4096. Please try again in 576ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 140 / 152  (92.1):  72%|███████▏  | 152/210 [01:37<00:36,  1.58it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56442, Requested 4096. Please try again in 538ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 147 / 159  (92.5):  76%|███████▌  | 159/210 [01:42<00:33,  1.54it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56335, Requested 4096. Please try again in 431ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56325, Requested 4096. Please try again in 421ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 149 / 161  (92.5):  77%|███████▋  | 161/210 [01:43<00:32,  1.50it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56452, Requested 4096. Please try again in 548ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 153 / 165  (92.7):  79%|███████▊  | 165/210 [01:45<00:27,  1.66it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56492, Requested 4096. Please try again in 588ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 156 / 168  (92.9):  80%|████████  | 168/210 [01:48<00:28,  1.45it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56319, Requested 4096. Please try again in 415ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56324, Requested 4096. Please try again in 420ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 158 / 171  (92.4):  81%|████████▏ | 171/210 [01:50<00:25,  1.55it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59887, Requested 4096. Please try again in 3.983s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 159 / 172  (92.4):  82%|████████▏ | 172/210 [01:51<00:28,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 160 / 174  (92.0):  83%|████████▎ | 174/210 [01:52<00:23,  1.56it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59879, Requested 4096. Please try again in 3.975s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 161 / 175  (92.0):  83%|████████▎ | 175/210 [01:52<00:24,  1.42it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56341, Requested 4096. Please try again in 437ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 164 / 178  (92.1):  85%|████████▍ | 178/210 [01:54<00:21,  1.50it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56445, Requested 4096. Please try again in 541ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 166 / 180  (92.2):  86%|████████▌ | 180/210 [01:55<00:18,  1.59it/s]INFO:backoff:Backing off request(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56470, Requested 4096. Please try again in 566ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56436, Requested 4096. Please try again in 532ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 167 / 181  (92.3):  86%|████████▌ | 181/210 [01:56<00:18,  1.59it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56441, Requested 4096. Please try again in 537ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 168 / 182  (92.3):  87%|████████▋ | 182/210 [01:57<00:18,  1.51it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59910, Requested 4096. Please try again in 4.006s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 169 / 183  (92.3):  87%|████████▋ | 183/210 [01:58<00:18,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 170 / 184  (92.4):  88%|████████▊ | 184/210 [01:58<00:17,  1.50it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59904, Requested 4096. Please try again in 4s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 171 / 185  (92.4):  88%|████████▊ | 185/210 [01:59<00:17,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 174 / 188  (92.6):  90%|████████▉ | 188/210 [02:01<00:14,  1.56it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56456, Requested 4096. Please try again in 552ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 175 / 189  (92.6):  90%|█████████ | 189/210 [02:01<00:13,  1.54it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56355, Requested 4096. Please try again in 451ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 181 / 196  (92.3):  93%|█████████▎| 196/210 [02:06<00:09,  1.48it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56343, Requested 4096. Please try again in 439ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56286, Requested 4096. Please try again in 382ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 188 / 204  (92.2):  97%|█████████▋| 204/210 [02:11<00:03,  1.56it/s]INFO:backoff:Backing off request(...) for 1.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56338, Requested 4096. Please try again in 434ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56334, Requested 4096. Please try again in 430ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 189 / 205  (92.2):  98%|█████████▊| 205/210 [02:12<00:03,  1.51it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56460, Requested 4096. Please try again in 556ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 191 / 207  (92.3):  99%|█████████▊| 207/210 [02:13<00:02,  1.46it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56471, Requested 4096. Please try again in 567ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 194 / 210  (92.4): 100%|██████████| 210/210 [02:16<00:00,  1.54it/s]\n",
      "  1%|          | 2/210 [00:01<02:30,  1.39it/s]\n",
      "Average Metric: 7 / 7  (100.0):   3%|▎         | 7/210 [00:04<02:13,  1.52it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56370, Requested 4096. Please try again in 466ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56354, Requested 4096. Please try again in 450ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 8 / 8  (100.0):   4%|▍         | 8/210 [00:04<02:05,  1.61it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59920, Requested 4096. Please try again in 4.016s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59882, Requested 4096. Please try again in 3.978s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 9 / 9  (100.0):   4%|▍         | 9/210 [00:05<02:13,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 10 / 10  (100.0):   5%|▍         | 10/210 [00:06<02:07,  1.56it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59891, Requested 4096. Please try again in 3.986s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 13 / 13  (100.0):   6%|▌         | 13/210 [00:08<02:05,  1.57it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56449, Requested 4096. Please try again in 545ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 21 / 21  (100.0):  10%|█         | 21/210 [00:13<02:03,  1.53it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56366, Requested 4096. Please try again in 462ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 24 / 24  (100.0):  11%|█▏        | 24/210 [00:15<01:56,  1.59it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56466, Requested 4096. Please try again in 562ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 2.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56334, Requested 4096. Please try again in 430ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 26 / 26  (100.0):  12%|█▏        | 26/210 [00:16<01:59,  1.54it/s]INFO:backoff:Backing off request(...) for 1.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56447, Requested 4096. Please try again in 543ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 34 / 34  (100.0):  16%|█▌        | 34/210 [00:22<01:54,  1.53it/s]INFO:backoff:Backing off request(...) for 3.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56319, Requested 4096. Please try again in 415ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.2 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 35 / 35  (100.0):  17%|█▋        | 35/210 [00:22<01:59,  1.47it/s]INFO:backoff:Backing off request(...) for 2.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56363, Requested 4096. Please try again in 459ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.5 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 39 / 40  (97.5):  19%|█▉        | 40/210 [00:26<01:53,  1.49it/s] INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59883, Requested 4096. Please try again in 3.978s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 40 / 41  (97.6):  20%|█▉        | 41/210 [00:26<01:55,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 44 / 45  (97.8):  21%|██▏       | 45/210 [00:30<02:21,  1.17it/s]INFO:backoff:Backing off request(...) for 7.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59764, Requested 4096. Please try again in 3.86s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 45 / 46  (97.8):  22%|██▏       | 46/210 [00:30<01:50,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.5 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 47 / 48  (97.9):  23%|██▎       | 48/210 [00:31<01:38,  1.65it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56312, Requested 4096. Please try again in 408ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 59 / 62  (95.2):  30%|██▉       | 62/210 [00:40<01:38,  1.50it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56347, Requested 4096. Please try again in 443ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 61 / 64  (95.3):  30%|███       | 64/210 [00:42<01:34,  1.55it/s]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59773, Requested 4096. Please try again in 3.869s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 62 / 65  (95.4):  31%|███       | 65/210 [00:42<01:43,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 64 / 67  (95.5):  32%|███▏      | 67/210 [00:44<01:30,  1.58it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59908, Requested 4096. Please try again in 4.004s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 64 / 68  (94.1):  32%|███▏      | 68/210 [00:44<01:34,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 65 / 69  (94.2):  33%|███▎      | 69/210 [00:46<02:05,  1.12it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59124, Requested 4096. Please try again in 3.22s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 66 / 71  (93.0):  34%|███▍      | 71/210 [00:46<01:24,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 71 / 76  (93.4):  36%|███▌      | 76/210 [00:49<01:19,  1.69it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56451, Requested 4096. Please try again in 547ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 73 / 79  (92.4):  38%|███▊      | 79/210 [00:51<01:21,  1.61it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56412, Requested 4096. Please try again in 508ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 76 / 82  (92.7):  39%|███▉      | 82/210 [00:53<01:19,  1.61it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59759, Requested 4096. Please try again in 3.855s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 80 / 86  (93.0):  41%|████      | 86/210 [00:56<01:19,  1.56it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56329, Requested 4096. Please try again in 425ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 85 / 91  (93.4):  43%|████▎     | 91/210 [00:59<01:18,  1.51it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56334, Requested 4096. Please try again in 430ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 86 / 92  (93.5):  44%|████▍     | 92/210 [01:00<01:18,  1.50it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59799, Requested 4096. Please try again in 3.895s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 91 / 98  (92.9):  47%|████▋     | 98/210 [01:05<01:23,  1.34it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59814, Requested 4096. Please try again in 3.91s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 92 / 99  (92.9):  47%|████▋     | 99/210 [01:05<01:11,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 94 / 101  (93.1):  48%|████▊     | 101/210 [01:06<01:06,  1.64it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56443, Requested 4096. Please try again in 539ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56361, Requested 4096. Please try again in 457ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 95 / 103  (92.2):  49%|████▉     | 103/210 [01:07<01:07,  1.59it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56457, Requested 4096. Please try again in 553ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 96 / 104  (92.3):  50%|████▉     | 104/210 [01:08<01:08,  1.55it/s]INFO:backoff:Backing off request(...) for 1.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56448, Requested 4096. Please try again in 544ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 101 / 110  (91.8):  52%|█████▏    | 110/210 [01:12<01:05,  1.54it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59853, Requested 4096. Please try again in 3.948s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 103 / 112  (92.0):  53%|█████▎    | 112/210 [01:14<01:10,  1.40it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59808, Requested 4096. Please try again in 3.903s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 104 / 113  (92.0):  54%|█████▍    | 113/210 [01:14<01:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 109 / 118  (92.4):  56%|█████▌    | 118/210 [01:17<00:56,  1.64it/s]INFO:backoff:Backing off request(...) for 1.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59896, Requested 4096. Please try again in 3.992s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 110 / 119  (92.4):  57%|█████▋    | 119/210 [01:18<00:59,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 111 / 120  (92.5):  57%|█████▋    | 120/210 [01:19<00:55,  1.62it/s]INFO:backoff:Backing off request(...) for 2.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56352, Requested 4096. Please try again in 448ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 117 / 127  (92.1):  60%|██████    | 127/210 [01:23<00:55,  1.48it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56362, Requested 4096. Please try again in 458ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 119 / 130  (91.5):  62%|██████▏   | 130/210 [01:25<00:51,  1.56it/s]INFO:backoff:Backing off request(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56340, Requested 4096. Please try again in 436ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 123 / 135  (91.1):  64%|██████▍   | 135/210 [01:29<00:48,  1.53it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56335, Requested 4096. Please try again in 431ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 128 / 140  (91.4):  67%|██████▋   | 140/210 [01:32<00:43,  1.60it/s]INFO:backoff:Backing off request(...) for 4.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56350, Requested 4096. Please try again in 446ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.1 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 129 / 141  (91.5):  67%|██████▋   | 141/210 [01:33<00:43,  1.58it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59792, Requested 4096. Please try again in 3.888s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 130 / 142  (91.5):  68%|██████▊   | 142/210 [01:33<00:46,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 131 / 143  (91.6):  68%|██████▊   | 143/210 [01:34<00:42,  1.59it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59865, Requested 4096. Please try again in 3.961s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 132 / 144  (91.7):  69%|██████▊   | 144/210 [01:35<00:45,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 145 / 158  (91.8):  75%|███████▌  | 158/210 [01:44<00:34,  1.51it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56359, Requested 4096. Please try again in 455ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 146 / 159  (91.8):  76%|███████▌  | 159/210 [01:45<00:33,  1.50it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56357, Requested 4096. Please try again in 453ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 153 / 166  (92.2):  79%|███████▉  | 166/210 [01:49<00:27,  1.58it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56338, Requested 4096. Please try again in 434ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56280, Requested 4096. Please try again in 376ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 159 / 173  (91.9):  82%|████████▏ | 173/210 [01:54<00:22,  1.67it/s]INFO:backoff:Backing off request(...) for 1.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56337, Requested 4096. Please try again in 433ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 161 / 175  (92.0):  83%|████████▎ | 175/210 [01:55<00:22,  1.55it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56338, Requested 4096. Please try again in 434ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 162 / 176  (92.0):  84%|████████▍ | 176/210 [01:56<00:20,  1.69it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59781, Requested 4096. Please try again in 3.877s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 163 / 177  (92.1):  84%|████████▍ | 177/210 [01:57<00:23,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 169 / 183  (92.3):  87%|████████▋ | 183/210 [02:00<00:17,  1.51it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56334, Requested 4096. Please try again in 430ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 170 / 184  (92.4):  88%|████████▊ | 184/210 [02:01<00:16,  1.56it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56328, Requested 4096. Please try again in 424ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 171 / 185  (92.4):  88%|████████▊ | 185/210 [02:02<00:15,  1.57it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59903, Requested 4096. Please try again in 3.999s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 171 / 186  (91.9):  89%|████████▊ | 186/210 [02:03<00:16,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 175 / 192  (91.1):  91%|█████████▏| 192/210 [02:06<00:11,  1.56it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56366, Requested 4096. Please try again in 462ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59766, Requested 4096. Please try again in 3.862s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 176 / 193  (91.2):  92%|█████████▏| 193/210 [02:07<00:12,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 177 / 194  (91.2):  92%|█████████▏| 194/210 [02:08<00:10,  1.58it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59873, Requested 4096. Please try again in 3.969s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 178 / 195  (91.3):  93%|█████████▎| 195/210 [02:08<00:10,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 181 / 198  (91.4):  94%|█████████▍| 198/210 [02:11<00:07,  1.60it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59754, Requested 4096. Please try again in 3.85s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 183 / 200  (91.5):  95%|█████████▌| 200/210 [02:12<00:05,  1.97it/s]INFO:backoff:Backing off request(...) for 3.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59885, Requested 4096. Please try again in 3.981s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.3 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 184 / 201  (91.5):  96%|█████████▌| 201/210 [02:13<00:06,  1.48it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59809, Requested 4096. Please try again in 3.905s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 193 / 210  (91.9): 100%|██████████| 210/210 [02:22<00:00,  1.48it/s]\n",
      "  1%|          | 2/210 [00:01<03:10,  1.09it/s]\n",
      "Average Metric: 8 / 10  (80.0):   4%|▍         | 9/210 [00:04<01:33,  2.14it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58547, Requested 4096. Please try again in 2.643s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 9 / 11  (81.8):   5%|▌         | 11/210 [00:04<01:29,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 16 / 20  (80.0):  10%|▉         | 20/210 [00:09<01:56,  1.64it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59883, Requested 4096. Please try again in 3.978s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 16 / 21  (76.2):  10%|█         | 21/210 [00:10<01:59,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 18 / 24  (75.0):  11%|█▏        | 24/210 [00:12<02:03,  1.51it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56380, Requested 4096. Please try again in 476ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 19 / 25  (76.0):  12%|█▏        | 25/210 [00:12<01:54,  1.61it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56483, Requested 4096. Please try again in 579ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 20 / 26  (76.9):  12%|█▏        | 26/210 [00:13<01:59,  1.54it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56474, Requested 4096. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56469, Requested 4096. Please try again in 565ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 21 / 29  (72.4):  14%|█▍        | 29/210 [00:15<02:02,  1.48it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56479, Requested 4096. Please try again in 575ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 22 / 30  (73.3):  14%|█▍        | 30/210 [00:16<01:57,  1.53it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56481, Requested 4096. Please try again in 577ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 27 / 36  (75.0):  17%|█▋        | 36/210 [00:20<01:56,  1.49it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59895, Requested 4096. Please try again in 3.991s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 1.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59899, Requested 4096. Please try again in 3.994s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 28 / 37  (75.7):  18%|█▊        | 37/210 [00:21<01:59,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 34 / 44  (77.3):  21%|██        | 44/210 [00:26<01:53,  1.47it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59848, Requested 4096. Please try again in 3.944s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59838, Requested 4096. Please try again in 3.933s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 34 / 45  (75.6):  21%|██▏       | 45/210 [00:26<02:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 35 / 47  (74.5):  22%|██▏       | 47/210 [00:28<01:48,  1.50it/s]INFO:backoff:Backing off request(...) for 2.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56487, Requested 4096. Please try again in 583ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 40 / 55  (72.7):  26%|██▌       | 55/210 [00:33<01:35,  1.62it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59876, Requested 4096. Please try again in 3.971s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 41 / 58  (70.7):  28%|██▊       | 58/210 [00:35<01:40,  1.51it/s]INFO:backoff:Backing off request(...) for 5.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59909, Requested 4096. Please try again in 4.005s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.1 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 48 / 68  (70.6):  32%|███▏      | 68/210 [00:42<01:34,  1.50it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59900, Requested 4096. Please try again in 3.996s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 54 / 74  (73.0):  35%|███▌      | 74/210 [00:46<01:24,  1.61it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59833, Requested 4096. Please try again in 3.929s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 55 / 75  (73.3):  36%|███▌      | 75/210 [00:47<01:32,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 58 / 78  (74.4):  37%|███▋      | 78/210 [00:49<01:21,  1.63it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56480, Requested 4096. Please try again in 576ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 62 / 83  (74.7):  40%|███▉      | 83/210 [00:52<01:23,  1.51it/s]INFO:backoff:Backing off request(...) for 1.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56474, Requested 4096. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 64 / 85  (75.3):  40%|████      | 84/210 [00:54<01:56,  1.08it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59777, Requested 4096. Please try again in 3.873s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 66 / 88  (75.0):  42%|████▏     | 88/210 [00:55<01:16,  1.59it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56479, Requested 4096. Please try again in 575ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 69 / 91  (75.8):  43%|████▎     | 91/210 [00:58<01:37,  1.22it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59754, Requested 4096. Please try again in 3.85s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 73 / 95  (76.8):  45%|████▌     | 95/210 [01:00<01:05,  1.75it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56473, Requested 4096. Please try again in 569ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 76 / 98  (77.6):  47%|████▋     | 98/210 [01:02<01:11,  1.56it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56467, Requested 4096. Please try again in 563ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 77 / 99  (77.8):  47%|████▋     | 99/210 [01:03<01:09,  1.59it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59899, Requested 4096. Please try again in 3.994s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 6.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59789, Requested 4096. Please try again in 3.885s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 6.2 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 93 / 119  (78.2):  57%|█████▋    | 119/210 [01:17<00:52,  1.75it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56458, Requested 4096. Please try again in 554ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 103 / 133  (77.4):  63%|██████▎   | 133/210 [01:26<00:49,  1.55it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59765, Requested 4096. Please try again in 3.861s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 111 / 144  (77.1):  69%|██████▊   | 144/210 [01:34<00:45,  1.44it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59279, Requested 4096. Please try again in 3.375s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59208, Requested 4096. Please try again in 3.304s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 111 / 145  (76.6):  69%|██████▉   | 145/210 [01:35<00:56,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 122 / 157  (77.7):  75%|███████▍  | 157/210 [01:43<00:32,  1.62it/s]INFO:backoff:Backing off request(...) for 3.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59905, Requested 4096. Please try again in 4.001s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 122 / 158  (77.2):  75%|███████▌  | 158/210 [01:43<00:28,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 125 / 162  (77.2):  77%|███████▋  | 162/210 [01:46<00:29,  1.61it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59242, Requested 4096. Please try again in 3.338s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 126 / 163  (77.3):  78%|███████▊  | 163/210 [01:48<00:41,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 131 / 170  (77.1):  81%|████████  | 170/210 [01:52<00:25,  1.55it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59907, Requested 4096. Please try again in 4.002s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 133 / 173  (76.9):  82%|████████▏ | 172/210 [01:54<00:41,  1.10s/it]INFO:backoff:Backing off request(...) for 7.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59222, Requested 4096. Please try again in 3.318s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.6 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 141 / 183  (77.0):  87%|████████▋ | 183/210 [02:00<00:15,  1.78it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59878, Requested 4096. Please try again in 3.974s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 145 / 188  (77.1):  90%|████████▉ | 188/210 [02:04<00:14,  1.55it/s]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56491, Requested 4096. Please try again in 587ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 148 / 195  (75.9):  93%|█████████▎| 195/210 [02:09<00:10,  1.47it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59871, Requested 4096. Please try again in 3.967s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 149 / 196  (76.0):  93%|█████████▎| 196/210 [02:09<00:09,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 151 / 199  (75.9):  95%|█████████▍| 199/210 [02:11<00:07,  1.47it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56452, Requested 4096. Please try again in 548ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 152 / 200  (76.0):  95%|█████████▌| 200/210 [02:12<00:06,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 153 / 202  (75.7):  96%|█████████▌| 202/210 [02:13<00:05,  1.45it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59243, Requested 4096. Please try again in 3.339s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 155 / 204  (76.0):  97%|█████████▋| 203/210 [02:15<00:06,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 161 / 210  (76.7): 100%|██████████| 210/210 [02:22<00:00,  1.48it/s]\n",
      "  2%|▏         | 4/210 [00:03<03:21,  1.02it/s]\n",
      "Average Metric: 5 / 8  (62.5):   4%|▍         | 8/210 [00:03<01:27,  2.32it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59213, Requested 4096. Please try again in 3.309s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 15 / 21  (71.4):  10%|█         | 21/210 [00:10<02:00,  1.57it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56439, Requested 4096. Please try again in 535ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 16 / 22  (72.7):  10%|█         | 22/210 [00:11<02:17,  1.37it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59787, Requested 4096. Please try again in 3.883s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 16 / 23  (69.6):  11%|█         | 23/210 [00:12<02:10,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 20 / 28  (71.4):  13%|█▎        | 28/210 [00:15<02:01,  1.50it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59879, Requested 4096. Please try again in 3.975s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 21 / 29  (72.4):  14%|█▍        | 29/210 [00:16<02:05,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 26 / 35  (74.3):  17%|█▋        | 35/210 [00:20<01:49,  1.60it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59886, Requested 4096. Please try again in 3.982s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59868, Requested 4096. Please try again in 3.963s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 27 / 36  (75.0):  17%|█▋        | 36/210 [00:21<02:07,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 30 / 40  (75.0):  19%|█▉        | 40/210 [00:23<01:50,  1.54it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56460, Requested 4096. Please try again in 556ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 37 / 48  (77.1):  23%|██▎       | 48/210 [00:29<01:20,  2.01it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56444, Requested 4096. Please try again in 540ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59844, Requested 4096. Please try again in 3.94s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 38 / 49  (77.6):  23%|██▎       | 49/210 [00:30<01:42,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 43 / 56  (76.8):  27%|██▋       | 56/210 [00:34<01:28,  1.75it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56428, Requested 4096. Please try again in 524ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 1.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56392, Requested 4096. Please try again in 487ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 44 / 57  (77.2):  27%|██▋       | 57/210 [00:35<01:44,  1.47it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56515, Requested 4096. Please try again in 611ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 47 / 60  (78.3):  29%|██▊       | 60/210 [00:37<01:41,  1.48it/s]INFO:backoff:Backing off request(...) for 1.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56447, Requested 4096. Please try again in 543ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 49 / 63  (77.8):  30%|███       | 63/210 [00:39<01:51,  1.32it/s]INFO:backoff:Backing off request(...) for 1.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59787, Requested 4096. Please try again in 3.883s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 50 / 64  (78.1):  30%|███       | 64/210 [00:40<01:44,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 52 / 69  (75.4):  33%|███▎      | 69/210 [00:43<01:20,  1.74it/s]INFO:backoff:Backing off request(...) for 2.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56483, Requested 4096. Please try again in 579ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.1 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 53 / 70  (75.7):  33%|███▎      | 70/210 [00:43<01:15,  1.85it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56451, Requested 4096. Please try again in 547ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 54 / 72  (75.0):  34%|███▍      | 72/210 [00:45<01:35,  1.44it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56503, Requested 4096. Please try again in 599ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 55 / 73  (75.3):  35%|███▍      | 73/210 [00:46<01:40,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 3.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59926, Requested 4096. Please try again in 4.022s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 56 / 74  (75.7):  35%|███▌      | 74/210 [00:47<01:41,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.2 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 61 / 80  (76.2):  38%|███▊      | 80/210 [00:51<01:26,  1.50it/s]INFO:backoff:Backing off request(...) for 6.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56444, Requested 4096. Please try again in 540ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56376, Requested 4096. Please try again in 471ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.3 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 66 / 86  (76.7):  41%|████      | 86/210 [00:54<01:17,  1.61it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56459, Requested 4096. Please try again in 555ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 67 / 87  (77.0):  41%|████▏     | 87/210 [00:55<01:22,  1.50it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56458, Requested 4096. Please try again in 554ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 67 / 88  (76.1):  42%|████▏     | 88/210 [00:56<01:17,  1.57it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59867, Requested 4096. Please try again in 3.963s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 68 / 89  (76.4):  42%|████▏     | 89/210 [00:57<01:28,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 70 / 91  (76.9):  43%|████▎     | 91/210 [00:58<01:09,  1.71it/s]INFO:backoff:Backing off request(...) for 3.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56481, Requested 4096. Please try again in 577ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.1 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 71 / 92  (77.2):  44%|████▍     | 92/210 [00:58<01:15,  1.57it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56503, Requested 4096. Please try again in 599ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56484, Requested 4096. Please try again in 580ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 73 / 94  (77.7):  45%|████▍     | 94/210 [01:00<01:20,  1.44it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59882, Requested 4096. Please try again in 3.978s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 75 / 96  (78.1):  46%|████▌     | 96/210 [01:01<01:14,  1.53it/s]INFO:backoff:Backing off request(...) for 10.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59923, Requested 4096. Please try again in 4.019s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 76 / 97  (78.4):  46%|████▌     | 97/210 [01:02<01:17,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 10.1 seconds after 6 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 86 / 110  (78.2):  52%|█████▏    | 110/210 [01:11<00:58,  1.72it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56474, Requested 4096. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 87 / 111  (78.4):  53%|█████▎    | 111/210 [01:11<00:55,  1.77it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56473, Requested 4096. Please try again in 569ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 89 / 113  (78.8):  54%|█████▍    | 113/210 [01:13<01:00,  1.60it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56501, Requested 4096. Please try again in 597ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 89 / 114  (78.1):  54%|█████▍    | 114/210 [01:13<01:04,  1.50it/s]INFO:backoff:Backing off request(...) for 41.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56480, Requested 4096. Please try again in 576ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 41.0 seconds after 7 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 91 / 116  (78.4):  55%|█████▌    | 116/210 [01:15<01:07,  1.40it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56516, Requested 4096. Please try again in 612ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56490, Requested 4096. Please try again in 586ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 97 / 124  (78.2):  59%|█████▉    | 124/210 [01:20<01:00,  1.42it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56453, Requested 4096. Please try again in 549ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 102 / 130  (78.5):  62%|██████▏   | 130/210 [01:25<00:56,  1.41it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59894, Requested 4096. Please try again in 3.99s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 108 / 137  (78.8):  65%|██████▌   | 137/210 [01:29<00:45,  1.60it/s]INFO:backoff:Backing off request(...) for 1.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59913, Requested 4096. Please try again in 4.009s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 109 / 138  (79.0):  66%|██████▌   | 138/210 [01:30<00:48,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 110 / 141  (78.0):  67%|██████▋   | 141/210 [01:32<00:39,  1.77it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56478, Requested 4096. Please try again in 574ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 111 / 143  (77.6):  68%|██████▊   | 143/210 [01:33<00:47,  1.41it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56492, Requested 4096. Please try again in 588ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 114 / 146  (78.1):  70%|██████▉   | 146/210 [01:35<00:43,  1.49it/s]INFO:backoff:Backing off request(...) for 7.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56494, Requested 4096. Please try again in 590ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56481, Requested 4096. Please try again in 577ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.6 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 130 / 167  (77.8):  80%|███████▉  | 167/210 [01:50<00:26,  1.60it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59223, Requested 4096. Please try again in 3.319s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 141 / 181  (77.9):  86%|████████▌ | 181/210 [01:59<00:16,  1.74it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56492, Requested 4096. Please try again in 588ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 143 / 183  (78.1):  87%|████████▋ | 183/210 [02:01<00:16,  1.67it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56458, Requested 4096. Please try again in 554ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59895, Requested 4096. Please try again in 3.991s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 144 / 184  (78.3):  88%|████████▊ | 184/210 [02:02<00:18,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59871, Requested 4096. Please try again in 3.967s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 146 / 189  (77.2):  90%|█████████ | 189/210 [02:05<00:13,  1.62it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56482, Requested 4096. Please try again in 578ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 148 / 192  (77.1):  91%|█████████▏| 192/210 [02:07<00:11,  1.62it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56464, Requested 4096. Please try again in 560ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 2.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56455, Requested 4096. Please try again in 551ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 149 / 193  (77.2):  92%|█████████▏| 193/210 [02:07<00:11,  1.47it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56433, Requested 4096. Please try again in 529ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 156 / 202  (77.2):  96%|█████████▌| 202/210 [02:13<00:04,  1.64it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56491, Requested 4096. Please try again in 587ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56475, Requested 4096. Please try again in 571ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 159 / 206  (77.2):  98%|█████████▊| 206/210 [02:16<00:02,  1.54it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56446, Requested 4096. Please try again in 542ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 160 / 210  (76.2): 100%|██████████| 210/210 [02:21<00:00,  1.49it/s]\n",
      "  0%|          | 1/210 [00:01<03:46,  1.08s/it]\n",
      "Average Metric: 12 / 13  (92.3):   6%|▌         | 13/210 [00:06<01:53,  1.73it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59750, Requested 4096. Please try again in 3.846s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59713, Requested 4096. Please try again in 3.809s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 18 / 21  (85.7):  10%|█         | 21/210 [00:11<01:52,  1.68it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59768, Requested 4096. Please try again in 3.864s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56326, Requested 4096. Please try again in 422ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 19 / 22  (86.4):  10%|█         | 22/210 [00:12<01:59,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 23 / 28  (82.1):  13%|█▎        | 28/210 [00:16<01:51,  1.64it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59734, Requested 4096. Please try again in 3.83s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 28 / 35  (80.0):  17%|█▋        | 35/210 [00:21<01:39,  1.76it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59907, Requested 4096. Please try again in 4.002s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 29 / 36  (80.6):  17%|█▋        | 36/210 [00:21<01:46,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 31 / 41  (75.6):  20%|█▉        | 41/210 [00:25<01:49,  1.54it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59793, Requested 4096. Please try again in 3.888s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 32 / 42  (76.2):  20%|██        | 42/210 [00:25<01:46,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59807, Requested 4096. Please try again in 3.903s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 32 / 43  (74.4):  20%|██        | 43/210 [00:26<01:49,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 37 / 50  (74.0):  24%|██▍       | 50/210 [00:31<01:47,  1.49it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59805, Requested 4096. Please try again in 3.901s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 38 / 51  (74.5):  24%|██▍       | 51/210 [00:31<01:46,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 41 / 55  (74.5):  26%|██▌       | 55/210 [00:34<01:35,  1.63it/s]INFO:backoff:Backing off request(...) for 1.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59764, Requested 4096. Please try again in 3.86s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 42 / 56  (75.0):  27%|██▋       | 56/210 [00:34<01:42,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 44 / 58  (75.9):  28%|██▊       | 58/210 [00:36<01:38,  1.54it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59749, Requested 4096. Please try again in 3.845s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 49 / 65  (75.4):  30%|███       | 64/210 [00:40<01:35,  1.53it/s]INFO:backoff:Backing off request(...) for 3.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56320, Requested 4096. Please try again in 416ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 49 / 65  (75.4):  31%|███       | 65/210 [00:40<01:34,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 50 / 67  (74.6):  32%|███▏      | 67/210 [00:42<01:33,  1.53it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56345, Requested 4096. Please try again in 441ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 54 / 73  (74.0):  34%|███▍      | 72/210 [00:46<01:35,  1.44it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59790, Requested 4096. Please try again in 3.886s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 62 / 81  (76.5):  39%|███▊      | 81/210 [00:51<01:31,  1.41it/s]INFO:backoff:Backing off request(...) for 2.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59732, Requested 4096. Please try again in 3.827s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.4 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 67 / 87  (77.0):  41%|████▏     | 87/210 [00:55<01:16,  1.61it/s]INFO:backoff:Backing off request(...) for 3.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59899, Requested 4096. Please try again in 3.994s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 76 / 97  (78.4):  46%|████▌     | 97/210 [01:02<01:13,  1.54it/s]INFO:backoff:Backing off request(...) for 8.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59741, Requested 4096. Please try again in 3.837s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 8.7 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 77 / 99  (77.8):  47%|████▋     | 98/210 [01:03<01:25,  1.30it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59745, Requested 4096. Please try again in 3.841s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 78 / 100  (78.0):  48%|████▊     | 100/210 [01:03<01:07,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 82 / 107  (76.6):  51%|█████     | 107/210 [01:08<01:01,  1.68it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59854, Requested 4096. Please try again in 3.949s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 83 / 108  (76.9):  51%|█████▏    | 108/210 [01:09<01:06,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 89 / 116  (76.7):  55%|█████▌    | 116/210 [01:14<01:00,  1.56it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56360, Requested 4096. Please try again in 456ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 90 / 117  (76.9):  56%|█████▌    | 117/210 [01:15<01:07,  1.37it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59813, Requested 4096. Please try again in 3.909s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 91 / 118  (77.1):  56%|█████▌    | 118/210 [01:15<01:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 92 / 122  (75.4):  58%|█████▊    | 122/210 [01:18<00:56,  1.55it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59778, Requested 4096. Please try again in 3.873s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 93 / 125  (74.4):  60%|█████▉    | 125/210 [01:20<00:52,  1.63it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56326, Requested 4096. Please try again in 422ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 97 / 130  (74.6):  62%|██████▏   | 130/210 [01:23<00:50,  1.59it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59895, Requested 4096. Please try again in 3.991s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 98 / 131  (74.8):  62%|██████▏   | 131/210 [01:24<00:51,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 99 / 132  (75.0):  63%|██████▎   | 132/210 [01:25<00:51,  1.52it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56278, Requested 4096. Please try again in 374ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 104 / 138  (75.4):  66%|██████▌   | 138/210 [01:29<00:48,  1.48it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59772, Requested 4096. Please try again in 3.868s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 104 / 139  (74.8):  66%|██████▌   | 139/210 [01:29<00:49,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59779, Requested 4096. Please try again in 3.875s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 105 / 140  (75.0):  67%|██████▋   | 140/210 [01:30<00:47,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 107 / 145  (73.8):  69%|██████▊   | 144/210 [01:33<00:47,  1.39it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59803, Requested 4096. Please try again in 3.899s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 107 / 146  (73.3):  70%|██████▉   | 146/210 [01:34<00:39,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 108 / 147  (73.5):  70%|███████   | 147/210 [01:35<00:42,  1.48it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59814, Requested 4096. Please try again in 3.91s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 109 / 148  (73.6):  70%|███████   | 148/210 [01:35<00:38,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 112 / 153  (73.2):  73%|███████▎  | 153/210 [01:39<00:35,  1.61it/s]INFO:backoff:Backing off request(...) for 1.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59874, Requested 4096. Please try again in 3.97s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 114 / 155  (73.5):  74%|███████▍  | 155/210 [01:40<00:35,  1.56it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56268, Requested 4096. Please try again in 364ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 117 / 161  (72.7):  77%|███████▋  | 161/210 [01:44<00:35,  1.40it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59769, Requested 4096. Please try again in 3.865s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 121 / 167  (72.5):  80%|███████▉  | 167/210 [01:48<00:27,  1.59it/s]INFO:backoff:Backing off request(...) for 1.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59771, Requested 4096. Please try again in 3.866s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 122 / 168  (72.6):  80%|████████  | 168/210 [01:49<00:26,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 123 / 173  (71.1):  82%|████████▏ | 173/210 [01:52<00:26,  1.40it/s]INFO:backoff:Backing off request(...) for 1.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59749, Requested 4096. Please try again in 3.845s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 124 / 174  (71.3):  83%|████████▎ | 174/210 [01:52<00:20,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 126 / 176  (71.6):  84%|████████▍ | 176/210 [01:54<00:22,  1.53it/s]INFO:backoff:Backing off request(...) for 4.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59726, Requested 4096. Please try again in 3.822s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 127 / 177  (71.8):  84%|████████▍ | 177/210 [01:54<00:20,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.3 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 132 / 182  (72.5):  87%|████████▋ | 182/210 [01:58<00:19,  1.46it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59755, Requested 4096. Please try again in 3.85s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 132 / 183  (72.1):  87%|████████▋ | 183/210 [01:58<00:17,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 135 / 189  (71.4):  90%|█████████ | 189/210 [02:02<00:12,  1.65it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59837, Requested 4096. Please try again in 3.933s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 135 / 190  (71.1):  90%|█████████ | 190/210 [02:03<00:13,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 136 / 192  (70.8):  91%|█████████ | 191/210 [02:04<00:14,  1.28it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56357, Requested 4096. Please try again in 453ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 140 / 196  (71.4):  93%|█████████▎| 196/210 [02:07<00:09,  1.51it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59740, Requested 4096. Please try again in 3.835s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 141 / 197  (71.6):  94%|█████████▍| 197/210 [02:08<00:08,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 141 / 199  (70.9):  95%|█████████▍| 199/210 [02:09<00:06,  1.63it/s]INFO:backoff:Backing off request(...) for 2.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59787, Requested 4096. Please try again in 3.883s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 142 / 200  (71.0):  95%|█████████▌| 200/210 [02:10<00:06,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.5 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 145 / 204  (71.1):  97%|█████████▋| 204/210 [02:12<00:03,  1.64it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56345, Requested 4096. Please try again in 441ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 151 / 210  (71.9): 100%|██████████| 210/210 [02:18<00:00,  1.51it/s]\n",
      "  2%|▏         | 4/210 [00:03<03:18,  1.04it/s]\n",
      "Average Metric: 5 / 6  (83.3):   3%|▎         | 6/210 [00:02<01:16,  2.67it/s] INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58669, Requested 4096. Please try again in 2.765s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58651, Requested 4096. Please try again in 2.747s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 11 / 12  (91.7):   6%|▌         | 12/210 [00:05<01:48,  1.82it/s]INFO:backoff:Backing off request(...) for 1.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59789, Requested 4096. Please try again in 3.885s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 16 / 20  (80.0):  10%|▉         | 20/210 [00:11<02:10,  1.46it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56017, Requested 4096. Please try again in 113ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 18 / 24  (75.0):  11%|█▏        | 24/210 [00:14<02:09,  1.44it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56497, Requested 4096. Please try again in 593ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 19 / 26  (73.1):  12%|█▏        | 26/210 [00:15<02:09,  1.42it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55968, Requested 4096. Please try again in 64ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 20 / 27  (74.1):  13%|█▎        | 27/210 [00:16<02:10,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59886, Requested 4096. Please try again in 3.982s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 21 / 28  (75.0):  13%|█▎        | 28/210 [00:16<02:11,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 22 / 29  (75.9):  14%|█▍        | 29/210 [00:17<01:58,  1.52it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59900, Requested 4096. Please try again in 3.996s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 23 / 30  (76.7):  14%|█▍        | 30/210 [00:18<02:12,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 24 / 31  (77.4):  15%|█▍        | 31/210 [00:19<02:15,  1.33it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56008, Requested 4096. Please try again in 104ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 28 / 36  (77.8):  17%|█▋        | 36/210 [00:22<02:03,  1.41it/s]INFO:backoff:Backing off request(...) for 1.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55981, Requested 4096. Please try again in 77ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 30 / 38  (78.9):  18%|█▊        | 38/210 [00:24<02:02,  1.40it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56002, Requested 4096. Please try again in 98ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 35 / 44  (79.5):  21%|██        | 44/210 [00:28<01:52,  1.47it/s]INFO:backoff:Backing off request(...) for 1.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56095, Requested 4096. Please try again in 191ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 36 / 45  (80.0):  21%|██▏       | 45/210 [00:29<01:50,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56016, Requested 4096. Please try again in 112ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 42 / 53  (79.2):  25%|██▌       | 53/210 [00:34<01:49,  1.44it/s]INFO:backoff:Backing off request(...) for 2.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56028, Requested 4096. Please try again in 124ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.3 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 44 / 57  (77.2):  27%|██▋       | 57/210 [00:37<01:43,  1.48it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55976, Requested 4096. Please try again in 72ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 49 / 63  (77.8):  30%|███       | 63/210 [00:41<01:35,  1.54it/s]INFO:backoff:Backing off request(...) for 5.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56072, Requested 4096. Please try again in 168ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56049, Requested 4096. Please try again in 145ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.3 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 56 / 70  (80.0):  33%|███▎      | 70/210 [00:47<01:45,  1.33it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55996, Requested 4096. Please try again in 92ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 57 / 71  (80.3):  34%|███▍      | 71/210 [00:47<01:35,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 62 / 77  (80.5):  37%|███▋      | 77/210 [00:51<01:30,  1.47it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56001, Requested 4096. Please try again in 97ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 63 / 78  (80.8):  37%|███▋      | 78/210 [00:52<01:36,  1.36it/s]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55986, Requested 4096. Please try again in 82ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 64 / 79  (81.0):  38%|███▊      | 79/210 [00:53<01:26,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59876, Requested 4096. Please try again in 3.971s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 71 / 86  (82.6):  41%|████      | 86/210 [00:58<01:20,  1.53it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56542, Requested 4096. Please try again in 638ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 73 / 88  (83.0):  42%|████▏     | 88/210 [00:59<01:26,  1.41it/s]INFO:backoff:Backing off request(...) for 1.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56132, Requested 4096. Please try again in 228ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 76 / 91  (83.5):  43%|████▎     | 91/210 [01:01<01:22,  1.44it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56469, Requested 4096. Please try again in 565ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 77 / 92  (83.7):  44%|████▍     | 92/210 [01:02<01:23,  1.41it/s]INFO:backoff:Backing off request(...) for 4.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55966, Requested 4096. Please try again in 62ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 78 / 93  (83.9):  44%|████▍     | 93/210 [01:03<01:21,  1.43it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56472, Requested 4096. Please try again in 568ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.4 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 85 / 101  (84.2):  48%|████▊     | 101/210 [01:09<01:26,  1.26it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55967, Requested 4096. Please try again in 62ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 90 / 106  (84.9):  50%|█████     | 106/210 [01:12<01:10,  1.48it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56063, Requested 4096. Please try again in 159ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 91 / 107  (85.0):  51%|█████     | 107/210 [01:13<01:07,  1.53it/s]INFO:backoff:Backing off request(...) for 1.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59921, Requested 4096. Please try again in 4.016s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 92 / 108  (85.2):  51%|█████▏    | 108/210 [01:14<01:10,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 93 / 110  (84.5):  52%|█████▏    | 110/210 [01:15<01:07,  1.49it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59913, Requested 4096. Please try again in 4.009s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59875, Requested 4096. Please try again in 3.971s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 101 / 118  (85.6):  56%|█████▌    | 118/210 [01:21<00:52,  1.76it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56025, Requested 4096. Please try again in 121ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 103 / 122  (84.4):  58%|█████▊    | 122/210 [01:24<00:56,  1.55it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56486, Requested 4096. Please try again in 582ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 104 / 123  (84.6):  59%|█████▊    | 123/210 [01:25<00:57,  1.52it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59885, Requested 4096. Please try again in 3.981s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 104 / 124  (83.9):  59%|█████▉    | 124/210 [01:25<01:01,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 105 / 125  (84.0):  60%|█████▉    | 125/210 [01:26<01:01,  1.39it/s]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56017, Requested 4096. Please try again in 113ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 108 / 129  (83.7):  61%|██████▏   | 129/210 [01:29<00:58,  1.38it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59374, Requested 4096. Please try again in 3.47s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 111 / 132  (84.1):  63%|██████▎   | 132/210 [01:31<00:54,  1.44it/s]INFO:backoff:Backing off request(...) for 6.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59913, Requested 4096. Please try again in 4.009s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 112 / 133  (84.2):  63%|██████▎   | 133/210 [01:32<00:44,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.0 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 115 / 137  (83.9):  65%|██████▌   | 137/210 [01:35<00:46,  1.58it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56027, Requested 4096. Please try again in 123ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 119 / 144  (82.6):  69%|██████▊   | 144/210 [01:40<00:47,  1.40it/s]INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56063, Requested 4096. Please try again in 159ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 121 / 146  (82.9):  70%|██████▉   | 146/210 [01:42<01:04,  1.01s/it]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59403, Requested 4096. Please try again in 3.499s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 128 / 153  (83.7):  73%|███████▎  | 153/210 [01:46<00:33,  1.70it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56521, Requested 4096. Please try again in 617ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 129 / 154  (83.8):  73%|███████▎  | 154/210 [01:47<00:35,  1.59it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56517, Requested 4096. Please try again in 613ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 132 / 157  (84.1):  75%|███████▍  | 157/210 [01:49<00:40,  1.30it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55987, Requested 4096. Please try again in 83ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 133 / 158  (84.2):  75%|███████▌  | 158/210 [01:50<00:35,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 137 / 162  (84.6):  77%|███████▋  | 162/210 [01:53<00:32,  1.48it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56028, Requested 4096. Please try again in 124ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 138 / 164  (84.1):  78%|███████▊  | 164/210 [01:54<00:31,  1.44it/s]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55999, Requested 4096. Please try again in 95ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 139 / 165  (84.2):  79%|███████▊  | 165/210 [01:55<00:30,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 142 / 169  (84.0):  80%|████████  | 169/210 [01:58<00:29,  1.37it/s]INFO:backoff:Backing off request(...) for 1.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56031, Requested 4096. Please try again in 127ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 144 / 172  (83.7):  82%|████████▏ | 172/210 [02:00<00:25,  1.47it/s]INFO:backoff:Backing off request(...) for 2.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55974, Requested 4096. Please try again in 70ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 144 / 173  (83.2):  82%|████████▏ | 173/210 [02:00<00:25,  1.44it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56510, Requested 4096. Please try again in 606ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 152 / 181  (84.0):  86%|████████▌ | 181/210 [02:06<00:20,  1.44it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55992, Requested 4096. Please try again in 88ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 7.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55965, Requested 4096. Please try again in 60ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 7.3 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 163 / 194  (84.0):  92%|█████████▏| 194/210 [02:16<00:10,  1.49it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55996, Requested 4096. Please try again in 92ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 164 / 195  (84.1):  93%|█████████▎| 195/210 [02:16<00:09,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59888, Requested 4096. Please try again in 3.984s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 165 / 196  (84.2):  93%|█████████▎| 196/210 [02:17<00:09,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 165 / 198  (83.3):  94%|█████████▍| 198/210 [02:19<00:09,  1.33it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55973, Requested 4096. Please try again in 69ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 166 / 199  (83.4):  95%|█████████▍| 199/210 [02:19<00:07,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 168 / 201  (83.6):  96%|█████████▌| 201/210 [02:20<00:05,  1.51it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56495, Requested 4096. Please try again in 591ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 169 / 203  (83.3):  97%|█████████▋| 203/210 [02:22<00:05,  1.18it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55982, Requested 4096. Please try again in 78ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 171 / 206  (83.0):  98%|█████████▊| 206/210 [02:24<00:02,  1.45it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56505, Requested 4096. Please try again in 601ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 174 / 210  (82.9): 100%|██████████| 210/210 [02:30<00:00,  1.40it/s]\n",
      "  1%|▏         | 3/210 [00:02<02:35,  1.33it/s]\n",
      "Average Metric: 10 / 10  (100.0):   5%|▍         | 10/210 [00:04<01:30,  2.22it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59290, Requested 4096. Please try again in 3.386s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 14 / 16  (87.5):   7%|▋         | 15/210 [00:08<02:13,  1.46it/s] INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55906, Requested 4096. Please try again in 2ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 16 / 18  (88.9):   9%|▊         | 18/210 [00:09<01:41,  1.90it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59893, Requested 4096. Please try again in 3.989s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 17 / 19  (89.5):   9%|▉         | 19/210 [00:10<01:52,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 21 / 26  (80.8):  12%|█▏        | 26/210 [00:15<02:03,  1.48it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56486, Requested 4096. Please try again in 582ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55913, Requested 4096. Please try again in 9ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 22 / 27  (81.5):  13%|█▎        | 27/210 [00:15<02:08,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 24 / 29  (82.8):  14%|█▍        | 29/210 [00:17<02:04,  1.45it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56485, Requested 4096. Please try again in 581ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 28 / 34  (82.4):  16%|█▌        | 34/210 [00:20<02:01,  1.45it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56494, Requested 4096. Please try again in 590ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 30 / 36  (83.3):  17%|█▋        | 36/210 [00:22<01:57,  1.48it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59801, Requested 4096. Please try again in 3.896s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 33 / 42  (78.6):  20%|██        | 42/210 [00:26<02:03,  1.36it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55934, Requested 4096. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 34 / 44  (77.3):  21%|██        | 44/210 [00:27<01:46,  1.55it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55910, Requested 4096. Please try again in 6ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59879, Requested 4096. Please try again in 3.975s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 40 / 50  (80.0):  24%|██▍       | 50/210 [00:32<02:00,  1.33it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59305, Requested 4096. Please try again in 3.401s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 41 / 52  (78.8):  24%|██▍       | 51/210 [00:33<02:21,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 45 / 58  (77.6):  28%|██▊       | 58/210 [00:37<01:42,  1.48it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59894, Requested 4096. Please try again in 3.99s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 46 / 59  (78.0):  28%|██▊       | 59/210 [00:38<01:45,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 48 / 62  (77.4):  30%|██▉       | 62/210 [00:40<01:44,  1.42it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55953, Requested 4096. Please try again in 49ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 49 / 63  (77.8):  30%|███       | 63/210 [00:41<01:37,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 51 / 65  (78.5):  31%|███       | 65/210 [00:42<01:38,  1.48it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56485, Requested 4096. Please try again in 581ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55910, Requested 4096. Please try again in 6ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 62 / 79  (78.5):  38%|███▊      | 79/210 [00:52<01:27,  1.49it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56413, Requested 4096. Please try again in 509ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 63 / 80  (78.8):  38%|███▊      | 80/210 [00:52<01:26,  1.50it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56493, Requested 4096. Please try again in 589ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 68 / 86  (79.1):  41%|████      | 86/210 [00:57<01:24,  1.47it/s]INFO:backoff:Backing off request(...) for 1.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55914, Requested 4096. Please try again in 10ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 83 / 102  (81.4):  48%|████▊     | 101/210 [01:08<01:07,  1.62it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56480, Requested 4096. Please try again in 576ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 83 / 102  (81.4):  49%|████▊     | 102/210 [01:08<01:14,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 87 / 108  (80.6):  51%|█████▏    | 108/210 [01:12<01:16,  1.33it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55918, Requested 4096. Please try again in 14ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 89 / 111  (80.2):  53%|█████▎    | 111/210 [01:14<01:12,  1.37it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55928, Requested 4096. Please try again in 24ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 96 / 120  (80.0):  57%|█████▋    | 120/210 [01:20<01:02,  1.45it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55918, Requested 4096. Please try again in 14ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 97 / 121  (80.2):  57%|█████▋    | 120/210 [01:21<01:02,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 100 / 124  (80.6):  59%|█████▉    | 124/210 [01:23<01:01,  1.40it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55923, Requested 4096. Please try again in 19ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 102 / 127  (80.3):  60%|██████    | 127/210 [01:25<01:01,  1.36it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55915, Requested 4096. Please try again in 11ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 102 / 128  (79.7):  61%|██████    | 128/210 [01:26<00:53,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 104 / 131  (79.4):  62%|██████▏   | 131/210 [01:28<00:51,  1.53it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56511, Requested 4096. Please try again in 607ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 113 / 141  (80.1):  67%|██████▋   | 141/210 [01:35<00:38,  1.79it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59939, Requested 4096. Please try again in 4.035s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 113 / 142  (79.6):  68%|██████▊   | 142/210 [01:36<00:36,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 116 / 147  (78.9):  70%|███████   | 147/210 [01:39<00:45,  1.40it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55964, Requested 4096. Please try again in 60ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 118 / 149  (79.2):  71%|███████   | 149/210 [01:41<00:37,  1.61it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55933, Requested 4096. Please try again in 29ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 124 / 155  (80.0):  74%|███████▍  | 155/210 [01:45<00:32,  1.68it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55915, Requested 4096. Please try again in 11ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 125 / 157  (79.6):  75%|███████▍  | 157/210 [01:46<00:33,  1.58it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59857, Requested 4096. Please try again in 3.953s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 126 / 158  (79.7):  75%|███████▌  | 158/210 [01:47<00:35,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 128 / 160  (80.0):  76%|███████▌  | 160/210 [01:48<00:32,  1.56it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59899, Requested 4096. Please try again in 3.994s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 129 / 161  (80.1):  77%|███████▋  | 161/210 [01:49<00:37,  1.30it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55933, Requested 4096. Please try again in 29ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 134 / 167  (80.2):  80%|███████▉  | 167/210 [01:53<00:32,  1.34it/s]INFO:backoff:Backing off request(...) for 1.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55923, Requested 4096. Please try again in 19ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 135 / 168  (80.4):  80%|████████  | 168/210 [01:54<00:26,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 137 / 170  (80.6):  81%|████████  | 170/210 [01:55<00:26,  1.48it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59901, Requested 4096. Please try again in 3.997s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 141 / 174  (81.0):  83%|████████▎ | 174/210 [01:58<00:24,  1.45it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55932, Requested 4096. Please try again in 28ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 142 / 175  (81.1):  83%|████████▎ | 175/210 [01:59<00:23,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 150 / 185  (81.1):  88%|████████▊ | 185/210 [02:05<00:15,  1.61it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56483, Requested 4096. Please try again in 579ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 151 / 186  (81.2):  89%|████████▊ | 186/210 [02:06<00:15,  1.55it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56504, Requested 4096. Please try again in 600ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 153 / 188  (81.4):  90%|████████▉ | 188/210 [02:08<00:15,  1.46it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56495, Requested 4096. Please try again in 591ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 153 / 189  (81.0):  90%|█████████ | 189/210 [02:08<00:14,  1.45it/s]INFO:backoff:Backing off request(...) for 2.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56436, Requested 4096. Please try again in 532ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 161 / 202  (79.7):  96%|█████████▌| 202/210 [02:18<00:05,  1.48it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55915, Requested 4096. Please try again in 11ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 162 / 203  (79.8):  97%|█████████▋| 203/210 [02:18<00:04,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55908, Requested 4096. Please try again in 4ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 169 / 210  (80.5): 100%|██████████| 210/210 [02:24<00:00,  1.46it/s]\n",
      "  2%|▏         | 5/210 [00:05<03:51,  1.13s/it]\n",
      "Average Metric: 6 / 8  (75.0):   4%|▍         | 8/210 [00:04<02:09,  1.56it/s] INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58971, Requested 4096. Please try again in 3.067s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 7 / 9  (77.8):   4%|▍         | 9/210 [00:05<01:54,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 10 / 13  (76.9):   6%|▌         | 13/210 [00:09<03:01,  1.09it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58164, Requested 4096. Please try again in 2.26s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 12 / 15  (80.0):   7%|▋         | 15/210 [00:11<02:58,  1.09it/s]INFO:backoff:Backing off request(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58173, Requested 4096. Please try again in 2.269s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 17 / 23  (73.9):  11%|█         | 23/210 [00:15<01:35,  1.95it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56432, Requested 4096. Please try again in 528ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 20 / 28  (71.4):  13%|█▎        | 28/210 [00:20<02:47,  1.09it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59719, Requested 4096. Please try again in 3.815s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 23 / 31  (74.2):  14%|█▍        | 30/210 [00:21<02:42,  1.11it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59728, Requested 4096. Please try again in 3.824s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 24 / 32  (75.0):  15%|█▌        | 32/210 [00:22<02:04,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 26 / 34  (76.5):  16%|█▌        | 34/210 [00:24<02:00,  1.46it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59869, Requested 4096. Please try again in 3.964s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 29 / 38  (76.3):  18%|█▊        | 38/210 [00:27<02:12,  1.30it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59768, Requested 4096. Please try again in 3.864s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 30 / 39  (76.9):  19%|█▊        | 39/210 [00:28<01:58,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 31 / 40  (77.5):  19%|█▉        | 40/210 [00:28<01:57,  1.45it/s]INFO:backoff:Backing off request(...) for 13.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59908, Requested 4096. Please try again in 4.004s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 13.9 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 36 / 46  (78.3):  22%|██▏       | 46/210 [00:33<01:55,  1.42it/s]INFO:backoff:Backing off request(...) for 3.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56455, Requested 4096. Please try again in 551ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 40 / 52  (76.9):  25%|██▍       | 52/210 [00:38<01:44,  1.51it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59904, Requested 4096. Please try again in 4s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 49 / 64  (76.6):  30%|███       | 64/210 [00:47<01:17,  1.88it/s]INFO:backoff:Backing off request(...) for 9.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59735, Requested 4096. Please try again in 3.831s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 9.8 seconds after 6 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 52 / 67  (77.6):  32%|███▏      | 67/210 [00:52<02:20,  1.01it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58196, Requested 4096. Please try again in 2.292s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 61 / 76  (80.3):  36%|███▌      | 75/210 [00:58<01:31,  1.48it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58942, Requested 4096. Please try again in 3.038s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 72 / 87  (82.8):  41%|████▏     | 87/210 [01:05<01:10,  1.75it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59898, Requested 4096. Please try again in 3.994s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 77 / 93  (82.8):  44%|████▍     | 93/210 [01:10<01:26,  1.36it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59727, Requested 4096. Please try again in 3.823s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59622, Requested 4096. Please try again in 3.718s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 82 / 100  (82.0):  48%|████▊     | 100/210 [01:20<01:43,  1.07it/s]INFO:backoff:Backing off request(...) for 2.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56447, Requested 4096. Please try again in 543ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 84 / 102  (82.4):  49%|████▊     | 102/210 [01:21<01:27,  1.24it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59888, Requested 4096. Please try again in 3.984s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 85 / 103  (82.5):  49%|████▉     | 103/210 [01:22<01:32,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 88 / 108  (81.5):  51%|█████▏    | 108/210 [01:27<01:30,  1.13it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59798, Requested 4096. Please try again in 3.894s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 89 / 109  (81.7):  52%|█████▏    | 109/210 [01:27<01:19,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 94 / 114  (82.5):  54%|█████▍    | 114/210 [01:30<00:54,  1.77it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56581, Requested 4096. Please try again in 677ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 95 / 115  (82.6):  55%|█████▍    | 115/210 [01:31<00:58,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 96 / 116  (82.8):  55%|█████▌    | 116/210 [01:32<01:16,  1.22it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56443, Requested 4096. Please try again in 539ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 102 / 123  (82.9):  59%|█████▊    | 123/210 [01:37<00:54,  1.61it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57394, Requested 4096. Please try again in 1.49s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 1.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57229, Requested 4096. Please try again in 1.325s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 106 / 128  (82.8):  60%|██████    | 127/210 [01:42<01:47,  1.29s/it]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56226, Requested 4096. Please try again in 322ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 110 / 134  (82.1):  64%|██████▍   | 134/210 [01:46<00:58,  1.30it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59716, Requested 4096. Please try again in 3.812s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 118 / 146  (80.8):  69%|██████▉   | 145/210 [01:53<00:37,  1.74it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58964, Requested 4096. Please try again in 3.06s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58889, Requested 4096. Please try again in 2.985s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 129 / 157  (82.2):  75%|███████▍  | 157/210 [02:01<00:34,  1.54it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56450, Requested 4096. Please try again in 546ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56404, Requested 4096. Please try again in 500ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 134 / 162  (82.7):  77%|███████▋  | 162/210 [02:05<00:46,  1.03it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59741, Requested 4096. Please try again in 3.837s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 136 / 164  (82.9):  78%|███████▊  | 164/210 [02:06<00:32,  1.43it/s]INFO:backoff:Backing off request(...) for 1.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56395, Requested 4096. Please try again in 491ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 139 / 168  (82.7):  80%|████████  | 168/210 [02:09<00:32,  1.29it/s]INFO:backoff:Backing off request(...) for 7.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59782, Requested 4096. Please try again in 3.878s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.7 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 140 / 169  (82.8):  80%|████████  | 169/210 [02:11<00:39,  1.03it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58173, Requested 4096. Please try again in 2.269s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 140 / 170  (82.4):  81%|████████  | 170/210 [02:13<00:50,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 147 / 181  (81.2):  86%|████████▌ | 181/210 [02:19<00:21,  1.35it/s]INFO:backoff:Backing off request(...) for 3.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56578, Requested 4096. Please try again in 674ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.7 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 148 / 182  (81.3):  87%|████████▋ | 182/210 [02:20<00:21,  1.33it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56318, Requested 4096. Please try again in 414ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 150 / 184  (81.5):  88%|████████▊ | 184/210 [02:22<00:19,  1.34it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59918, Requested 4096. Please try again in 4.014s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 151 / 185  (81.6):  88%|████████▊ | 185/210 [02:23<00:19,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 155 / 189  (82.0):  90%|█████████ | 189/210 [02:26<00:15,  1.39it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59016, Requested 4096. Please try again in 3.112s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59016, Requested 4096. Please try again in 3.112s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 156 / 191  (81.7):  91%|█████████ | 191/210 [02:28<00:14,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 158 / 194  (81.4):  92%|█████████▏| 194/210 [02:30<00:11,  1.37it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56555, Requested 4096. Please try again in 651ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 161 / 197  (81.7):  94%|█████████▍| 197/210 [02:32<00:09,  1.38it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56396, Requested 4096. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 162 / 199  (81.4):  95%|█████████▍| 199/210 [02:34<00:08,  1.35it/s]INFO:backoff:Backing off request(...) for 6.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59881, Requested 4096. Please try again in 3.977s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 163 / 200  (81.5):  95%|█████████▌| 200/210 [02:35<00:07,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.7 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59919, Requested 4096. Please try again in 4.015s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 163 / 201  (81.1):  96%|█████████▌| 201/210 [02:35<00:07,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 165 / 205  (80.5):  98%|█████████▊| 205/210 [02:40<00:05,  1.03s/it]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58955, Requested 4096. Please try again in 3.051s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 166 / 206  (80.6):  98%|█████████▊| 206/210 [02:40<00:03,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 169 / 210  (80.5): 100%|██████████| 210/210 [02:45<00:00,  1.27it/s]\n",
      "  0%|          | 1/210 [00:00<02:50,  1.23it/s]\n",
      "Average Metric: 11 / 14  (78.6):   7%|▋         | 14/210 [00:06<01:34,  2.08it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56448, Requested 4096. Please try again in 544ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 12 / 15  (80.0):   7%|▋         | 15/210 [00:06<01:46,  1.84it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56102, Requested 4096. Please try again in 198ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 18 / 22  (81.8):  10%|█         | 22/210 [00:11<01:48,  1.73it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56109, Requested 4096. Please try again in 205ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 19 / 23  (82.6):  11%|█         | 23/210 [00:11<01:48,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56427, Requested 4096. Please try again in 523ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 20 / 24  (83.3):  11%|█▏        | 24/210 [00:12<01:51,  1.68it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56060, Requested 4096. Please try again in 156ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 23 / 28  (82.1):  13%|█▎        | 28/210 [00:14<01:48,  1.68it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56407, Requested 4096. Please try again in 503ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 25 / 30  (83.3):  14%|█▍        | 30/210 [00:16<01:51,  1.61it/s]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56413, Requested 4096. Please try again in 509ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 26 / 31  (83.9):  15%|█▍        | 31/210 [00:16<01:58,  1.51it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56086, Requested 4096. Please try again in 182ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 27 / 32  (84.4):  15%|█▍        | 31/210 [00:17<01:58,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 28 / 33  (84.8):  16%|█▌        | 33/210 [00:17<01:48,  1.64it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56448, Requested 4096. Please try again in 544ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 34 / 41  (82.9):  20%|█▉        | 41/210 [00:23<01:48,  1.56it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56130, Requested 4096. Please try again in 226ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56117, Requested 4096. Please try again in 213ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 36 / 44  (81.8):  21%|██        | 44/210 [00:24<01:44,  1.58it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56433, Requested 4096. Please try again in 529ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 40 / 48  (83.3):  23%|██▎       | 48/210 [00:27<01:42,  1.59it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56076, Requested 4096. Please try again in 172ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 45 / 53  (84.9):  25%|██▌       | 53/210 [00:30<01:37,  1.61it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56093, Requested 4096. Please try again in 189ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 47 / 56  (83.9):  27%|██▋       | 56/210 [00:32<01:31,  1.69it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56413, Requested 4096. Please try again in 509ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 47 / 57  (82.5):  27%|██▋       | 57/210 [00:33<01:30,  1.69it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56105, Requested 4096. Please try again in 201ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 48 / 58  (82.8):  28%|██▊       | 58/210 [00:33<01:35,  1.60it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56421, Requested 4096. Please try again in 517ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 49 / 59  (83.1):  28%|██▊       | 59/210 [00:34<01:34,  1.60it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59884, Requested 4096. Please try again in 3.979s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 49 / 60  (81.7):  29%|██▊       | 60/210 [00:35<01:38,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 50 / 61  (82.0):  29%|██▉       | 61/210 [00:35<01:30,  1.65it/s]INFO:backoff:Backing off request(...) for 1.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56434, Requested 4096. Please try again in 530ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 53 / 65  (81.5):  31%|███       | 65/210 [00:38<01:28,  1.63it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56391, Requested 4096. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 56 / 68  (82.4):  32%|███▏      | 68/210 [00:39<01:30,  1.57it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56107, Requested 4096. Please try again in 203ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59891, Requested 4096. Please try again in 3.986s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 57 / 69  (82.6):  33%|███▎      | 69/210 [00:40<01:30,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 58 / 70  (82.9):  33%|███▎      | 70/210 [00:41<01:23,  1.68it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59894, Requested 4096. Please try again in 3.99s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 59 / 71  (83.1):  34%|███▍      | 71/210 [00:41<01:28,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59878, Requested 4096. Please try again in 3.974s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 59 / 72  (81.9):  34%|███▍      | 72/210 [00:42<01:29,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 61 / 74  (82.4):  35%|███▌      | 74/210 [00:43<01:25,  1.60it/s]INFO:backoff:Backing off request(...) for 1.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56436, Requested 4096. Please try again in 532ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 65 / 78  (83.3):  37%|███▋      | 78/210 [00:46<01:19,  1.65it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56415, Requested 4096. Please try again in 511ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 66 / 79  (83.5):  38%|███▊      | 79/210 [00:46<01:22,  1.59it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56045, Requested 4096. Please try again in 141ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 67 / 80  (83.8):  38%|███▊      | 80/210 [00:47<01:19,  1.63it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56430, Requested 4096. Please try again in 526ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 74 / 88  (84.1):  42%|████▏     | 88/210 [00:52<01:15,  1.61it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56075, Requested 4096. Please try again in 171ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56053, Requested 4096. Please try again in 149ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 82 / 96  (85.4):  46%|████▌     | 96/210 [00:57<01:12,  1.57it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56039, Requested 4096. Please try again in 135ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 88 / 105  (83.8):  50%|█████     | 105/210 [01:03<00:58,  1.81it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56116, Requested 4096. Please try again in 212ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 89 / 107  (83.2):  51%|█████     | 107/210 [01:04<00:52,  1.95it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56431, Requested 4096. Please try again in 527ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 94 / 113  (83.2):  54%|█████▍    | 113/210 [01:08<01:01,  1.58it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59598, Requested 4096. Please try again in 3.694s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 95 / 114  (83.3):  54%|█████▍    | 114/210 [01:09<01:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 95 / 115  (82.6):  55%|█████▍    | 115/210 [01:09<00:50,  1.89it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56035, Requested 4096. Please try again in 131ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 97 / 118  (82.2):  56%|█████▌    | 118/210 [01:11<00:50,  1.81it/s]INFO:backoff:Backing off request(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56450, Requested 4096. Please try again in 546ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 100 / 122  (82.0):  58%|█████▊    | 122/210 [01:13<00:46,  1.87it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56056, Requested 4096. Please try again in 152ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59896, Requested 4096. Please try again in 3.992s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 101 / 123  (82.1):  59%|█████▊    | 123/210 [01:14<00:54,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 107 / 130  (82.3):  62%|██████▏   | 130/210 [01:18<00:49,  1.61it/s]INFO:backoff:Backing off request(...) for 1.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56065, Requested 4096. Please try again in 161ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 107 / 131  (81.7):  62%|██████▏   | 131/210 [01:19<00:49,  1.61it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56037, Requested 4096. Please try again in 133ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 112 / 139  (80.6):  66%|██████▌   | 139/210 [01:24<00:38,  1.83it/s]INFO:backoff:Backing off request(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56449, Requested 4096. Please try again in 545ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59866, Requested 4096. Please try again in 3.962s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 113 / 140  (80.7):  67%|██████▋   | 140/210 [01:25<00:45,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 119 / 148  (80.4):  70%|███████   | 148/210 [01:30<00:40,  1.52it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56117, Requested 4096. Please try again in 213ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56110, Requested 4096. Please try again in 206ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 126 / 155  (81.3):  74%|███████▍  | 155/210 [01:34<00:35,  1.57it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56086, Requested 4096. Please try again in 182ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59858, Requested 4096. Please try again in 3.954s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 128 / 158  (81.0):  75%|███████▌  | 158/210 [01:36<00:27,  1.86it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59890, Requested 4096. Please try again in 3.986s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 129 / 159  (81.1):  76%|███████▌  | 159/210 [01:37<00:31,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 134 / 164  (81.7):  78%|███████▊  | 164/210 [01:40<00:27,  1.67it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56415, Requested 4096. Please try again in 511ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 137 / 168  (81.5):  80%|████████  | 168/210 [01:42<00:26,  1.59it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56077, Requested 4096. Please try again in 173ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 140 / 172  (81.4):  82%|████████▏ | 172/210 [01:45<00:23,  1.61it/s]INFO:backoff:Backing off request(...) for 2.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56084, Requested 4096. Please try again in 180ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.2 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 144 / 176  (81.8):  84%|████████▍ | 176/210 [01:47<00:19,  1.74it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59893, Requested 4096. Please try again in 3.989s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 153 / 185  (82.7):  88%|████████▊ | 185/210 [01:53<00:15,  1.64it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56078, Requested 4096. Please try again in 174ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 156 / 190  (82.1):  90%|█████████ | 190/210 [01:56<00:12,  1.63it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56148, Requested 4096. Please try again in 243ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 158 / 193  (81.9):  92%|█████████▏| 193/210 [01:58<00:09,  1.70it/s]INFO:backoff:Backing off request(...) for 1.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56330, Requested 4096. Please try again in 426ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 159 / 194  (82.0):  92%|█████████▏| 194/210 [01:58<00:09,  1.60it/s]INFO:backoff:Backing off request(...) for 1.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56390, Requested 4096. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 166 / 202  (82.2):  96%|█████████▌| 202/210 [02:03<00:04,  1.63it/s]INFO:backoff:Backing off request(...) for 3.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56121, Requested 4096. Please try again in 217ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 167 / 203  (82.3):  97%|█████████▋| 203/210 [02:04<00:04,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 2.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56445, Requested 4096. Please try again in 541ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 170 / 207  (82.1):  99%|█████████▊| 207/210 [02:06<00:01,  1.59it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56420, Requested 4096. Please try again in 516ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 171 / 208  (82.2):  99%|█████████▉| 208/210 [02:07<00:01,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 173 / 210  (82.4): 100%|██████████| 210/210 [02:09<00:00,  1.63it/s]\n",
      "  3%|▎         | 6/210 [00:05<03:08,  1.08it/s]\n",
      "Average Metric: 7 / 7  (100.0):   3%|▎         | 7/210 [00:03<02:01,  1.67it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56573, Requested 4096. Please try again in 669ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56541, Requested 4096. Please try again in 637ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 13 / 13  (100.0):   6%|▌         | 13/210 [00:08<02:27,  1.33it/s]INFO:backoff:Backing off request(...) for 1.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56261, Requested 4096. Please try again in 357ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 14 / 14  (100.0):   7%|▋         | 14/210 [00:09<02:21,  1.38it/s]INFO:backoff:Backing off request(...) for 1.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56248, Requested 4096. Please try again in 344ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 17 / 18  (94.4):   9%|▊         | 18/210 [00:12<02:19,  1.37it/s] INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56568, Requested 4096. Please try again in 664ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 19 / 22  (86.4):  10%|█         | 22/210 [00:15<02:15,  1.39it/s]INFO:backoff:Backing off request(...) for 3.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56263, Requested 4096. Please try again in 359ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.1 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 21 / 24  (87.5):  11%|█▏        | 24/210 [00:16<02:08,  1.44it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56289, Requested 4096. Please try again in 385ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 25 / 28  (89.3):  13%|█▎        | 28/210 [00:19<02:03,  1.47it/s]INFO:backoff:Backing off request(...) for 4.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56539, Requested 4096. Please try again in 635ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.1 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 26 / 29  (89.7):  14%|█▍        | 29/210 [00:20<02:10,  1.38it/s]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56548, Requested 4096. Please try again in 644ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 32 / 35  (91.4):  17%|█▋        | 35/210 [00:25<02:01,  1.44it/s]INFO:backoff:Backing off request(...) for 13.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56579, Requested 4096. Please try again in 675ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 13.7 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 32 / 36  (88.9):  17%|█▋        | 36/210 [00:25<02:08,  1.36it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56266, Requested 4096. Please try again in 362ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 37 / 42  (88.1):  20%|██        | 42/210 [00:30<01:59,  1.41it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56320, Requested 4096. Please try again in 416ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 38 / 44  (86.4):  21%|██        | 44/210 [00:32<02:01,  1.37it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56577, Requested 4096. Please try again in 673ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 40 / 46  (87.0):  22%|██▏       | 46/210 [00:33<01:56,  1.41it/s]INFO:backoff:Backing off request(...) for 1.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56567, Requested 4096. Please try again in 663ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56577, Requested 4096. Please try again in 673ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 42 / 48  (87.5):  23%|██▎       | 48/210 [00:35<02:04,  1.30it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56548, Requested 4096. Please try again in 644ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 46 / 54  (85.2):  26%|██▌       | 54/210 [00:39<02:06,  1.23it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59659, Requested 4096. Please try again in 3.755s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 54 / 63  (85.7):  30%|███       | 63/210 [00:46<01:41,  1.45it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56541, Requested 4096. Please try again in 637ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 55 / 64  (85.9):  30%|███       | 64/210 [00:47<01:52,  1.30it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56272, Requested 4096. Please try again in 368ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 62 / 71  (87.3):  34%|███▍      | 71/210 [00:52<01:41,  1.37it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56263, Requested 4096. Please try again in 359ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 63 / 72  (87.5):  34%|███▍      | 72/210 [00:53<01:41,  1.35it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56244, Requested 4096. Please try again in 340ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59905, Requested 4096. Please try again in 4.001s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 63 / 73  (86.3):  35%|███▍      | 73/210 [00:54<01:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 66 / 77  (85.7):  37%|███▋      | 77/210 [00:57<01:38,  1.35it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56550, Requested 4096. Please try again in 646ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 67 / 78  (85.9):  37%|███▋      | 78/210 [00:57<01:45,  1.25it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56232, Requested 4096. Please try again in 328ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 74 / 85  (87.1):  40%|████      | 85/210 [01:03<01:13,  1.69it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56263, Requested 4096. Please try again in 359ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 81 / 92  (88.0):  44%|████▍     | 92/210 [01:08<01:25,  1.38it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56256, Requested 4096. Please try again in 352ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 84 / 95  (88.4):  45%|████▌     | 95/210 [01:10<01:28,  1.29it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56255, Requested 4096. Please try again in 351ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 87 / 98  (88.8):  47%|████▋     | 98/210 [01:12<01:19,  1.40it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56565, Requested 4096. Please try again in 661ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 88 / 99  (88.9):  47%|████▋     | 99/210 [01:13<01:18,  1.41it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56218, Requested 4096. Please try again in 314ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59847, Requested 4096. Please try again in 3.943s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 88 / 100  (88.0):  48%|████▊     | 100/210 [01:14<01:23,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 88 / 101  (87.1):  48%|████▊     | 101/210 [01:15<01:22,  1.32it/s]INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59889, Requested 4096. Please try again in 3.985s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 89 / 102  (87.3):  49%|████▊     | 102/210 [01:15<01:21,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 93 / 107  (86.9):  51%|█████     | 107/210 [01:19<01:18,  1.31it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56267, Requested 4096. Please try again in 363ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 95 / 109  (87.2):  52%|█████▏    | 109/210 [01:21<01:16,  1.32it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56250, Requested 4096. Please try again in 346ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 99 / 113  (87.6):  54%|█████▍    | 113/210 [01:24<01:12,  1.33it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56292, Requested 4096. Please try again in 388ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 100 / 115  (87.0):  55%|█████▍    | 115/210 [01:25<01:08,  1.39it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56316, Requested 4096. Please try again in 412ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 104 / 119  (87.4):  57%|█████▋    | 119/210 [01:28<01:06,  1.37it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56237, Requested 4096. Please try again in 333ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 107 / 122  (87.7):  58%|█████▊    | 122/210 [01:31<01:08,  1.28it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56305, Requested 4096. Please try again in 401ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 111 / 126  (88.1):  60%|██████    | 126/210 [01:34<00:59,  1.41it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56277, Requested 4096. Please try again in 373ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 112 / 127  (88.2):  60%|██████    | 127/210 [01:34<01:01,  1.35it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56554, Requested 4096. Please try again in 650ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 113 / 129  (87.6):  61%|██████▏   | 129/210 [01:36<01:00,  1.34it/s]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56193, Requested 4096. Please try again in 289ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 115 / 131  (87.8):  62%|██████▏   | 131/210 [01:38<01:00,  1.30it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59888, Requested 4096. Please try again in 3.984s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 115 / 132  (87.1):  63%|██████▎   | 132/210 [01:38<01:02,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56028, Requested 4096. Please try again in 124ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 118 / 135  (87.4):  64%|██████▍   | 135/210 [01:40<00:55,  1.36it/s]INFO:backoff:Backing off request(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56539, Requested 4096. Please try again in 635ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 121 / 138  (87.7):  66%|██████▌   | 138/210 [01:43<00:56,  1.26it/s]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56216, Requested 4096. Please try again in 312ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 126 / 143  (88.1):  68%|██████▊   | 143/210 [01:47<00:46,  1.44it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56296, Requested 4096. Please try again in 392ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 128 / 145  (88.3):  69%|██████▉   | 145/210 [01:48<00:45,  1.44it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56326, Requested 4096. Please try again in 422ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 132 / 149  (88.6):  71%|███████   | 149/210 [01:51<00:47,  1.29it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56289, Requested 4096. Please try again in 385ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 134 / 152  (88.2):  72%|███████▏  | 152/210 [01:54<00:44,  1.29it/s]INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56287, Requested 4096. Please try again in 383ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 137 / 155  (88.4):  74%|███████▍  | 155/210 [01:56<00:44,  1.25it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56265, Requested 4096. Please try again in 361ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 140 / 159  (88.1):  76%|███████▌  | 159/210 [01:59<00:36,  1.40it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56537, Requested 4096. Please try again in 633ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56263, Requested 4096. Please try again in 359ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59896, Requested 4096. Please try again in 3.992s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 141 / 160  (88.1):  76%|███████▌  | 160/210 [02:00<00:39,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 142 / 161  (88.2):  77%|███████▋  | 161/210 [02:00<00:35,  1.38it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59914, Requested 4096. Please try again in 4.009s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 143 / 162  (88.3):  77%|███████▋  | 162/210 [02:01<00:37,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 144 / 163  (88.3):  78%|███████▊  | 163/210 [02:02<00:35,  1.34it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56544, Requested 4096. Please try again in 640ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 145 / 164  (88.4):  78%|███████▊  | 164/210 [02:02<00:32,  1.43it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56582, Requested 4096. Please try again in 678ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 146 / 165  (88.5):  79%|███████▊  | 165/210 [02:03<00:34,  1.32it/s]INFO:backoff:Backing off request(...) for 1.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56572, Requested 4096. Please try again in 668ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 148 / 167  (88.6):  80%|███████▉  | 167/210 [02:05<00:32,  1.32it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56549, Requested 4096. Please try again in 645ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 149 / 168  (88.7):  80%|████████  | 168/210 [02:06<00:32,  1.31it/s]INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59924, Requested 4096. Please try again in 4.02s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59823, Requested 4096. Please try again in 3.918s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 150 / 169  (88.8):  80%|████████  | 169/210 [02:07<00:33,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 156 / 175  (89.1):  83%|████████▎ | 175/210 [02:11<00:25,  1.35it/s]INFO:backoff:Backing off request(...) for 3.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59884, Requested 4096. Please try again in 3.979s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56488, Requested 4096. Please try again in 584ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 157 / 176  (89.2):  84%|████████▍ | 176/210 [02:12<00:25,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 163 / 182  (89.6):  87%|████████▋ | 182/210 [02:16<00:20,  1.35it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56232, Requested 4096. Please try again in 328ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 165 / 184  (89.7):  88%|████████▊ | 184/210 [02:18<00:19,  1.36it/s]INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56540, Requested 4096. Please try again in 636ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 168 / 188  (89.4):  90%|████████▉ | 188/210 [02:21<00:16,  1.35it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56312, Requested 4096. Please try again in 408ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 170 / 191  (89.0):  91%|█████████ | 191/210 [02:23<00:13,  1.40it/s]INFO:backoff:Backing off request(...) for 1.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56318, Requested 4096. Please try again in 414ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 172 / 194  (88.7):  92%|█████████▏| 194/210 [02:25<00:11,  1.35it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56305, Requested 4096. Please try again in 401ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 173 / 195  (88.7):  93%|█████████▎| 195/210 [02:26<00:11,  1.33it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56464, Requested 4096. Please try again in 560ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 174 / 197  (88.3):  94%|█████████▍| 197/210 [02:28<00:09,  1.41it/s]INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56578, Requested 4096. Please try again in 674ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 175 / 198  (88.4):  94%|█████████▍| 198/210 [02:28<00:08,  1.35it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56553, Requested 4096. Please try again in 649ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 177 / 200  (88.5):  95%|█████████▌| 200/210 [02:30<00:07,  1.35it/s]INFO:backoff:Backing off request(...) for 2.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56586, Requested 4096. Please try again in 682ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56259, Requested 4096. Please try again in 355ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 179 / 202  (88.6):  96%|█████████▌| 202/210 [02:31<00:06,  1.31it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59891, Requested 4096. Please try again in 3.986s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 179 / 203  (88.2):  97%|█████████▋| 203/210 [02:32<00:05,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 180 / 204  (88.2):  97%|█████████▋| 204/210 [02:33<00:04,  1.29it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59861, Requested 4096. Please try again in 3.956s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 181 / 205  (88.3):  98%|█████████▊| 205/210 [02:34<00:04,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 182 / 206  (88.3):  98%|█████████▊| 206/210 [02:34<00:02,  1.34it/s]INFO:backoff:Backing off request(...) for 1.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59888, Requested 4096. Please try again in 3.984s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 183 / 207  (88.4):  99%|█████████▊| 207/210 [02:35<00:02,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 186 / 210  (88.6): 100%|██████████| 210/210 [02:40<00:00,  1.31it/s]\n",
      "  2%|▏         | 4/210 [00:02<02:33,  1.34it/s]\n",
      "Average Metric: 9 / 10  (90.0):   5%|▍         | 10/210 [00:04<01:30,  2.21it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56004, Requested 4096. Please try again in 100ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55995, Requested 4096. Please try again in 91ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 10 / 11  (90.9):   5%|▌         | 11/210 [00:05<01:49,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 15 / 16  (93.8):   8%|▊         | 16/210 [00:09<02:58,  1.09it/s]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59418, Requested 4096. Please try again in 3.514s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59405, Requested 4096. Please try again in 3.501s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 16 / 17  (94.1):   8%|▊         | 17/210 [00:10<02:36,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 23 / 26  (88.5):  12%|█▏        | 26/210 [00:16<02:17,  1.34it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55992, Requested 4096. Please try again in 88ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 24 / 27  (88.9):  13%|█▎        | 27/210 [00:16<01:59,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 26 / 29  (89.7):  14%|█▍        | 29/210 [00:17<01:54,  1.58it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56518, Requested 4096. Please try again in 614ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 27 / 30  (90.0):  14%|█▍        | 30/210 [00:18<02:12,  1.35it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55972, Requested 4096. Please try again in 68ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 28 / 31  (90.3):  15%|█▍        | 31/210 [00:19<02:01,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 30 / 33  (90.9):  16%|█▌        | 33/210 [00:20<02:01,  1.46it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56501, Requested 4096. Please try again in 597ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 31 / 34  (91.2):  16%|█▌        | 34/210 [00:21<02:06,  1.39it/s]INFO:backoff:Backing off request(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59899, Requested 4096. Please try again in 3.994s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59901, Requested 4096. Please try again in 3.997s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 32 / 35  (91.4):  17%|█▋        | 35/210 [00:22<02:08,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 38 / 42  (90.5):  20%|██        | 42/210 [00:27<01:59,  1.40it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56010, Requested 4096. Please try again in 106ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59878, Requested 4096. Please try again in 3.974s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59379, Requested 4096. Please try again in 3.475s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 39 / 43  (90.7):  20%|██        | 43/210 [00:28<02:34,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 42 / 46  (91.3):  22%|██▏       | 46/210 [00:30<01:50,  1.48it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56515, Requested 4096. Please try again in 611ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 46 / 50  (92.0):  24%|██▍       | 50/210 [00:33<01:50,  1.45it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56490, Requested 4096. Please try again in 586ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 48 / 52  (92.3):  25%|██▍       | 52/210 [00:34<01:48,  1.45it/s]INFO:backoff:Backing off request(...) for 1.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59886, Requested 4096. Please try again in 3.982s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 48 / 53  (90.6):  25%|██▌       | 53/210 [00:35<01:56,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56019, Requested 4096. Please try again in 115ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 50 / 56  (89.3):  27%|██▋       | 56/210 [00:37<01:42,  1.51it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56506, Requested 4096. Please try again in 602ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 51 / 57  (89.5):  27%|██▋       | 57/210 [00:37<01:38,  1.55it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56537, Requested 4096. Please try again in 633ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 52 / 58  (89.7):  28%|██▊       | 58/210 [00:38<01:49,  1.39it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56521, Requested 4096. Please try again in 617ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56507, Requested 4096. Please try again in 603ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 52 / 59  (88.1):  28%|██▊       | 59/210 [00:39<01:56,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 54 / 62  (87.1):  29%|██▉       | 61/210 [00:41<01:49,  1.36it/s]INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56523, Requested 4096. Please try again in 619ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 54 / 62  (87.1):  30%|██▉       | 62/210 [00:41<01:49,  1.35it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56495, Requested 4096. Please try again in 591ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 56 / 64  (87.5):  30%|███       | 64/210 [00:43<01:42,  1.43it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56495, Requested 4096. Please try again in 591ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 5.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59842, Requested 4096. Please try again in 3.938s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 57 / 65  (87.7):  31%|███       | 65/210 [00:44<01:53,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.0 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 62 / 71  (87.3):  34%|███▍      | 71/210 [00:48<01:32,  1.50it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56007, Requested 4096. Please try again in 103ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 68 / 78  (87.2):  37%|███▋      | 78/210 [00:53<01:24,  1.57it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56517, Requested 4096. Please try again in 613ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56482, Requested 4096. Please try again in 578ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 69 / 79  (87.3):  38%|███▊      | 79/210 [00:53<01:29,  1.47it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59899, Requested 4096. Please try again in 3.994s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 70 / 80  (87.5):  38%|███▊      | 80/210 [00:54<01:31,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 73 / 83  (88.0):  40%|███▉      | 83/210 [00:56<01:25,  1.48it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56523, Requested 4096. Please try again in 619ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56502, Requested 4096. Please try again in 598ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 74 / 84  (88.1):  40%|████      | 84/210 [00:57<01:30,  1.39it/s]INFO:backoff:Backing off request(...) for 1.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59913, Requested 4096. Please try again in 4.009s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 75 / 85  (88.2):  40%|████      | 85/210 [00:58<01:31,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55983, Requested 4096. Please try again in 79ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 76 / 86  (88.4):  41%|████      | 86/210 [00:58<01:25,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 78 / 88  (88.6):  42%|████▏     | 88/210 [01:00<01:28,  1.39it/s]INFO:backoff:Backing off request(...) for 1.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56497, Requested 4096. Please try again in 593ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 82 / 92  (89.1):  44%|████▍     | 92/210 [01:03<01:25,  1.39it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56505, Requested 4096. Please try again in 601ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 84 / 94  (89.4):  45%|████▍     | 94/210 [01:04<01:19,  1.45it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55975, Requested 4096. Please try again in 71ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 6.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59886, Requested 4096. Please try again in 3.982s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 6.6 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 88 / 98  (89.8):  47%|████▋     | 98/210 [01:07<01:11,  1.57it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56498, Requested 4096. Please try again in 594ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 95 / 106  (89.6):  50%|█████     | 106/210 [01:13<01:10,  1.48it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56024, Requested 4096. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 97 / 110  (88.2):  52%|█████▏    | 110/210 [01:16<01:09,  1.43it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56063, Requested 4096. Please try again in 159ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 103 / 117  (88.0):  56%|█████▌    | 117/210 [01:21<01:03,  1.46it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56017, Requested 4096. Please try again in 113ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 105 / 119  (88.2):  57%|█████▋    | 119/210 [01:22<01:05,  1.39it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56029, Requested 4096. Please try again in 125ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 106 / 120  (88.3):  57%|█████▋    | 120/210 [01:23<00:59,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59924, Requested 4096. Please try again in 4.02s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 110 / 124  (88.7):  59%|█████▉    | 124/210 [01:26<00:56,  1.51it/s]INFO:backoff:Backing off request(...) for 2.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56033, Requested 4096. Please try again in 129ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 110 / 125  (88.0):  60%|█████▉    | 125/210 [01:26<00:56,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 112 / 127  (88.2):  60%|██████    | 127/210 [01:28<00:57,  1.45it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56500, Requested 4096. Please try again in 596ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 114 / 130  (87.7):  62%|██████▏   | 130/210 [01:30<00:56,  1.41it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56501, Requested 4096. Please try again in 597ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 117 / 133  (88.0):  63%|██████▎   | 133/210 [01:32<00:54,  1.41it/s]INFO:backoff:Backing off request(...) for 3.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55980, Requested 4096. Please try again in 76ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.1 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 120 / 136  (88.2):  65%|██████▍   | 136/210 [01:34<00:48,  1.52it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56012, Requested 4096. Please try again in 108ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 121 / 138  (87.7):  66%|██████▌   | 138/210 [01:36<00:49,  1.46it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59905, Requested 4096. Please try again in 4.001s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 121 / 139  (87.1):  66%|██████▌   | 139/210 [01:37<00:53,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 123 / 141  (87.2):  67%|██████▋   | 141/210 [01:38<00:46,  1.47it/s]INFO:backoff:Backing off request(...) for 5.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56537, Requested 4096. Please try again in 633ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 2.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56555, Requested 4096. Please try again in 651ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56511, Requested 4096. Please try again in 607ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.8 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 127 / 145  (87.6):  69%|██████▉   | 145/210 [01:41<00:44,  1.46it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56516, Requested 4096. Please try again in 612ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 131 / 149  (87.9):  71%|███████   | 149/210 [01:43<00:41,  1.47it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59902, Requested 4096. Please try again in 3.998s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 133 / 152  (87.5):  72%|███████▏  | 152/210 [01:46<00:40,  1.43it/s]INFO:backoff:Backing off request(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56044, Requested 4096. Please try again in 140ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 134 / 153  (87.6):  73%|███████▎  | 153/210 [01:46<00:38,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 138 / 157  (87.9):  75%|███████▍  | 157/210 [01:49<00:38,  1.36it/s]INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56017, Requested 4096. Please try again in 113ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 141 / 160  (88.1):  76%|███████▌  | 160/210 [01:51<00:34,  1.43it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56530, Requested 4096. Please try again in 626ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 142 / 161  (88.2):  77%|███████▋  | 161/210 [01:52<00:35,  1.39it/s]INFO:backoff:Backing off request(...) for 2.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56519, Requested 4096. Please try again in 615ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.5 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 143 / 162  (88.3):  77%|███████▋  | 162/210 [01:53<00:34,  1.38it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56005, Requested 4096. Please try again in 101ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 144 / 163  (88.3):  78%|███████▊  | 163/210 [01:54<00:34,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 146 / 165  (88.5):  79%|███████▊  | 165/210 [01:55<00:31,  1.41it/s]INFO:backoff:Backing off request(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56523, Requested 4096. Please try again in 619ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 147 / 166  (88.6):  79%|███████▉  | 166/210 [01:56<00:31,  1.39it/s]INFO:backoff:Backing off request(...) for 5.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56525, Requested 4096. Please try again in 621ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.7 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 152 / 173  (87.9):  82%|████████▏ | 173/210 [02:01<00:23,  1.56it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56516, Requested 4096. Please try again in 612ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56451, Requested 4096. Please try again in 547ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 155 / 176  (88.1):  84%|████████▍ | 176/210 [02:03<00:21,  1.58it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56502, Requested 4096. Please try again in 598ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 7.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56502, Requested 4096. Please try again in 598ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 7.2 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 158 / 179  (88.3):  85%|████████▌ | 179/210 [02:05<00:21,  1.47it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56509, Requested 4096. Please try again in 605ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 158 / 180  (87.8):  86%|████████▌ | 180/210 [02:06<00:20,  1.45it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56513, Requested 4096. Please try again in 609ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 161 / 183  (88.0):  87%|████████▋ | 183/210 [02:08<00:18,  1.46it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56462, Requested 4096. Please try again in 558ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 164 / 186  (88.2):  89%|████████▊ | 186/210 [02:10<00:16,  1.41it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56506, Requested 4096. Please try again in 602ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55959, Requested 4096. Please try again in 55ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 164 / 187  (87.7):  89%|████████▉ | 187/210 [02:11<00:16,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 166 / 190  (87.4):  90%|█████████ | 190/210 [02:13<00:14,  1.42it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59894, Requested 4096. Please try again in 3.99s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 167 / 191  (87.4):  91%|█████████ | 191/210 [02:14<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 168 / 193  (87.0):  92%|█████████▏| 193/210 [02:15<00:10,  1.66it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56469, Requested 4096. Please try again in 565ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 169 / 194  (87.1):  92%|█████████▏| 194/210 [02:16<00:11,  1.41it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56540, Requested 4096. Please try again in 636ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 170 / 195  (87.2):  93%|█████████▎| 195/210 [02:16<00:10,  1.50it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56507, Requested 4096. Please try again in 603ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 171 / 196  (87.2):  93%|█████████▎| 196/210 [02:17<00:10,  1.28it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59878, Requested 4096. Please try again in 3.974s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 173 / 198  (87.4):  94%|█████████▍| 198/210 [02:19<00:08,  1.40it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56538, Requested 4096. Please try again in 634ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56539, Requested 4096. Please try again in 635ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 175 / 201  (87.1):  96%|█████████▌| 201/210 [02:21<00:06,  1.33it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56518, Requested 4096. Please try again in 614ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56008, Requested 4096. Please try again in 104ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 176 / 202  (87.1):  96%|█████████▌| 202/210 [02:21<00:05,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 178 / 204  (87.3):  97%|█████████▋| 204/210 [02:23<00:04,  1.39it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56514, Requested 4096. Please try again in 610ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 180 / 206  (87.4):  98%|█████████▊| 206/210 [02:24<00:02,  1.39it/s]INFO:backoff:Backing off request(...) for 4.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56533, Requested 4096. Please try again in 629ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.9 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59889, Requested 4096. Please try again in 3.985s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 180 / 207  (87.0):  99%|█████████▊| 207/210 [02:25<00:02,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 183 / 210  (87.1): 100%|██████████| 210/210 [02:30<00:00,  1.40it/s]\n",
      "  1%|▏         | 3/210 [00:02<02:59,  1.15it/s]\n",
      "Average Metric: 4 / 5  (80.0):   2%|▏         | 5/210 [00:02<01:40,  2.05it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58020, Requested 4096. Please try again in 2.116s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 5 / 6  (83.3):   3%|▎         | 6/210 [00:02<01:24,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 13 / 16  (81.2):   8%|▊         | 16/210 [00:08<02:05,  1.55it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56163, Requested 4096. Please try again in 259ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 14 / 18  (77.8):   9%|▊         | 18/210 [00:09<02:10,  1.47it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56172, Requested 4096. Please try again in 268ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 16 / 22  (72.7):  10%|█         | 22/210 [00:12<02:14,  1.40it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56182, Requested 4096. Please try again in 278ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 18 / 25  (72.0):  12%|█▏        | 25/210 [00:14<02:13,  1.38it/s]INFO:backoff:Backing off request(...) for 1.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56149, Requested 4096. Please try again in 244ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 22 / 29  (75.9):  14%|█▍        | 29/210 [00:17<02:11,  1.38it/s]INFO:backoff:Backing off request(...) for 3.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56541, Requested 4096. Please try again in 637ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56122, Requested 4096. Please try again in 218ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 27 / 34  (79.4):  16%|█▌        | 34/210 [00:21<02:11,  1.34it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59870, Requested 4096. Please try again in 3.966s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 27 / 35  (77.1):  17%|█▋        | 35/210 [00:22<02:12,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 30 / 38  (78.9):  18%|█▊        | 38/210 [00:24<02:06,  1.36it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56185, Requested 4096. Please try again in 281ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59875, Requested 4096. Please try again in 3.971s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 31 / 39  (79.5):  19%|█▊        | 39/210 [00:25<02:08,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 35 / 45  (77.8):  21%|██▏       | 45/210 [00:29<02:05,  1.32it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56177, Requested 4096. Please try again in 273ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 37 / 47  (78.7):  22%|██▏       | 47/210 [00:31<01:57,  1.39it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56174, Requested 4096. Please try again in 270ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 43 / 54  (79.6):  26%|██▌       | 54/210 [00:36<01:47,  1.45it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56252, Requested 4096. Please try again in 348ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 44 / 55  (80.0):  26%|██▌       | 55/210 [00:37<01:47,  1.44it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56553, Requested 4096. Please try again in 649ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 46 / 57  (80.7):  27%|██▋       | 57/210 [00:38<01:52,  1.36it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56206, Requested 4096. Please try again in 302ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 51 / 62  (82.3):  30%|██▉       | 62/210 [00:42<01:50,  1.34it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56527, Requested 4096. Please try again in 623ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 52 / 64  (81.2):  30%|███       | 64/210 [00:44<01:55,  1.26it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56171, Requested 4096. Please try again in 267ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 54 / 68  (79.4):  32%|███▏      | 68/210 [00:47<01:50,  1.28it/s]INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56158, Requested 4096. Please try again in 254ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 57 / 71  (80.3):  34%|███▍      | 71/210 [00:49<01:41,  1.37it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56161, Requested 4096. Please try again in 257ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 64 / 78  (82.1):  37%|███▋      | 78/210 [00:54<01:32,  1.43it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56546, Requested 4096. Please try again in 642ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56183, Requested 4096. Please try again in 279ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 70 / 84  (83.3):  40%|████      | 84/210 [00:59<01:42,  1.22it/s]INFO:backoff:Backing off request(...) for 3.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56160, Requested 4096. Please try again in 256ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 73 / 87  (83.9):  41%|████▏     | 87/210 [01:01<01:24,  1.46it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56179, Requested 4096. Please try again in 275ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 80 / 94  (85.1):  45%|████▍     | 94/210 [01:06<01:19,  1.45it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56550, Requested 4096. Please try again in 646ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 1.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56543, Requested 4096. Please try again in 639ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 81 / 95  (85.3):  45%|████▌     | 95/210 [01:07<01:25,  1.34it/s]INFO:backoff:Backing off request(...) for 5.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56169, Requested 4096. Please try again in 265ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.6 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 83 / 97  (85.6):  46%|████▌     | 97/210 [01:08<01:19,  1.42it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59872, Requested 4096. Please try again in 3.968s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 84 / 98  (85.7):  47%|████▋     | 98/210 [01:09<01:23,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 85 / 100  (85.0):  48%|████▊     | 100/210 [01:10<01:20,  1.37it/s]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56548, Requested 4096. Please try again in 644ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 90 / 106  (84.9):  50%|█████     | 106/210 [01:15<01:17,  1.34it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56198, Requested 4096. Please try again in 294ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 92 / 109  (84.4):  52%|█████▏    | 109/210 [01:17<01:17,  1.31it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56254, Requested 4096. Please try again in 350ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 95 / 112  (84.8):  53%|█████▎    | 112/210 [01:19<01:11,  1.38it/s]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56532, Requested 4096. Please try again in 628ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59911, Requested 4096. Please try again in 4.007s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 96 / 113  (85.0):  54%|█████▍    | 113/210 [01:20<01:14,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 101 / 119  (84.9):  57%|█████▋    | 119/210 [01:24<01:07,  1.35it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56169, Requested 4096. Please try again in 265ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 102 / 121  (84.3):  58%|█████▊    | 121/210 [01:26<01:05,  1.36it/s]INFO:backoff:Backing off request(...) for 1.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56165, Requested 4096. Please try again in 261ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 106 / 125  (84.8):  60%|█████▉    | 125/210 [01:29<00:58,  1.45it/s]INFO:backoff:Backing off request(...) for 5.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56560, Requested 4096. Please try again in 656ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56533, Requested 4096. Please try again in 629ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.5 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59834, Requested 4096. Please try again in 3.93s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 112 / 134  (83.6):  64%|██████▍   | 134/210 [01:36<00:52,  1.44it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56556, Requested 4096. Please try again in 652ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 114 / 137  (83.2):  65%|██████▌   | 137/210 [01:38<00:54,  1.35it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56207, Requested 4096. Please try again in 303ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 116 / 140  (82.9):  67%|██████▋   | 140/210 [01:40<00:47,  1.47it/s]INFO:backoff:Backing off request(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56178, Requested 4096. Please try again in 274ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 119 / 144  (82.6):  69%|██████▊   | 144/210 [01:43<00:53,  1.23it/s]INFO:backoff:Backing off request(...) for 1.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56226, Requested 4096. Please try again in 322ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 124 / 149  (83.2):  71%|███████   | 149/210 [01:47<00:45,  1.34it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56209, Requested 4096. Please try again in 305ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 126 / 152  (82.9):  72%|███████▏  | 152/210 [01:49<00:44,  1.30it/s]INFO:backoff:Backing off request(...) for 1.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56185, Requested 4096. Please try again in 281ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 129 / 155  (83.2):  74%|███████▍  | 155/210 [01:51<00:40,  1.37it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56165, Requested 4096. Please try again in 261ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 134 / 161  (83.2):  77%|███████▋  | 161/210 [01:56<00:37,  1.31it/s]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56170, Requested 4096. Please try again in 266ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 135 / 162  (83.3):  77%|███████▋  | 162/210 [01:57<00:37,  1.30it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56154, Requested 4096. Please try again in 250ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 140 / 168  (83.3):  80%|████████  | 168/210 [02:01<00:30,  1.37it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56230, Requested 4096. Please try again in 326ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 142 / 170  (83.5):  81%|████████  | 170/210 [02:02<00:29,  1.37it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56194, Requested 4096. Please try again in 290ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 145 / 174  (83.3):  83%|████████▎ | 174/210 [02:05<00:25,  1.43it/s]INFO:backoff:Backing off request(...) for 2.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56160, Requested 4096. Please try again in 256ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 148 / 177  (83.6):  84%|████████▍ | 177/210 [02:08<00:24,  1.33it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56167, Requested 4096. Please try again in 263ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 154 / 183  (84.2):  87%|████████▋ | 183/210 [02:12<00:18,  1.43it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56173, Requested 4096. Please try again in 269ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59899, Requested 4096. Please try again in 3.994s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 157 / 188  (83.5):  90%|████████▉ | 188/210 [02:16<00:17,  1.26it/s]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59524, Requested 4096. Please try again in 3.62s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 159 / 192  (82.8):  91%|█████████▏| 192/210 [02:19<00:11,  1.62it/s]INFO:backoff:Backing off request(...) for 2.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56195, Requested 4096. Please try again in 291ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 163 / 196  (83.2):  93%|█████████▎| 196/210 [02:22<00:10,  1.37it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56557, Requested 4096. Please try again in 653ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 168 / 202  (83.2):  96%|█████████▌| 201/210 [02:26<00:08,  1.08it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56169, Requested 4096. Please try again in 265ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56171, Requested 4096. Please try again in 267ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 173 / 208  (83.2):  99%|█████████▉| 208/210 [02:31<00:01,  1.44it/s]INFO:backoff:Backing off request(...) for 3.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56205, Requested 4096. Please try again in 301ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 175 / 210  (83.3): 100%|██████████| 210/210 [02:37<00:00,  1.34it/s]\n",
      "  0%|          | 1/210 [00:00<02:26,  1.43it/s]\n",
      "Average Metric: 7 / 8  (87.5):   4%|▍         | 8/210 [00:03<01:21,  2.48it/s] INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57572, Requested 4096. Please try again in 1.668s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 9 / 10  (90.0):   5%|▍         | 10/210 [00:03<01:18,  2.56it/s]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57704, Requested 4096. Please try again in 1.8s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 10 / 11  (90.9):   5%|▌         | 11/210 [00:04<01:20,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 17 / 21  (81.0):  10%|█         | 21/210 [00:08<01:08,  2.75it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59910, Requested 4096. Please try again in 4.006s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 18 / 22  (81.8):  10%|█         | 22/210 [00:08<01:27,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 19 / 24  (79.2):  11%|█▏        | 24/210 [00:09<01:32,  2.01it/s]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55922, Requested 4096. Please try again in 18ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 19 / 25  (76.0):  12%|█▏        | 25/210 [00:10<01:38,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 21 / 27  (77.8):  13%|█▎        | 27/210 [00:11<01:41,  1.81it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59892, Requested 4096. Please try again in 3.987s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 22 / 28  (78.6):  13%|█▎        | 28/210 [00:12<01:55,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 25 / 31  (80.6):  15%|█▍        | 31/210 [00:14<01:37,  1.83it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56409, Requested 4096. Please try again in 504ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 26 / 32  (81.2):  15%|█▌        | 32/210 [00:14<01:44,  1.71it/s]INFO:backoff:Backing off request(...) for 4.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59906, Requested 4096. Please try again in 4.001s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 27 / 33  (81.8):  16%|█▌        | 33/210 [00:15<01:48,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.0 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 29 / 36  (80.6):  17%|█▋        | 36/210 [00:17<01:41,  1.72it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55932, Requested 4096. Please try again in 28ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 31 / 41  (75.6):  20%|█▉        | 41/210 [00:20<01:35,  1.77it/s]INFO:backoff:Backing off request(...) for 6.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56400, Requested 4096. Please try again in 496ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.4 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 34 / 45  (75.6):  21%|██▏       | 45/210 [00:22<01:47,  1.54it/s]INFO:backoff:Backing off request(...) for 1.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55917, Requested 4096. Please try again in 13ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 35 / 46  (76.1):  22%|██▏       | 46/210 [00:23<01:29,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 44 / 58  (75.9):  28%|██▊       | 58/210 [00:30<01:26,  1.76it/s]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55919, Requested 4096. Please try again in 15ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 48 / 62  (77.4):  30%|██▉       | 62/210 [00:33<01:31,  1.62it/s]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55968, Requested 4096. Please try again in 64ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 50 / 65  (76.9):  31%|███       | 65/210 [00:34<01:19,  1.83it/s]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55962, Requested 4096. Please try again in 58ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59896, Requested 4096. Please try again in 3.992s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 55 / 73  (75.3):  35%|███▍      | 73/210 [00:39<01:20,  1.71it/s]INFO:backoff:Backing off request(...) for 1.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55945, Requested 4096. Please try again in 41ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 57 / 75  (76.0):  36%|███▌      | 75/210 [00:40<01:18,  1.73it/s]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55906, Requested 4096. Please try again in 2ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 58 / 76  (76.3):  36%|███▌      | 76/210 [00:41<01:18,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 71 / 93  (76.3):  44%|████▍     | 93/210 [00:51<01:17,  1.50it/s]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55964, Requested 4096. Please try again in 60ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 72 / 94  (76.6):  45%|████▍     | 94/210 [00:52<01:03,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 75 / 98  (76.5):  47%|████▋     | 98/210 [00:54<01:03,  1.77it/s]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59399, Requested 4096. Please try again in 3.495s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58211, Requested 4096. Please try again in 2.307s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59908, Requested 4096. Please try again in 4.004s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 76 / 99  (76.8):  47%|████▋     | 99/210 [01:03<05:50,  3.16s/it]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 3.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59895, Requested 4096. Please try again in 3.991s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59889, Requested 4096. Please try again in 3.985s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59899, Requested 4096. Please try again in 3.994s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 4.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59882, Requested 4096. Please try again in 3.978s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 4.9 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 3.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59365, Requested 4096. Please try again in 3.461s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59925, Requested 4096. Please try again in 4.021s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 77 / 100  (77.0):  48%|████▊     | 100/210 [01:29<18:09,  9.91s/it]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56397, Requested 4096. Please try again in 493ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 2.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.1 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 5.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59902, Requested 4096. Please try again in 3.998s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.8 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 4.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59874, Requested 4096. Please try again in 3.97s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 4.4 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 7.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59320, Requested 4096. Please try again in 3.416s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.9 seconds after 6 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 6.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59900, Requested 4096. Please try again in 3.996s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.9 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59316, Requested 4096. Please try again in 3.412s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 77 / 101  (76.2):  48%|████▊     | 101/210 [01:54<26:22, 14.51s/it]INFO:backoff:Backing off request(...) for 14.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 1.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59898, Requested 4096. Please try again in 3.994s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 14.4 seconds after 6 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 7.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59905, Requested 4096. Please try again in 4.001s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.8 seconds after 6 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 3.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59365, Requested 4096. Please try again in 3.461s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.0 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59798, Requested 4096. Please try again in 3.894s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 44.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59902, Requested 4096. Please try again in 3.998s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 44.5 seconds after 7 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 34.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59367, Requested 4096. Please try again in 3.463s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 34.1 seconds after 7 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 78 / 102  (76.5):  49%|████▊     | 102/210 [02:20<31:57, 17.75s/it]INFO:backoff:Backing off request(...) for 12.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 12.6 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 80 / 105  (76.2):  50%|█████     | 105/210 [02:46<20:48, 11.89s/it]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59355, Requested 4096. Please try again in 3.451s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 80 / 106  (75.5):  50%|█████     | 106/210 [03:02<22:46, 13.14s/it]INFO:backoff:Backing off request(...) for 66.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59308, Requested 4096. Please try again in 3.404s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 66.0 seconds after 8 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 57.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59864, Requested 4096. Please try again in 3.96s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 57.4 seconds after 8 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 81 / 107  (75.7):  51%|█████     | 107/210 [03:11<20:23, 11.88s/it]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56427, Requested 4096. Please try again in 523ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 81 / 108  (75.0):  51%|█████▏    | 108/210 [03:21<19:01, 11.19s/it]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 82 / 109  (75.2):  52%|█████▏    | 109/210 [03:29<17:15, 10.26s/it]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 83 / 110  (75.5):  52%|█████▏    | 110/210 [03:38<16:17,  9.77s/it]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 84 / 111  (75.7):  53%|█████▎    | 111/210 [03:46<15:36,  9.46s/it]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 85 / 112  (75.9):  53%|█████▎    | 112/210 [03:56<15:18,  9.37s/it]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56426, Requested 4096. Please try again in 522ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 85 / 113  (75.2):  54%|█████▍    | 113/210 [04:05<15:14,  9.43s/it]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59894, Requested 4096. Please try again in 3.99s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 86 / 114  (75.4):  54%|█████▍    | 114/210 [04:13<14:29,  9.05s/it]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59887, Requested 4096. Please try again in 3.983s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58622, Requested 4096. Please try again in 2.718s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 5.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59896, Requested 4096. Please try again in 3.992s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 5.2 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 215.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59406, Requested 4096. Please try again in 3.502s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 215.4 seconds after 9 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59365, Requested 4096. Please try again in 3.461s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 87 / 115  (75.7):  55%|█████▍    | 115/210 [04:30<17:53, 11.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 88 / 116  (75.9):  55%|█████▌    | 116/210 [04:39<16:34, 10.58s/it]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56398, Requested 4096. Please try again in 494ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 6.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.6 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 90 / 118  (76.3):  56%|█████▌    | 118/210 [04:56<14:47,  9.65s/it]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59900, Requested 4096. Please try again in 3.996s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59905, Requested 4096. Please try again in 4.001s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 90 / 119  (75.6):  57%|█████▋    | 119/210 [05:05<14:16,  9.41s/it]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59837, Requested 4096. Please try again in 3.933s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 91 / 120  (75.8):  57%|█████▋    | 120/210 [05:14<13:47,  9.20s/it]INFO:backoff:Backing off request(...) for 1.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59907, Requested 4096. Please try again in 4.002s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59896, Requested 4096. Please try again in 3.992s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 3.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59381, Requested 4096. Please try again in 3.477s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 92 / 121  (76.0):  58%|█████▊    | 121/210 [05:31<17:06, 11.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.6 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56438, Requested 4096. Please try again in 534ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 92 / 122  (75.4):  58%|█████▊    | 122/210 [05:40<15:45, 10.74s/it]INFO:backoff:Backing off request(...) for 2.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59904, Requested 4096. Please try again in 4s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59910, Requested 4096. Please try again in 4.006s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 11.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59336, Requested 4096. Please try again in 3.432s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 11.6 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 92 / 123  (74.8):  59%|█████▊    | 123/210 [05:57<18:26, 12.72s/it]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56424, Requested 4096. Please try again in 520ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 92 / 124  (74.2):  59%|█████▉    | 124/210 [06:07<16:52, 11.77s/it]INFO:backoff:Backing off request(...) for 1.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 26.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 26.4 seconds after 6 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 3.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59906, Requested 4096. Please try again in 4.001s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.0 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 93 / 125  (74.4):  60%|█████▉    | 125/210 [06:30<21:50, 15.41s/it]INFO:backoff:Backing off request(...) for 7.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59836, Requested 4096. Please try again in 3.932s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.2 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 94 / 126  (74.6):  60%|██████    | 126/210 [06:39<18:35, 13.28s/it]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59313, Requested 4096. Please try again in 3.409s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 95 / 127  (74.8):  60%|██████    | 127/210 [06:48<16:45, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 7 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59885, Requested 4096. Please try again in 3.981s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59876, Requested 4096. Please try again in 3.971s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 77.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59348, Requested 4096. Please try again in 3.444s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 95 / 128  (74.2):  61%|██████    | 128/210 [07:05<18:31, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 77.3 seconds after 8 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 96 / 129  (74.4):  61%|██████▏   | 129/210 [07:14<16:36, 12.30s/it]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 98 / 131  (74.8):  62%|██████▏   | 131/210 [07:33<14:06, 10.71s/it]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 99 / 132  (75.0):  63%|██████▎   | 132/210 [07:41<12:46,  9.83s/it]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 100 / 133  (75.2):  63%|██████▎   | 133/210 [07:49<12:08,  9.46s/it]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 101 / 134  (75.4):  64%|██████▍   | 134/210 [07:58<11:51,  9.36s/it]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 109.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 109.0 seconds after 10 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59908, Requested 4096. Please try again in 4.004s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 2.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 3.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59352, Requested 4096. Please try again in 3.448s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 102 / 135  (75.6):  64%|██████▍   | 135/210 [08:31<20:31, 16.42s/it]INFO:backoff:Backing off request(...) for 2.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 199.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 199.8 seconds after 9 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59861, Requested 4096. Please try again in 3.956s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 103 / 136  (75.7):  65%|██████▍   | 136/210 [08:40<17:27, 14.15s/it]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 104 / 137  (75.9):  65%|██████▌   | 137/210 [08:49<15:20, 12.61s/it]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56400, Requested 4096. Please try again in 496ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 105 / 139  (75.5):  66%|██████▌   | 139/210 [09:09<13:31, 11.43s/it]INFO:backoff:Backing off request(...) for 1.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 106 / 140  (75.7):  67%|██████▋   | 140/210 [09:24<14:24, 12.34s/it]INFO:backoff:Backing off request(...) for 1.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58791, Requested 4096. Please try again in 2.887s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 106 / 141  (75.2):  67%|██████▋   | 141/210 [09:33<13:15, 11.53s/it]INFO:backoff:Backing off request(...) for 4.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.2 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 106 / 142  (74.6):  68%|██████▊   | 142/210 [09:41<11:47, 10.40s/it]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 106 / 143  (74.1):  68%|██████▊   | 143/210 [09:50<11:03,  9.90s/it]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59841, Requested 4096. Please try again in 3.937s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 459.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59324, Requested 4096. Please try again in 3.42s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 107 / 144  (74.3):  69%|██████▊   | 144/210 [10:07<13:12, 12.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 459.2 seconds after 11 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 3.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56391, Requested 4096. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 111 / 150  (74.0):  71%|███████▏  | 150/210 [11:02<09:38,  9.64s/it]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 113 / 153  (73.9):  73%|███████▎  | 153/210 [11:23<07:28,  7.86s/it]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 114 / 154  (74.0):  73%|███████▎  | 154/210 [11:32<07:30,  8.05s/it]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 115 / 155  (74.2):  74%|███████▍  | 155/210 [11:40<07:21,  8.04s/it]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 116 / 156  (74.4):  74%|███████▍  | 156/210 [11:48<07:25,  8.26s/it]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 117 / 157  (74.5):  75%|███████▍  | 157/210 [11:57<07:25,  8.41s/it]INFO:backoff:Backing off request(...) for 230.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56383, Requested 4096. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 230.1 seconds after 10 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 118 / 158  (74.7):  75%|███████▌  | 158/210 [12:07<07:35,  8.76s/it]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 119 / 159  (74.8):  76%|███████▌  | 159/210 [12:15<07:15,  8.53s/it]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 119 / 160  (74.4):  76%|███████▌  | 160/210 [12:24<07:13,  8.67s/it]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56420, Requested 4096. Please try again in 516ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 120 / 161  (74.5):  77%|███████▋  | 161/210 [12:33<07:15,  8.89s/it]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 121 / 162  (74.7):  77%|███████▋  | 162/210 [12:41<06:57,  8.69s/it]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 121 / 163  (74.2):  78%|███████▊  | 163/210 [12:50<06:46,  8.66s/it]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 122 / 164  (74.4):  78%|███████▊  | 164/210 [12:59<06:44,  8.80s/it]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 123 / 165  (74.5):  79%|███████▊  | 165/210 [13:08<06:32,  8.73s/it]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 125 / 167  (74.9):  80%|███████▉  | 167/210 [13:26<06:24,  8.95s/it]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 126 / 168  (75.0):  80%|████████  | 168/210 [13:34<06:06,  8.74s/it]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 127 / 169  (75.1):  80%|████████  | 169/210 [13:43<05:57,  8.72s/it]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 128 / 170  (75.3):  81%|████████  | 170/210 [13:51<05:47,  8.69s/it]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 128 / 172  (74.4):  82%|████████▏ | 172/210 [14:10<05:42,  9.01s/it]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 128 / 173  (74.0):  82%|████████▏ | 173/210 [14:18<05:23,  8.74s/it]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 129 / 174  (74.1):  83%|████████▎ | 174/210 [14:27<05:14,  8.73s/it]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 130 / 175  (74.3):  83%|████████▎ | 175/210 [14:36<05:10,  8.86s/it]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56403, Requested 4096. Please try again in 499ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 131 / 176  (74.4):  84%|████████▍ | 176/210 [14:45<05:08,  9.07s/it]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59379, Requested 4096. Please try again in 3.475s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 131 / 177  (74.0):  84%|████████▍ | 177/210 [15:10<07:32, 13.73s/it]INFO:backoff:Backing off request(...) for 7.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.7 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 133 / 179  (74.3):  85%|████████▌ | 179/210 [15:30<06:08, 11.90s/it]INFO:backoff:Backing off request(...) for 1.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 134 / 180  (74.4):  86%|████████▌ | 180/210 [15:44<06:15, 12.53s/it]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 345.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59892, Requested 4096. Please try again in 3.987s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 345.6 seconds after 11 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59338, Requested 4096. Please try again in 3.434s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 135 / 181  (74.6):  86%|████████▌ | 181/210 [16:01<06:37, 13.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 135 / 182  (74.2):  87%|████████▋ | 182/210 [16:11<05:49, 12.49s/it]INFO:backoff:Backing off request(...) for 3.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.6 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 5.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59201, Requested 4096. Please try again in 3.297s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 135 / 183  (73.8):  87%|████████▋ | 183/210 [16:27<06:07, 13.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.8 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 136 / 185  (73.5):  88%|████████▊ | 185/210 [16:44<04:41, 11.25s/it]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 137 / 186  (73.7):  89%|████████▊ | 186/210 [16:57<04:40, 11.67s/it]INFO:backoff:Backing off request(...) for 1.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 138 / 187  (73.8):  89%|████████▉ | 187/210 [17:11<04:44, 12.37s/it]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 139 / 188  (73.9):  90%|████████▉ | 188/210 [17:19<04:05, 11.18s/it]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 140 / 189  (74.1):  90%|█████████ | 189/210 [17:28<03:39, 10.43s/it]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 140 / 190  (73.7):  90%|█████████ | 190/210 [17:36<03:18,  9.92s/it]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 140 / 191  (73.3):  91%|█████████ | 191/210 [17:45<03:02,  9.60s/it]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59847, Requested 4096. Please try again in 3.943s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 140 / 192  (72.9):  91%|█████████▏| 192/210 [17:54<02:48,  9.34s/it]ERROR:backoff:Giving up request(...) after 12 tries (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "ERROR:dspy.evaluate.evaluate:\u001b[2m2024-05-22T21:39:02.752362Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mError for example in dev set: \t\t Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.evaluate.evaluate\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mevaluate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m180\u001b[0m\n",
      "Average Metric: 140.0 / 193  (72.5):  92%|█████████▏| 193/210 [17:58<02:11,  7.74s/it]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59211, Requested 4096. Please try again in 3.307s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 141.0 / 194  (72.7):  92%|█████████▏| 194/210 [18:03<01:49,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56409, Requested 4096. Please try again in 504ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 142.0 / 195  (72.8):  93%|█████████▎| 195/210 [18:12<01:51,  7.41s/it]INFO:backoff:Backing off request(...) for 1.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59931, Requested 4096. Please try again in 4.027s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 3.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59905, Requested 4096. Please try again in 4.001s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59356, Requested 4096. Please try again in 3.452s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59916, Requested 4096. Please try again in 4.012s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 3.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59367, Requested 4096. Please try again in 3.463s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.1 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 143.0 / 196  (73.0):  93%|█████████▎| 196/210 [18:38<03:03, 13.08s/it]INFO:backoff:Backing off request(...) for 3.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.6 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 3.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59885, Requested 4096. Please try again in 3.981s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.6 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 4.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59912, Requested 4096. Please try again in 4.008s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.2 seconds after 6 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 6.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59362, Requested 4096. Please try again in 3.458s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 143.0 / 197  (72.6):  94%|█████████▍| 197/210 [18:54<03:01, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.1 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 42.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59365, Requested 4096. Please try again in 3.461s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 42.1 seconds after 7 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 144.0 / 198  (72.7):  94%|█████████▍| 198/210 [19:11<02:58, 14.90s/it]INFO:backoff:Backing off request(...) for 7.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58772, Requested 4096. Please try again in 2.868s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.5 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 148.0 / 203  (72.9):  97%|█████████▋| 203/210 [19:57<01:11, 10.16s/it]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56396, Requested 4096. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 24.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 24.8 seconds after 8 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 149.0 / 204  (73.0):  97%|█████████▋| 204/210 [20:04<00:54,  9.09s/it]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 150.0 / 205  (73.2):  98%|█████████▊| 205/210 [20:13<00:45,  9.06s/it]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56395, Requested 4096. Please try again in 491ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 152.0 / 207  (73.4):  99%|█████████▊| 207/210 [20:30<00:26,  8.78s/it]INFO:backoff:Backing off request(...) for 245.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 245.3 seconds after 9 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 155.0 / 210  (73.8): 100%|██████████| 210/210 [24:41<00:00,  7.06s/it]\n",
      "  1%|          | 2/210 [00:01<03:16,  1.06it/s]\n",
      "Average Metric: 19 / 25  (76.0):  12%|█▏        | 25/210 [00:14<07:42,  2.50s/it]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 21 / 27  (77.8):  13%|█▎        | 27/210 [00:34<18:26,  6.04s/it]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 57725, Requested 4096. Please try again in 1.821s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 22 / 28  (78.6):  13%|█▎        | 28/210 [00:43<20:55,  6.90s/it]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56485, Requested 4096. Please try again in 581ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 2.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59900, Requested 4096. Please try again in 3.996s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.5 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59833, Requested 4096. Please try again in 3.929s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59377, Requested 4096. Please try again in 3.473s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59368, Requested 4096. Please try again in 3.464s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59895, Requested 4096. Please try again in 3.991s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 2.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59381, Requested 4096. Please try again in 3.477s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.6 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59363, Requested 4096. Please try again in 3.459s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 13.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 13.3 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 2.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59352, Requested 4096. Please try again in 3.448s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 7.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.8 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 3.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59378, Requested 4096. Please try again in 3.474s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 5.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.9 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59899, Requested 4096. Please try again in 3.994s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 6.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59343, Requested 4096. Please try again in 3.439s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 23 / 29  (79.3):  14%|█▍        | 29/210 [01:30<56:49, 18.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.8 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 15.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56464, Requested 4096. Please try again in 560ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 15.8 seconds after 6 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 21.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55924, Requested 4096. Please try again in 20ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 21.9 seconds after 6 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 24 / 30  (80.0):  14%|█▍        | 30/210 [01:37<46:19, 15.44s/it]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 26 / 32  (81.2):  15%|█▌        | 32/210 [01:57<36:48, 12.41s/it]INFO:backoff:Backing off request(...) for 1.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55927, Requested 4096. Please try again in 23ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 59.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59867, Requested 4096. Please try again in 3.963s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 59.8 seconds after 7 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 27 / 33  (81.8):  16%|█▌        | 33/210 [02:05<33:08, 11.23s/it]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56460, Requested 4096. Please try again in 556ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59374, Requested 4096. Please try again in 3.47s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 28 / 34  (82.4):  16%|█▌        | 34/210 [02:14<31:04, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56457, Requested 4096. Please try again in 553ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 29 / 35  (82.9):  17%|█▋        | 35/210 [02:23<29:11, 10.01s/it]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59908, Requested 4096. Please try again in 4.004s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59401, Requested 4096. Please try again in 3.497s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 30 / 36  (83.3):  17%|█▋        | 36/210 [02:33<28:52,  9.96s/it]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56491, Requested 4096. Please try again in 587ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 2.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59899, Requested 4096. Please try again in 3.994s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 31 / 37  (83.8):  18%|█▊        | 37/210 [02:49<33:59, 11.79s/it]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59417, Requested 4096. Please try again in 3.513s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 2.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59901, Requested 4096. Please try again in 3.997s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.7 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59383, Requested 4096. Please try again in 3.479s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 112.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59893, Requested 4096. Please try again in 3.989s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 112.1 seconds after 8 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 32 / 38  (84.2):  18%|█▊        | 38/210 [03:06<38:19, 13.37s/it]INFO:backoff:Backing off request(...) for 2.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55907, Requested 4096. Please try again in 3ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.5 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 3.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59823, Requested 4096. Please try again in 3.918s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.3 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59393, Requested 4096. Please try again in 3.489s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 34 / 40  (85.0):  19%|█▉        | 40/210 [03:24<31:48, 11.23s/it]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56504, Requested 4096. Please try again in 600ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 8.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55958, Requested 4096. Please try again in 54ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 8.1 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 36 / 42  (85.7):  20%|██        | 42/210 [03:42<27:38,  9.87s/it]INFO:backoff:Backing off request(...) for 30.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55937, Requested 4096. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 30.5 seconds after 6 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 37 / 43  (86.0):  20%|██        | 43/210 [03:59<33:33, 12.06s/it]INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58856, Requested 4096. Please try again in 2.952s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 38 / 44  (86.4):  21%|██        | 44/210 [04:08<31:12, 11.28s/it]INFO:backoff:Backing off request(...) for 2.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59820, Requested 4096. Please try again in 3.916s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 7.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59359, Requested 4096. Please try again in 3.455s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.7 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 39 / 45  (86.7):  21%|██▏       | 45/210 [04:25<35:10, 12.79s/it]INFO:backoff:Backing off request(...) for 13.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 13.8 seconds after 7 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 40 / 46  (87.0):  22%|██▏       | 46/210 [04:42<38:23, 14.05s/it]INFO:backoff:Backing off request(...) for 14.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58880, Requested 4096. Please try again in 2.976s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 14.0 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 41 / 47  (87.2):  22%|██▏       | 47/210 [04:51<34:30, 12.70s/it]INFO:backoff:Backing off request(...) for 70.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55934, Requested 4096. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 70.0 seconds after 8 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 42 / 48  (87.5):  23%|██▎       | 48/210 [04:58<29:13, 10.82s/it]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 227.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59374, Requested 4096. Please try again in 3.47s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 227.4 seconds after 9 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58771, Requested 4096. Please try again in 2.867s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 43 / 49  (87.8):  23%|██▎       | 49/210 [05:17<35:36, 13.27s/it]INFO:backoff:Backing off request(...) for 1.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 44 / 50  (88.0):  24%|██▍       | 50/210 [05:34<38:17, 14.36s/it]INFO:backoff:Backing off request(...) for 3.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58891, Requested 4096. Please try again in 2.987s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 45 / 53  (84.9):  25%|██▌       | 53/210 [05:58<26:51, 10.26s/it]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59815, Requested 4096. Please try again in 3.91s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59342, Requested 4096. Please try again in 3.438s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 89.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59343, Requested 4096. Please try again in 3.439s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 89.1 seconds after 9 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59347, Requested 4096. Please try again in 3.443s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 45 / 54  (83.3):  26%|██▌       | 54/210 [06:34<47:07, 18.12s/it]INFO:backoff:Backing off request(...) for 5.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.0 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 46 / 55  (83.6):  26%|██▌       | 55/210 [06:43<40:03, 15.50s/it]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 47 / 56  (83.9):  27%|██▋       | 56/210 [06:51<33:54, 13.21s/it]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 49 / 58  (84.5):  28%|██▊       | 58/210 [07:10<28:19, 11.18s/it]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55912, Requested 4096. Please try again in 8ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 51 / 60  (85.0):  29%|██▊       | 60/210 [07:24<23:25,  9.37s/it]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 51 / 61  (83.6):  29%|██▉       | 61/210 [07:32<21:45,  8.76s/it]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 52 / 62  (83.9):  30%|██▉       | 62/210 [07:40<21:24,  8.68s/it]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 53 / 63  (84.1):  30%|███       | 63/210 [07:49<21:26,  8.75s/it]INFO:backoff:Backing off request(...) for 296.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59898, Requested 4096. Please try again in 3.994s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 296.4 seconds after 10 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 54 / 64  (84.4):  30%|███       | 64/210 [07:58<21:33,  8.86s/it]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56454, Requested 4096. Please try again in 550ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 55 / 65  (84.6):  31%|███       | 65/210 [08:08<21:55,  9.07s/it]INFO:backoff:Backing off request(...) for 1.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 56 / 66  (84.8):  31%|███▏      | 66/210 [08:16<21:02,  8.77s/it]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 58 / 68  (85.3):  32%|███▏      | 68/210 [08:35<21:41,  9.17s/it]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55935, Requested 4096. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 60 / 70  (85.7):  33%|███▎      | 70/210 [08:55<22:34,  9.68s/it]INFO:backoff:Backing off request(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59398, Requested 4096. Please try again in 3.494s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 61 / 71  (85.9):  34%|███▍      | 71/210 [09:08<24:39, 10.64s/it]INFO:backoff:Backing off request(...) for 2.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59870, Requested 4096. Please try again in 3.966s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59445, Requested 4096. Please try again in 3.541s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 62 / 72  (86.1):  34%|███▍      | 72/210 [09:17<23:34, 10.25s/it]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56452, Requested 4096. Please try again in 548ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 3.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55935, Requested 4096. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.1 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59378, Requested 4096. Please try again in 3.474s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 5.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59345, Requested 4096. Please try again in 3.441s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.1 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 63 / 73  (86.3):  35%|███▍      | 73/210 [09:34<27:54, 12.23s/it]INFO:backoff:Backing off request(...) for 2.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56470, Requested 4096. Please try again in 566ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 64 / 74  (86.5):  35%|███▌      | 74/210 [09:43<25:24, 11.21s/it]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 21.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59897, Requested 4096. Please try again in 3.993s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 21.0 seconds after 6 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 65 / 75  (86.7):  36%|███▌      | 75/210 [09:52<23:43, 10.54s/it]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56449, Requested 4096. Please try again in 545ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 66 / 76  (86.8):  36%|███▌      | 76/210 [10:02<23:02, 10.31s/it]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 67 / 77  (87.0):  37%|███▋      | 77/210 [10:09<21:04,  9.51s/it]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 68 / 78  (87.2):  37%|███▋      | 78/210 [10:19<20:41,  9.41s/it]INFO:backoff:Backing off request(...) for 1.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56481, Requested 4096. Please try again in 577ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56474, Requested 4096. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 70 / 80  (87.5):  38%|███▊      | 80/210 [10:36<19:38,  9.07s/it]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59723, Requested 4096. Please try again in 3.819s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55911, Requested 4096. Please try again in 7ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 71 / 81  (87.7):  39%|███▊      | 81/210 [10:45<19:15,  8.95s/it]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59900, Requested 4096. Please try again in 3.996s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 72 / 82  (87.8):  39%|███▉      | 82/210 [10:54<19:04,  8.94s/it]INFO:backoff:Backing off request(...) for 3.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56455, Requested 4096. Please try again in 551ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56441, Requested 4096. Please try again in 537ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.1 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 74 / 84  (88.1):  40%|████      | 84/210 [11:07<16:48,  8.01s/it]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55990, Requested 4096. Please try again in 86ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 75 / 85  (88.2):  40%|████      | 85/210 [11:17<17:26,  8.38s/it]INFO:backoff:Backing off request(...) for 1.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56483, Requested 4096. Please try again in 579ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56481, Requested 4096. Please try again in 577ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 76 / 86  (88.4):  41%|████      | 86/210 [11:25<17:22,  8.41s/it]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59816, Requested 4096. Please try again in 3.911s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 77 / 87  (88.5):  41%|████▏     | 87/210 [11:34<17:21,  8.46s/it]INFO:backoff:Backing off request(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56428, Requested 4096. Please try again in 524ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 78 / 88  (88.6):  42%|████▏     | 88/210 [11:43<17:35,  8.65s/it]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56457, Requested 4096. Please try again in 553ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 3.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56441, Requested 4096. Please try again in 537ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 3.6 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59299, Requested 4096. Please try again in 3.395s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 7.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59359, Requested 4096. Please try again in 3.455s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.7 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 79 / 89  (88.8):  42%|████▏     | 89/210 [12:00<22:38, 11.22s/it]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56483, Requested 4096. Please try again in 579ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 7.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59346, Requested 4096. Please try again in 3.442s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.8 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 80 / 90  (88.9):  43%|████▎     | 90/210 [12:17<25:58, 12.98s/it]INFO:backoff:Backing off request(...) for 12.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58855, Requested 4096. Please try again in 2.951s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 12.4 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 81 / 91  (89.0):  43%|████▎     | 91/210 [12:27<23:52, 12.04s/it]INFO:backoff:Backing off request(...) for 5.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55925, Requested 4096. Please try again in 21ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.5 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 82 / 92  (89.1):  44%|████▍     | 92/210 [12:36<21:56, 11.16s/it]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56469, Requested 4096. Please try again in 565ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 83 / 93  (89.2):  44%|████▍     | 93/210 [12:44<19:40, 10.09s/it]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55922, Requested 4096. Please try again in 18ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 84 / 94  (89.4):  45%|████▍     | 94/210 [12:52<18:31,  9.58s/it]INFO:backoff:Backing off request(...) for 383.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56439, Requested 4096. Please try again in 535ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 1.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56442, Requested 4096. Please try again in 538ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 383.2 seconds after 11 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 85 / 95  (89.5):  45%|████▌     | 95/210 [13:01<18:01,  9.40s/it]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56456, Requested 4096. Please try again in 552ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 1.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56442, Requested 4096. Please try again in 538ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 86 / 96  (89.6):  46%|████▌     | 96/210 [13:10<17:36,  9.27s/it]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56451, Requested 4096. Please try again in 547ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 87 / 97  (89.7):  46%|████▌     | 97/210 [13:19<17:20,  9.21s/it]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56499, Requested 4096. Please try again in 595ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55937, Requested 4096. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 88 / 98  (89.8):  47%|████▋     | 98/210 [13:28<16:50,  9.02s/it]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 58743, Requested 4096. Please try again in 2.839s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 1.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59864, Requested 4096. Please try again in 3.96s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59379, Requested 4096. Please try again in 3.475s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 89 / 99  (89.9):  47%|████▋     | 99/210 [13:45<21:08, 11.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56433, Requested 4096. Please try again in 529ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 90 / 100  (90.0):  48%|████▊     | 100/210 [13:54<19:33, 10.66s/it]INFO:backoff:Backing off request(...) for 4.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.0 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59317, Requested 4096. Please try again in 3.413s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 13.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59899, Requested 4096. Please try again in 3.994s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 13.7 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 90 / 101  (89.1):  48%|████▊     | 101/210 [14:11<22:55, 12.62s/it]INFO:backoff:Backing off request(...) for 1.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55956, Requested 4096. Please try again in 52ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 91 / 102  (89.2):  49%|████▊     | 102/210 [14:20<21:10, 11.76s/it]INFO:backoff:Backing off request(...) for 7.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.0 seconds after 6 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 91 / 103  (88.3):  49%|████▉     | 103/210 [14:29<19:00, 10.66s/it]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 32.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59885, Requested 4096. Please try again in 3.981s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 32.1 seconds after 7 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 92 / 104  (88.5):  50%|████▉     | 104/210 [14:38<17:58, 10.17s/it]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56479, Requested 4096. Please try again in 575ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 93 / 106  (87.7):  50%|█████     | 106/210 [14:57<17:04,  9.86s/it]INFO:backoff:Backing off request(...) for 2.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 2.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59346, Requested 4096. Please try again in 3.442s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 40.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 40.0 seconds after 8 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 94 / 107  (87.9):  51%|█████     | 107/210 [15:20<23:51, 13.90s/it]INFO:backoff:Backing off request(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 94 / 108  (87.0):  51%|█████▏    | 108/210 [15:29<21:03, 12.39s/it]INFO:backoff:Backing off request(...) for 2.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 6.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59229, Requested 4096. Please try again in 3.325s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 95 / 109  (87.2):  52%|█████▏    | 109/210 [15:46<23:21, 13.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.0 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 96 / 110  (87.3):  52%|█████▏    | 110/210 [15:54<19:58, 11.99s/it]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59183, Requested 4096. Please try again in 3.279s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 52.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59337, Requested 4096. Please try again in 3.433s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 52.6 seconds after 9 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 97 / 111  (87.4):  53%|█████▎    | 111/210 [16:12<22:43, 13.77s/it]INFO:backoff:Backing off request(...) for 2.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55906, Requested 4096. Please try again in 2ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 98 / 112  (87.5):  53%|█████▎    | 112/210 [16:20<19:45, 12.10s/it]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59300, Requested 4096. Please try again in 3.396s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 99 / 113  (87.6):  54%|█████▍    | 113/210 [16:38<22:31, 13.93s/it]INFO:backoff:Backing off request(...) for 1.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55918, Requested 4096. Please try again in 14ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 100 / 115  (87.0):  55%|█████▍    | 115/210 [16:55<18:02, 11.39s/it]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 100 / 116  (86.2):  55%|█████▌    | 116/210 [17:05<16:55, 10.81s/it]INFO:backoff:Backing off request(...) for 1.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55961, Requested 4096. Please try again in 57ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59867, Requested 4096. Please try again in 3.963s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59349, Requested 4096. Please try again in 3.445s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 101 / 117  (86.3):  56%|█████▌    | 117/210 [17:21<19:32, 12.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56455, Requested 4096. Please try again in 551ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 102 / 118  (86.4):  56%|█████▌    | 118/210 [17:31<17:46, 11.59s/it]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56489, Requested 4096. Please try again in 585ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 4.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55939, Requested 4096. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.2 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 103 / 119  (86.6):  57%|█████▋    | 119/210 [17:39<16:21, 10.79s/it]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56473, Requested 4096. Please try again in 569ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55936, Requested 4096. Please try again in 32ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 103 / 120  (85.8):  57%|█████▋    | 120/210 [17:57<18:58, 12.66s/it]INFO:backoff:Backing off request(...) for 1.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59440, Requested 4096. Please try again in 3.536s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 1.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59431, Requested 4096. Please try again in 3.527s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 104 / 121  (86.0):  58%|█████▊    | 121/210 [18:05<16:59, 11.45s/it]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55919, Requested 4096. Please try again in 15ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 2.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59909, Requested 4096. Please try again in 4.005s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.9 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59362, Requested 4096. Please try again in 3.458s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 28.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 28.6 seconds after 6 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59370, Requested 4096. Please try again in 3.466s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 106 / 123  (86.2):  59%|█████▊    | 123/210 [18:40<19:50, 13.68s/it]INFO:backoff:Backing off request(...) for 1.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55905, Requested 4096. Please try again in 1ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 108 / 125  (86.4):  60%|█████▉    | 125/210 [18:55<15:18, 10.80s/it]INFO:backoff:Backing off request(...) for 26.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 26.0 seconds after 7 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59512, Requested 4096. Please try again in 3.608s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59298, Requested 4096. Please try again in 3.394s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 109 / 126  (86.5):  60%|██████    | 126/210 [19:14<18:36, 13.29s/it]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55913, Requested 4096. Please try again in 9ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 110 / 127  (86.6):  60%|██████    | 127/210 [19:23<16:36, 12.01s/it]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56487, Requested 4096. Please try again in 583ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 39.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 39.2 seconds after 8 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 111 / 128  (86.7):  61%|██████    | 128/210 [19:32<15:01, 11.00s/it]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56470, Requested 4096. Please try again in 566ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59896, Requested 4096. Please try again in 3.992s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 3.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59341, Requested 4096. Please try again in 3.437s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 111 / 129  (86.0):  61%|██████▏   | 129/210 [19:51<18:12, 13.49s/it]INFO:backoff:Backing off request(...) for 1.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56457, Requested 4096. Please try again in 553ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 3.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59340, Requested 4096. Please try again in 3.436s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.7 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 112 / 130  (86.2):  62%|██████▏   | 130/210 [20:06<18:27, 13.85s/it]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59108, Requested 4096. Please try again in 3.204s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 230.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59895, Requested 4096. Please try again in 3.991s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 230.4 seconds after 9 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 113 / 131  (86.3):  62%|██████▏   | 131/210 [20:15<16:36, 12.61s/it]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56456, Requested 4096. Please try again in 552ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 6.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55935, Requested 4096. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.8 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 114 / 132  (86.4):  63%|██████▎   | 132/210 [20:25<15:13, 11.71s/it]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55942, Requested 4096. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 115 / 133  (86.5):  63%|██████▎   | 133/210 [20:32<13:16, 10.34s/it]INFO:backoff:Backing off request(...) for 12.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55937, Requested 4096. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 12.1 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 116 / 134  (86.6):  64%|██████▍   | 134/210 [20:41<12:33,  9.92s/it]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56455, Requested 4096. Please try again in 551ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59901, Requested 4096. Please try again in 3.997s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 16.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59356, Requested 4096. Please try again in 3.452s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 16.4 seconds after 6 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 117 / 136  (86.0):  65%|██████▍   | 136/210 [21:09<14:28, 11.73s/it]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 53.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59897, Requested 4096. Please try again in 3.993s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 53.0 seconds after 7 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59368, Requested 4096. Please try again in 3.464s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 118 / 138  (85.5):  66%|██████▌   | 138/210 [21:34<14:09, 11.80s/it]INFO:backoff:Backing off request(...) for 5.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55937, Requested 4096. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.0 seconds after 5 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 119 / 139  (85.6):  66%|██████▌   | 139/210 [21:43<12:56, 10.94s/it]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 120 / 140  (85.7):  67%|██████▋   | 140/210 [21:53<12:23, 10.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 122 / 142  (85.9):  68%|██████▊   | 142/210 [22:06<09:55,  8.76s/it]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 123 / 143  (86.0):  68%|██████▊   | 143/210 [22:13<09:20,  8.36s/it]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 107.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59894, Requested 4096. Please try again in 3.99s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 107.0 seconds after 8 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 124 / 144  (86.1):  69%|██████▊   | 144/210 [22:22<09:26,  8.59s/it]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56493, Requested 4096. Please try again in 589ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 125 / 145  (86.2):  69%|██████▉   | 145/210 [22:32<09:31,  8.79s/it]INFO:backoff:Backing off request(...) for 1.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 126 / 146  (86.3):  70%|██████▉   | 146/210 [22:40<09:13,  8.66s/it]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 126 / 147  (85.7):  70%|███████   | 147/210 [22:49<09:14,  8.80s/it]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 127 / 148  (85.8):  70%|███████   | 148/210 [22:58<08:59,  8.70s/it]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 129 / 150  (86.0):  71%|███████▏  | 150/210 [23:16<08:53,  8.90s/it]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55906, Requested 4096. Please try again in 2ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 131 / 152  (86.2):  72%|███████▏  | 152/210 [23:35<08:53,  9.21s/it]INFO:backoff:Backing off request(...) for 1.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55994, Requested 4096. Please try again in 90ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 133 / 154  (86.4):  73%|███████▎  | 154/210 [23:49<07:50,  8.40s/it]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59329, Requested 4096. Please try again in 3.425s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "INFO:backoff:Backing off request(...) for 248.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59892, Requested 4096. Please try again in 3.987s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n",
      "Backing off 248.9 seconds after 9 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59335, Requested 4096. Please try again in 3.431s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 24.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59330, Requested 4096. Please try again in 3.426s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 24.3 seconds after 10 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 3.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 134 / 155  (86.5):  74%|███████▍  | 155/210 [24:24<14:59, 16.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 135 / 156  (86.5):  74%|███████▍  | 156/210 [24:33<12:42, 14.12s/it]INFO:backoff:Backing off request(...) for 0.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55921, Requested 4096. Please try again in 17ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 136 / 157  (86.6):  75%|███████▍  | 157/210 [24:50<13:19, 15.08s/it]INFO:backoff:Backing off request(...) for 561.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59443, Requested 4096. Please try again in 3.539s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 561.3 seconds after 11 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 137 / 158  (86.7):  75%|███████▌  | 158/210 [24:59<11:30, 13.27s/it]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56453, Requested 4096. Please try again in 549ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 138 / 159  (86.8):  76%|███████▌  | 159/210 [25:08<10:15, 12.07s/it]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 139 / 160  (86.9):  76%|███████▌  | 160/210 [25:16<09:02, 10.85s/it]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 140 / 161  (87.0):  77%|███████▋  | 161/210 [25:25<08:22, 10.25s/it]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 141 / 162  (87.0):  77%|███████▋  | 162/210 [25:34<07:50,  9.80s/it]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 142 / 163  (87.1):  78%|███████▊  | 163/210 [25:43<07:24,  9.46s/it]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59311, Requested 4096. Please try again in 3.407s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Average Metric: 143 / 164  (87.2):  78%|███████▊  | 164/210 [25:52<07:09,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 144 / 165  (87.3):  79%|███████▊  | 165/210 [26:01<07:04,  9.43s/it]INFO:backoff:Backing off request(...) for 1.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55919, Requested 4096. Please try again in 15ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 146 / 167  (87.4):  80%|███████▉  | 167/210 [26:18<06:28,  9.03s/it]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 146 / 168  (86.9):  80%|████████  | 168/210 [26:24<05:38,  8.07s/it]INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 146 / 169  (86.4):  80%|████████  | 169/210 [26:32<05:38,  8.26s/it]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 147 / 170  (86.5):  81%|████████  | 170/210 [26:41<05:35,  8.39s/it]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 147 / 171  (86.0):  81%|████████▏ | 171/210 [26:50<05:36,  8.63s/it]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56481, Requested 4096. Please try again in 577ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 148 / 172  (86.0):  82%|████████▏ | 172/210 [27:00<05:38,  8.92s/it]INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55920, Requested 4096. Please try again in 16ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 150 / 174  (86.2):  83%|████████▎ | 174/210 [27:20<05:41,  9.48s/it]INFO:backoff:Backing off request(...) for 3.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.2 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 151 / 175  (86.3):  83%|████████▎ | 175/210 [27:34<06:21, 10.89s/it]INFO:backoff:Backing off request(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 152 / 176  (86.4):  84%|████████▍ | 176/210 [27:42<05:43, 10.09s/it]INFO:backoff:Backing off request(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 153 / 177  (86.4):  84%|████████▍ | 177/210 [27:51<05:16,  9.60s/it]INFO:backoff:Backing off request(...) for 0.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59111, Requested 4096. Please try again in 3.207s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 155 / 179  (86.6):  85%|████████▌ | 179/210 [28:10<04:57,  9.60s/it]INFO:backoff:Backing off request(...) for 1.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 156 / 180  (86.7):  86%|████████▌ | 180/210 [28:18<04:32,  9.09s/it]INFO:backoff:Backing off request(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 22.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59897, Requested 4096. Please try again in 3.993s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 22.0 seconds after 10 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 157 / 181  (86.7):  86%|████████▌ | 181/210 [28:27<04:21,  9.03s/it]INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56480, Requested 4096. Please try again in 576ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 158 / 182  (86.8):  87%|████████▋ | 182/210 [28:36<04:17,  9.18s/it]INFO:backoff:Backing off request(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 159 / 183  (86.9):  87%|████████▋ | 183/210 [28:52<05:02, 11.20s/it]INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 443.9s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 56461, Requested 4096. Please try again in 557ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 443.9 seconds after 11 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59901, Requested 4096. Please try again in 3.997s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 160 / 184  (87.0):  88%|████████▊ | 184/210 [29:01<04:35, 10.60s/it]INFO:backoff:Backing off request(...) for 4.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55919, Requested 4096. Please try again in 15ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.0 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 161 / 185  (87.0):  88%|████████▊ | 185/210 [29:10<04:11, 10.04s/it]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 162 / 186  (87.1):  89%|████████▊ | 186/210 [29:21<04:06, 10.28s/it]INFO:backoff:Backing off request(...) for 1.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 2.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59213, Requested 4096. Please try again in 3.309s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 163 / 188  (86.7):  90%|████████▉ | 188/210 [29:46<04:02, 11.03s/it]INFO:backoff:Backing off request(...) for 1.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55916, Requested 4096. Please try again in 12ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 164 / 190  (86.3):  90%|█████████ | 190/210 [30:01<03:07,  9.39s/it]INFO:backoff:Backing off request(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 2.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59367, Requested 4096. Please try again in 3.463s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 1.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off request(...) for 2.3s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 59361, Requested 4096. Please try again in 3.457s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 164 / 191  (85.9):  91%|█████████ | 191/210 [30:37<05:34, 17.58s/it]INFO:backoff:Backing off request(...) for 6.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on tokens per min (TPM): Limit 60000, Used 55913, Requested 4096. Please try again in 9ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.8 seconds after 4 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 172 / 199  (86.4):  95%|█████████▍| 199/210 [31:44<01:30,  8.27s/it]INFO:backoff:Backing off request(...) for 1.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 173 / 202  (85.6):  96%|█████████▌| 202/210 [32:13<01:11,  8.96s/it]INFO:backoff:Backing off request(...) for 0.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-0125 in organization org-yMZpXHZaAyQQPRXh9bCU85qs on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x118f4e9e0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 181 / 210  (86.2): 100%|██████████| 210/210 [36:22<00:00, 10.39s/it]\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "config = dict(max_bootstrapped_demos=4, max_labeled_demos=16, num_candidate_programs=16, num_threads=4)\n",
    "\n",
    "teleprompter = BootstrapFewShotWithRandomSearch(metric=validate_exact_utterance_type, **config)\n",
    "\n",
    "compiled_prompt_opt = teleprompter.compile(UtteranceClassificator(), trainset=trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_prompt_opt.save(path=\"utterance_module_v2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 131 / 140  (93.6): 100%|██████████| 140/140 [01:31<00:00,  1.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_28b67 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_28b67 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_28b67_row0_col0, #T_28b67_row0_col1, #T_28b67_row0_col2, #T_28b67_row0_col3, #T_28b67_row0_col4, #T_28b67_row1_col0, #T_28b67_row1_col1, #T_28b67_row1_col2, #T_28b67_row1_col3, #T_28b67_row1_col4, #T_28b67_row2_col0, #T_28b67_row2_col1, #T_28b67_row2_col2, #T_28b67_row2_col3, #T_28b67_row2_col4, #T_28b67_row3_col0, #T_28b67_row3_col1, #T_28b67_row3_col2, #T_28b67_row3_col3, #T_28b67_row3_col4, #T_28b67_row4_col0, #T_28b67_row4_col1, #T_28b67_row4_col2, #T_28b67_row4_col3, #T_28b67_row4_col4, #T_28b67_row5_col0, #T_28b67_row5_col1, #T_28b67_row5_col2, #T_28b67_row5_col3, #T_28b67_row5_col4, #T_28b67_row6_col0, #T_28b67_row6_col1, #T_28b67_row6_col2, #T_28b67_row6_col3, #T_28b67_row6_col4, #T_28b67_row7_col0, #T_28b67_row7_col1, #T_28b67_row7_col2, #T_28b67_row7_col3, #T_28b67_row7_col4, #T_28b67_row8_col0, #T_28b67_row8_col1, #T_28b67_row8_col2, #T_28b67_row8_col3, #T_28b67_row8_col4, #T_28b67_row9_col0, #T_28b67_row9_col1, #T_28b67_row9_col2, #T_28b67_row9_col3, #T_28b67_row9_col4, #T_28b67_row10_col0, #T_28b67_row10_col1, #T_28b67_row10_col2, #T_28b67_row10_col3, #T_28b67_row10_col4, #T_28b67_row11_col0, #T_28b67_row11_col1, #T_28b67_row11_col2, #T_28b67_row11_col3, #T_28b67_row11_col4, #T_28b67_row12_col0, #T_28b67_row12_col1, #T_28b67_row12_col2, #T_28b67_row12_col3, #T_28b67_row12_col4, #T_28b67_row13_col0, #T_28b67_row13_col1, #T_28b67_row13_col2, #T_28b67_row13_col3, #T_28b67_row13_col4, #T_28b67_row14_col0, #T_28b67_row14_col1, #T_28b67_row14_col2, #T_28b67_row14_col3, #T_28b67_row14_col4, #T_28b67_row15_col0, #T_28b67_row15_col1, #T_28b67_row15_col2, #T_28b67_row15_col3, #T_28b67_row15_col4, #T_28b67_row16_col0, #T_28b67_row16_col1, #T_28b67_row16_col2, #T_28b67_row16_col3, #T_28b67_row16_col4, #T_28b67_row17_col0, #T_28b67_row17_col1, #T_28b67_row17_col2, #T_28b67_row17_col3, #T_28b67_row17_col4, #T_28b67_row18_col0, #T_28b67_row18_col1, #T_28b67_row18_col2, #T_28b67_row18_col3, #T_28b67_row18_col4, #T_28b67_row19_col0, #T_28b67_row19_col1, #T_28b67_row19_col2, #T_28b67_row19_col3, #T_28b67_row19_col4, #T_28b67_row20_col0, #T_28b67_row20_col1, #T_28b67_row20_col2, #T_28b67_row20_col3, #T_28b67_row20_col4, #T_28b67_row21_col0, #T_28b67_row21_col1, #T_28b67_row21_col2, #T_28b67_row21_col3, #T_28b67_row21_col4, #T_28b67_row22_col0, #T_28b67_row22_col1, #T_28b67_row22_col2, #T_28b67_row22_col3, #T_28b67_row22_col4, #T_28b67_row23_col0, #T_28b67_row23_col1, #T_28b67_row23_col2, #T_28b67_row23_col3, #T_28b67_row23_col4, #T_28b67_row24_col0, #T_28b67_row24_col1, #T_28b67_row24_col2, #T_28b67_row24_col3, #T_28b67_row24_col4, #T_28b67_row25_col0, #T_28b67_row25_col1, #T_28b67_row25_col2, #T_28b67_row25_col3, #T_28b67_row25_col4, #T_28b67_row26_col0, #T_28b67_row26_col1, #T_28b67_row26_col2, #T_28b67_row26_col3, #T_28b67_row26_col4, #T_28b67_row27_col0, #T_28b67_row27_col1, #T_28b67_row27_col2, #T_28b67_row27_col3, #T_28b67_row27_col4, #T_28b67_row28_col0, #T_28b67_row28_col1, #T_28b67_row28_col2, #T_28b67_row28_col3, #T_28b67_row28_col4, #T_28b67_row29_col0, #T_28b67_row29_col1, #T_28b67_row29_col2, #T_28b67_row29_col3, #T_28b67_row29_col4, #T_28b67_row30_col0, #T_28b67_row30_col1, #T_28b67_row30_col2, #T_28b67_row30_col3, #T_28b67_row30_col4, #T_28b67_row31_col0, #T_28b67_row31_col1, #T_28b67_row31_col2, #T_28b67_row31_col3, #T_28b67_row31_col4, #T_28b67_row32_col0, #T_28b67_row32_col1, #T_28b67_row32_col2, #T_28b67_row32_col3, #T_28b67_row32_col4, #T_28b67_row33_col0, #T_28b67_row33_col1, #T_28b67_row33_col2, #T_28b67_row33_col3, #T_28b67_row33_col4, #T_28b67_row34_col0, #T_28b67_row34_col1, #T_28b67_row34_col2, #T_28b67_row34_col3, #T_28b67_row34_col4, #T_28b67_row35_col0, #T_28b67_row35_col1, #T_28b67_row35_col2, #T_28b67_row35_col3, #T_28b67_row35_col4, #T_28b67_row36_col0, #T_28b67_row36_col1, #T_28b67_row36_col2, #T_28b67_row36_col3, #T_28b67_row36_col4, #T_28b67_row37_col0, #T_28b67_row37_col1, #T_28b67_row37_col2, #T_28b67_row37_col3, #T_28b67_row37_col4, #T_28b67_row38_col0, #T_28b67_row38_col1, #T_28b67_row38_col2, #T_28b67_row38_col3, #T_28b67_row38_col4, #T_28b67_row39_col0, #T_28b67_row39_col1, #T_28b67_row39_col2, #T_28b67_row39_col3, #T_28b67_row39_col4, #T_28b67_row40_col0, #T_28b67_row40_col1, #T_28b67_row40_col2, #T_28b67_row40_col3, #T_28b67_row40_col4, #T_28b67_row41_col0, #T_28b67_row41_col1, #T_28b67_row41_col2, #T_28b67_row41_col3, #T_28b67_row41_col4, #T_28b67_row42_col0, #T_28b67_row42_col1, #T_28b67_row42_col2, #T_28b67_row42_col3, #T_28b67_row42_col4, #T_28b67_row43_col0, #T_28b67_row43_col1, #T_28b67_row43_col2, #T_28b67_row43_col3, #T_28b67_row43_col4, #T_28b67_row44_col0, #T_28b67_row44_col1, #T_28b67_row44_col2, #T_28b67_row44_col3, #T_28b67_row44_col4, #T_28b67_row45_col0, #T_28b67_row45_col1, #T_28b67_row45_col2, #T_28b67_row45_col3, #T_28b67_row45_col4, #T_28b67_row46_col0, #T_28b67_row46_col1, #T_28b67_row46_col2, #T_28b67_row46_col3, #T_28b67_row46_col4, #T_28b67_row47_col0, #T_28b67_row47_col1, #T_28b67_row47_col2, #T_28b67_row47_col3, #T_28b67_row47_col4, #T_28b67_row48_col0, #T_28b67_row48_col1, #T_28b67_row48_col2, #T_28b67_row48_col3, #T_28b67_row48_col4, #T_28b67_row49_col0, #T_28b67_row49_col1, #T_28b67_row49_col2, #T_28b67_row49_col3, #T_28b67_row49_col4, #T_28b67_row50_col0, #T_28b67_row50_col1, #T_28b67_row50_col2, #T_28b67_row50_col3, #T_28b67_row50_col4, #T_28b67_row51_col0, #T_28b67_row51_col1, #T_28b67_row51_col2, #T_28b67_row51_col3, #T_28b67_row51_col4, #T_28b67_row52_col0, #T_28b67_row52_col1, #T_28b67_row52_col2, #T_28b67_row52_col3, #T_28b67_row52_col4, #T_28b67_row53_col0, #T_28b67_row53_col1, #T_28b67_row53_col2, #T_28b67_row53_col3, #T_28b67_row53_col4, #T_28b67_row54_col0, #T_28b67_row54_col1, #T_28b67_row54_col2, #T_28b67_row54_col3, #T_28b67_row54_col4, #T_28b67_row55_col0, #T_28b67_row55_col1, #T_28b67_row55_col2, #T_28b67_row55_col3, #T_28b67_row55_col4, #T_28b67_row56_col0, #T_28b67_row56_col1, #T_28b67_row56_col2, #T_28b67_row56_col3, #T_28b67_row56_col4, #T_28b67_row57_col0, #T_28b67_row57_col1, #T_28b67_row57_col2, #T_28b67_row57_col3, #T_28b67_row57_col4, #T_28b67_row58_col0, #T_28b67_row58_col1, #T_28b67_row58_col2, #T_28b67_row58_col3, #T_28b67_row58_col4, #T_28b67_row59_col0, #T_28b67_row59_col1, #T_28b67_row59_col2, #T_28b67_row59_col3, #T_28b67_row59_col4, #T_28b67_row60_col0, #T_28b67_row60_col1, #T_28b67_row60_col2, #T_28b67_row60_col3, #T_28b67_row60_col4, #T_28b67_row61_col0, #T_28b67_row61_col1, #T_28b67_row61_col2, #T_28b67_row61_col3, #T_28b67_row61_col4, #T_28b67_row62_col0, #T_28b67_row62_col1, #T_28b67_row62_col2, #T_28b67_row62_col3, #T_28b67_row62_col4, #T_28b67_row63_col0, #T_28b67_row63_col1, #T_28b67_row63_col2, #T_28b67_row63_col3, #T_28b67_row63_col4, #T_28b67_row64_col0, #T_28b67_row64_col1, #T_28b67_row64_col2, #T_28b67_row64_col3, #T_28b67_row64_col4, #T_28b67_row65_col0, #T_28b67_row65_col1, #T_28b67_row65_col2, #T_28b67_row65_col3, #T_28b67_row65_col4, #T_28b67_row66_col0, #T_28b67_row66_col1, #T_28b67_row66_col2, #T_28b67_row66_col3, #T_28b67_row66_col4, #T_28b67_row67_col0, #T_28b67_row67_col1, #T_28b67_row67_col2, #T_28b67_row67_col3, #T_28b67_row67_col4, #T_28b67_row68_col0, #T_28b67_row68_col1, #T_28b67_row68_col2, #T_28b67_row68_col3, #T_28b67_row68_col4, #T_28b67_row69_col0, #T_28b67_row69_col1, #T_28b67_row69_col2, #T_28b67_row69_col3, #T_28b67_row69_col4, #T_28b67_row70_col0, #T_28b67_row70_col1, #T_28b67_row70_col2, #T_28b67_row70_col3, #T_28b67_row70_col4, #T_28b67_row71_col0, #T_28b67_row71_col1, #T_28b67_row71_col2, #T_28b67_row71_col3, #T_28b67_row71_col4, #T_28b67_row72_col0, #T_28b67_row72_col1, #T_28b67_row72_col2, #T_28b67_row72_col3, #T_28b67_row72_col4, #T_28b67_row73_col0, #T_28b67_row73_col1, #T_28b67_row73_col2, #T_28b67_row73_col3, #T_28b67_row73_col4, #T_28b67_row74_col0, #T_28b67_row74_col1, #T_28b67_row74_col2, #T_28b67_row74_col3, #T_28b67_row74_col4, #T_28b67_row75_col0, #T_28b67_row75_col1, #T_28b67_row75_col2, #T_28b67_row75_col3, #T_28b67_row75_col4, #T_28b67_row76_col0, #T_28b67_row76_col1, #T_28b67_row76_col2, #T_28b67_row76_col3, #T_28b67_row76_col4, #T_28b67_row77_col0, #T_28b67_row77_col1, #T_28b67_row77_col2, #T_28b67_row77_col3, #T_28b67_row77_col4, #T_28b67_row78_col0, #T_28b67_row78_col1, #T_28b67_row78_col2, #T_28b67_row78_col3, #T_28b67_row78_col4, #T_28b67_row79_col0, #T_28b67_row79_col1, #T_28b67_row79_col2, #T_28b67_row79_col3, #T_28b67_row79_col4, #T_28b67_row80_col0, #T_28b67_row80_col1, #T_28b67_row80_col2, #T_28b67_row80_col3, #T_28b67_row80_col4, #T_28b67_row81_col0, #T_28b67_row81_col1, #T_28b67_row81_col2, #T_28b67_row81_col3, #T_28b67_row81_col4, #T_28b67_row82_col0, #T_28b67_row82_col1, #T_28b67_row82_col2, #T_28b67_row82_col3, #T_28b67_row82_col4, #T_28b67_row83_col0, #T_28b67_row83_col1, #T_28b67_row83_col2, #T_28b67_row83_col3, #T_28b67_row83_col4, #T_28b67_row84_col0, #T_28b67_row84_col1, #T_28b67_row84_col2, #T_28b67_row84_col3, #T_28b67_row84_col4, #T_28b67_row85_col0, #T_28b67_row85_col1, #T_28b67_row85_col2, #T_28b67_row85_col3, #T_28b67_row85_col4, #T_28b67_row86_col0, #T_28b67_row86_col1, #T_28b67_row86_col2, #T_28b67_row86_col3, #T_28b67_row86_col4, #T_28b67_row87_col0, #T_28b67_row87_col1, #T_28b67_row87_col2, #T_28b67_row87_col3, #T_28b67_row87_col4, #T_28b67_row88_col0, #T_28b67_row88_col1, #T_28b67_row88_col2, #T_28b67_row88_col3, #T_28b67_row88_col4, #T_28b67_row89_col0, #T_28b67_row89_col1, #T_28b67_row89_col2, #T_28b67_row89_col3, #T_28b67_row89_col4, #T_28b67_row90_col0, #T_28b67_row90_col1, #T_28b67_row90_col2, #T_28b67_row90_col3, #T_28b67_row90_col4, #T_28b67_row91_col0, #T_28b67_row91_col1, #T_28b67_row91_col2, #T_28b67_row91_col3, #T_28b67_row91_col4, #T_28b67_row92_col0, #T_28b67_row92_col1, #T_28b67_row92_col2, #T_28b67_row92_col3, #T_28b67_row92_col4, #T_28b67_row93_col0, #T_28b67_row93_col1, #T_28b67_row93_col2, #T_28b67_row93_col3, #T_28b67_row93_col4, #T_28b67_row94_col0, #T_28b67_row94_col1, #T_28b67_row94_col2, #T_28b67_row94_col3, #T_28b67_row94_col4, #T_28b67_row95_col0, #T_28b67_row95_col1, #T_28b67_row95_col2, #T_28b67_row95_col3, #T_28b67_row95_col4, #T_28b67_row96_col0, #T_28b67_row96_col1, #T_28b67_row96_col2, #T_28b67_row96_col3, #T_28b67_row96_col4, #T_28b67_row97_col0, #T_28b67_row97_col1, #T_28b67_row97_col2, #T_28b67_row97_col3, #T_28b67_row97_col4, #T_28b67_row98_col0, #T_28b67_row98_col1, #T_28b67_row98_col2, #T_28b67_row98_col3, #T_28b67_row98_col4, #T_28b67_row99_col0, #T_28b67_row99_col1, #T_28b67_row99_col2, #T_28b67_row99_col3, #T_28b67_row99_col4, #T_28b67_row100_col0, #T_28b67_row100_col1, #T_28b67_row100_col2, #T_28b67_row100_col3, #T_28b67_row100_col4, #T_28b67_row101_col0, #T_28b67_row101_col1, #T_28b67_row101_col2, #T_28b67_row101_col3, #T_28b67_row101_col4, #T_28b67_row102_col0, #T_28b67_row102_col1, #T_28b67_row102_col2, #T_28b67_row102_col3, #T_28b67_row102_col4, #T_28b67_row103_col0, #T_28b67_row103_col1, #T_28b67_row103_col2, #T_28b67_row103_col3, #T_28b67_row103_col4, #T_28b67_row104_col0, #T_28b67_row104_col1, #T_28b67_row104_col2, #T_28b67_row104_col3, #T_28b67_row104_col4, #T_28b67_row105_col0, #T_28b67_row105_col1, #T_28b67_row105_col2, #T_28b67_row105_col3, #T_28b67_row105_col4, #T_28b67_row106_col0, #T_28b67_row106_col1, #T_28b67_row106_col2, #T_28b67_row106_col3, #T_28b67_row106_col4, #T_28b67_row107_col0, #T_28b67_row107_col1, #T_28b67_row107_col2, #T_28b67_row107_col3, #T_28b67_row107_col4, #T_28b67_row108_col0, #T_28b67_row108_col1, #T_28b67_row108_col2, #T_28b67_row108_col3, #T_28b67_row108_col4, #T_28b67_row109_col0, #T_28b67_row109_col1, #T_28b67_row109_col2, #T_28b67_row109_col3, #T_28b67_row109_col4, #T_28b67_row110_col0, #T_28b67_row110_col1, #T_28b67_row110_col2, #T_28b67_row110_col3, #T_28b67_row110_col4, #T_28b67_row111_col0, #T_28b67_row111_col1, #T_28b67_row111_col2, #T_28b67_row111_col3, #T_28b67_row111_col4, #T_28b67_row112_col0, #T_28b67_row112_col1, #T_28b67_row112_col2, #T_28b67_row112_col3, #T_28b67_row112_col4, #T_28b67_row113_col0, #T_28b67_row113_col1, #T_28b67_row113_col2, #T_28b67_row113_col3, #T_28b67_row113_col4, #T_28b67_row114_col0, #T_28b67_row114_col1, #T_28b67_row114_col2, #T_28b67_row114_col3, #T_28b67_row114_col4, #T_28b67_row115_col0, #T_28b67_row115_col1, #T_28b67_row115_col2, #T_28b67_row115_col3, #T_28b67_row115_col4, #T_28b67_row116_col0, #T_28b67_row116_col1, #T_28b67_row116_col2, #T_28b67_row116_col3, #T_28b67_row116_col4, #T_28b67_row117_col0, #T_28b67_row117_col1, #T_28b67_row117_col2, #T_28b67_row117_col3, #T_28b67_row117_col4, #T_28b67_row118_col0, #T_28b67_row118_col1, #T_28b67_row118_col2, #T_28b67_row118_col3, #T_28b67_row118_col4, #T_28b67_row119_col0, #T_28b67_row119_col1, #T_28b67_row119_col2, #T_28b67_row119_col3, #T_28b67_row119_col4, #T_28b67_row120_col0, #T_28b67_row120_col1, #T_28b67_row120_col2, #T_28b67_row120_col3, #T_28b67_row120_col4, #T_28b67_row121_col0, #T_28b67_row121_col1, #T_28b67_row121_col2, #T_28b67_row121_col3, #T_28b67_row121_col4, #T_28b67_row122_col0, #T_28b67_row122_col1, #T_28b67_row122_col2, #T_28b67_row122_col3, #T_28b67_row122_col4, #T_28b67_row123_col0, #T_28b67_row123_col1, #T_28b67_row123_col2, #T_28b67_row123_col3, #T_28b67_row123_col4, #T_28b67_row124_col0, #T_28b67_row124_col1, #T_28b67_row124_col2, #T_28b67_row124_col3, #T_28b67_row124_col4, #T_28b67_row125_col0, #T_28b67_row125_col1, #T_28b67_row125_col2, #T_28b67_row125_col3, #T_28b67_row125_col4, #T_28b67_row126_col0, #T_28b67_row126_col1, #T_28b67_row126_col2, #T_28b67_row126_col3, #T_28b67_row126_col4, #T_28b67_row127_col0, #T_28b67_row127_col1, #T_28b67_row127_col2, #T_28b67_row127_col3, #T_28b67_row127_col4, #T_28b67_row128_col0, #T_28b67_row128_col1, #T_28b67_row128_col2, #T_28b67_row128_col3, #T_28b67_row128_col4, #T_28b67_row129_col0, #T_28b67_row129_col1, #T_28b67_row129_col2, #T_28b67_row129_col3, #T_28b67_row129_col4, #T_28b67_row130_col0, #T_28b67_row130_col1, #T_28b67_row130_col2, #T_28b67_row130_col3, #T_28b67_row130_col4, #T_28b67_row131_col0, #T_28b67_row131_col1, #T_28b67_row131_col2, #T_28b67_row131_col3, #T_28b67_row131_col4, #T_28b67_row132_col0, #T_28b67_row132_col1, #T_28b67_row132_col2, #T_28b67_row132_col3, #T_28b67_row132_col4, #T_28b67_row133_col0, #T_28b67_row133_col1, #T_28b67_row133_col2, #T_28b67_row133_col3, #T_28b67_row133_col4, #T_28b67_row134_col0, #T_28b67_row134_col1, #T_28b67_row134_col2, #T_28b67_row134_col3, #T_28b67_row134_col4, #T_28b67_row135_col0, #T_28b67_row135_col1, #T_28b67_row135_col2, #T_28b67_row135_col3, #T_28b67_row135_col4, #T_28b67_row136_col0, #T_28b67_row136_col1, #T_28b67_row136_col2, #T_28b67_row136_col3, #T_28b67_row136_col4, #T_28b67_row137_col0, #T_28b67_row137_col1, #T_28b67_row137_col2, #T_28b67_row137_col3, #T_28b67_row137_col4, #T_28b67_row138_col0, #T_28b67_row138_col1, #T_28b67_row138_col2, #T_28b67_row138_col3, #T_28b67_row138_col4, #T_28b67_row139_col0, #T_28b67_row139_col1, #T_28b67_row139_col2, #T_28b67_row139_col3, #T_28b67_row139_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_28b67\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_28b67_level0_col0\" class=\"col_heading level0 col0\" >utterance</th>\n",
       "      <th id=\"T_28b67_level0_col1\" class=\"col_heading level0 col1\" >example_utterance_type</th>\n",
       "      <th id=\"T_28b67_level0_col2\" class=\"col_heading level0 col2\" >rationale</th>\n",
       "      <th id=\"T_28b67_level0_col3\" class=\"col_heading level0 col3\" >pred_utterance_type</th>\n",
       "      <th id=\"T_28b67_level0_col4\" class=\"col_heading level0 col4\" >validate_exact_utterance_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_28b67_row0_col0\" class=\"data row0 col0\" >I’m out, but thanks for the opportunity.</td>\n",
       "      <td id=\"T_28b67_row0_col1\" class=\"data row0 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row0_col2\" class=\"data row0 col2\" >out_of_scope</td>\n",
       "      <td id=\"T_28b67_row0_col3\" class=\"data row0 col3\" >out_of_scope</td>\n",
       "      <td id=\"T_28b67_row0_col4\" class=\"data row0 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_28b67_row1_col0\" class=\"data row1 col0\" >Absolutely! I thrive in team environments and am committed to following all policies and procedures.</td>\n",
       "      <td id=\"T_28b67_row1_col1\" class=\"data row1 col1\" >qa_4</td>\n",
       "      <td id=\"T_28b67_row1_col2\" class=\"data row1 col2\" >produce the utterance_type. We see that the user is expressing agreement and highlighting their ability to work well in teams and adhere to policies and...</td>\n",
       "      <td id=\"T_28b67_row1_col3\" class=\"data row1 col3\" >qa_4</td>\n",
       "      <td id=\"T_28b67_row1_col4\" class=\"data row1 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_28b67_row2_col0\" class=\"data row2 col0\" >Handling tough situations involves staying positive, being patient, and finding effective solutions.</td>\n",
       "      <td id=\"T_28b67_row2_col1\" class=\"data row2 col1\" >qa_3</td>\n",
       "      <td id=\"T_28b67_row2_col2\" class=\"data row2 col2\" >produce the utterance_type. We see that the user is discussing their approach to handling tough situations, which is related to their problem-solving skills and attitude.</td>\n",
       "      <td id=\"T_28b67_row2_col3\" class=\"data row2 col3\" >qa_3</td>\n",
       "      <td id=\"T_28b67_row2_col4\" class=\"data row2 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_28b67_row3_col0\" class=\"data row3 col0\" >Any news on my job application?</td>\n",
       "      <td id=\"T_28b67_row3_col1\" class=\"data row3 col1\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row3_col2\" class=\"data row3 col2\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row3_col3\" class=\"data row3 col3\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row3_col4\" class=\"data row3 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_28b67_row4_col0\" class=\"data row4 col0\" >Unfortunately, I have to say no.</td>\n",
       "      <td id=\"T_28b67_row4_col1\" class=\"data row4 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row4_col2\" class=\"data row4 col2\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row4_col3\" class=\"data row4 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row4_col4\" class=\"data row4 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_28b67_row5_col0\" class=\"data row5 col0\" >Yes, I worked as a customer service representative at a retail company, assisting customers with their orders and returns.</td>\n",
       "      <td id=\"T_28b67_row5_col1\" class=\"data row5 col1\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row5_col2\" class=\"data row5 col2\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row5_col3\" class=\"data row5 col3\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row5_col4\" class=\"data row5 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_28b67_row6_col0\" class=\"data row6 col0\" >I keep a stash of my favorite snacks for a quick energy boost. 🍫</td>\n",
       "      <td id=\"T_28b67_row6_col1\" class=\"data row6 col1\" >qa_2</td>\n",
       "      <td id=\"T_28b67_row6_col2\" class=\"data row6 col2\" >qa_3</td>\n",
       "      <td id=\"T_28b67_row6_col3\" class=\"data row6 col3\" >qa_3</td>\n",
       "      <td id=\"T_28b67_row6_col4\" class=\"data row6 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_28b67_row7_col0\" class=\"data row7 col0\" >Hey! I'm juggling multiple tasks at the moment. Can we continue this at a more convenient time?</td>\n",
       "      <td id=\"T_28b67_row7_col1\" class=\"data row7 col1\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row7_col2\" class=\"data row7 col2\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row7_col3\" class=\"data row7 col3\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row7_col4\" class=\"data row7 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_28b67_row8_col0\" class=\"data row8 col0\" >Totally! My last job was in a call center, where I assisted customers with their service-related concerns.</td>\n",
       "      <td id=\"T_28b67_row8_col1\" class=\"data row8 col1\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row8_col2\" class=\"data row8 col2\" >qa_1. The user is providing information about their previous job experience.</td>\n",
       "      <td id=\"T_28b67_row8_col3\" class=\"data row8 col3\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row8_col4\" class=\"data row8 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_28b67_row9_col0\" class=\"data row9 col0\" >Sorry, but I’m not interested in this.</td>\n",
       "      <td id=\"T_28b67_row9_col1\" class=\"data row9 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row9_col2\" class=\"data row9 col2\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row9_col3\" class=\"data row9 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row9_col4\" class=\"data row9 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_28b67_row10_col0\" class=\"data row10 col0\" >Hey there! Could you tell me more about the company's history?</td>\n",
       "      <td id=\"T_28b67_row10_col1\" class=\"data row10 col1\" >company_related</td>\n",
       "      <td id=\"T_28b67_row10_col2\" class=\"data row10 col2\" >company_related</td>\n",
       "      <td id=\"T_28b67_row10_col3\" class=\"data row10 col3\" >company_related</td>\n",
       "      <td id=\"T_28b67_row10_col4\" class=\"data row10 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_28b67_row11_col0\" class=\"data row11 col0\" >I'm on board with that. Let's proceed.</td>\n",
       "      <td id=\"T_28b67_row11_col1\" class=\"data row11 col1\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row11_col2\" class=\"data row11 col2\" >produce the utterance_type. The user is expressing agreement and willingness to continue the conversation.</td>\n",
       "      <td id=\"T_28b67_row11_col3\" class=\"data row11 col3\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row11_col4\" class=\"data row11 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_28b67_row12_col0\" class=\"data row12 col0\" >Not agreeing with this, sorry.</td>\n",
       "      <td id=\"T_28b67_row12_col1\" class=\"data row12 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row12_col2\" class=\"data row12 col2\" >produce the utterance_type. We see that the user is expressing disagreement or discomfort with a certain topic or situation.</td>\n",
       "      <td id=\"T_28b67_row12_col3\" class=\"data row12 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row12_col4\" class=\"data row12 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_28b67_row13_col0\" class=\"data row13 col0\" >Oki</td>\n",
       "      <td id=\"T_28b67_row13_col1\" class=\"data row13 col1\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row13_col2\" class=\"data row13 col2\" >produce the utterance_type. The user's response is short and does not provide much information, indicating a lack of engagement or interest in continuing the conversation.</td>\n",
       "      <td id=\"T_28b67_row13_col3\" class=\"data row13 col3\" >out_of_scope</td>\n",
       "      <td id=\"T_28b67_row13_col4\" class=\"data row13 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_28b67_row14_col0\" class=\"data row14 col0\" >I’m not on board with this.</td>\n",
       "      <td id=\"T_28b67_row14_col1\" class=\"data row14 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row14_col2\" class=\"data row14 col2\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row14_col3\" class=\"data row14 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row14_col4\" class=\"data row14 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_28b67_row15_col0\" class=\"data row15 col0\" >Hey! Any news? 📰</td>\n",
       "      <td id=\"T_28b67_row15_col1\" class=\"data row15 col1\" >greetings</td>\n",
       "      <td id=\"T_28b67_row15_col2\" class=\"data row15 col2\" >greetings</td>\n",
       "      <td id=\"T_28b67_row15_col3\" class=\"data row15 col3\" >greetings</td>\n",
       "      <td id=\"T_28b67_row15_col4\" class=\"data row15 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_28b67_row16_col0\" class=\"data row16 col0\" >Staying organized and having a plan helps me stay on track.</td>\n",
       "      <td id=\"T_28b67_row16_col1\" class=\"data row16 col1\" >qa_2</td>\n",
       "      <td id=\"T_28b67_row16_col2\" class=\"data row16 col2\" >qa_1. We see that the user is discussing their strategies for staying on track and organized.</td>\n",
       "      <td id=\"T_28b67_row16_col3\" class=\"data row16 col3\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row16_col4\" class=\"data row16 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_28b67_row17_col0\" class=\"data row17 col0\" >Hi! Can you provide some insights into the company culture?</td>\n",
       "      <td id=\"T_28b67_row17_col1\" class=\"data row17 col1\" >company_related</td>\n",
       "      <td id=\"T_28b67_row17_col2\" class=\"data row17 col2\" >company_related</td>\n",
       "      <td id=\"T_28b67_row17_col3\" class=\"data row17 col3\" >company_related</td>\n",
       "      <td id=\"T_28b67_row17_col4\" class=\"data row17 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_28b67_row18_col0\" class=\"data row18 col0\" >Do you offer any training programs for new hires?</td>\n",
       "      <td id=\"T_28b67_row18_col1\" class=\"data row18 col1\" >company_related</td>\n",
       "      <td id=\"T_28b67_row18_col2\" class=\"data row18 col2\" >company_related</td>\n",
       "      <td id=\"T_28b67_row18_col3\" class=\"data row18 col3\" >company_related</td>\n",
       "      <td id=\"T_28b67_row18_col4\" class=\"data row18 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_28b67_row19_col0\" class=\"data row19 col0\" >I'm with you on that. What's next?</td>\n",
       "      <td id=\"T_28b67_row19_col1\" class=\"data row19 col1\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row19_col2\" class=\"data row19 col2\" >produce the utterance_type. We see that the user is agreeing to continue the conversation, indicating a willingness to proceed.</td>\n",
       "      <td id=\"T_28b67_row19_col3\" class=\"data row19 col3\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row19_col4\" class=\"data row19 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_28b67_row20_col0\" class=\"data row20 col0\" >How's my application doing? 🤔</td>\n",
       "      <td id=\"T_28b67_row20_col1\" class=\"data row20 col1\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row20_col2\" class=\"data row20 col2\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row20_col3\" class=\"data row20 col3\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row20_col4\" class=\"data row20 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_28b67_row21_col0\" class=\"data row21 col0\" >Hi! How's your day going? 😊</td>\n",
       "      <td id=\"T_28b67_row21_col1\" class=\"data row21 col1\" >greetings</td>\n",
       "      <td id=\"T_28b67_row21_col2\" class=\"data row21 col2\" >produce the utterance_type. We see that the user is initiating a conversation and asking about the other person's well-being.</td>\n",
       "      <td id=\"T_28b67_row21_col3\" class=\"data row21 col3\" >greetings</td>\n",
       "      <td id=\"T_28b67_row21_col4\" class=\"data row21 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_28b67_row22_col0\" class=\"data row22 col0\" >This isn't the right fit for me, so no.</td>\n",
       "      <td id=\"T_28b67_row22_col1\" class=\"data row22 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row22_col2\" class=\"data row22 col2\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row22_col3\" class=\"data row22 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row22_col4\" class=\"data row22 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_28b67_row23_col0\" class=\"data row23 col0\" >Hey there! I spent 2 years at a call center, where I honed my skills in customer service and communication.</td>\n",
       "      <td id=\"T_28b67_row23_col1\" class=\"data row23 col1\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row23_col2\" class=\"data row23 col2\" >qa_1. The user is providing information about their previous work experience and skills.</td>\n",
       "      <td id=\"T_28b67_row23_col3\" class=\"data row23 col3\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row23_col4\" class=\"data row23 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_28b67_row24_col0\" class=\"data row24 col0\" >Hey, what's the work environment like at the company?</td>\n",
       "      <td id=\"T_28b67_row24_col1\" class=\"data row24 col1\" >company_related</td>\n",
       "      <td id=\"T_28b67_row24_col2\" class=\"data row24 col2\" >company_related</td>\n",
       "      <td id=\"T_28b67_row24_col3\" class=\"data row24 col3\" >company_related</td>\n",
       "      <td id=\"T_28b67_row24_col4\" class=\"data row24 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_28b67_row25_col0\" class=\"data row25 col0\" >Hello! How are you today? 😄</td>\n",
       "      <td id=\"T_28b67_row25_col1\" class=\"data row25 col1\" >greetings</td>\n",
       "      <td id=\"T_28b67_row25_col2\" class=\"data row25 col2\" >produce the utterance_type. We see that the user is initiating a conversation with a friendly greeting.</td>\n",
       "      <td id=\"T_28b67_row25_col3\" class=\"data row25 col3\" >greetings</td>\n",
       "      <td id=\"T_28b67_row25_col4\" class=\"data row25 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_28b67_row26_col0\" class=\"data row26 col0\" >Can I get an update on my interview?</td>\n",
       "      <td id=\"T_28b67_row26_col1\" class=\"data row26 col1\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row26_col2\" class=\"data row26 col2\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row26_col3\" class=\"data row26 col3\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row26_col4\" class=\"data row26 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_28b67_row27_col0\" class=\"data row27 col0\" >Hi, how's your day going?</td>\n",
       "      <td id=\"T_28b67_row27_col1\" class=\"data row27 col1\" >greetings</td>\n",
       "      <td id=\"T_28b67_row27_col2\" class=\"data row27 col2\" >produce the utterance_type. We see that the user is initiating a conversation by asking about the other person's day.</td>\n",
       "      <td id=\"T_28b67_row27_col3\" class=\"data row27 col3\" >greetings</td>\n",
       "      <td id=\"T_28b67_row27_col4\" class=\"data row27 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_28b67_row28_col0\" class=\"data row28 col0\" >Hey, what benefits does the company offer to its employees?</td>\n",
       "      <td id=\"T_28b67_row28_col1\" class=\"data row28 col1\" >company_related</td>\n",
       "      <td id=\"T_28b67_row28_col2\" class=\"data row28 col2\" >company_related</td>\n",
       "      <td id=\"T_28b67_row28_col3\" class=\"data row28 col3\" >company_related</td>\n",
       "      <td id=\"T_28b67_row28_col4\" class=\"data row28 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_28b67_row29_col0\" class=\"data row29 col0\" >I'm stepping away for a bit, be back soon!</td>\n",
       "      <td id=\"T_28b67_row29_col1\" class=\"data row29 col1\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row29_col2\" class=\"data row29 col2\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row29_col3\" class=\"data row29 col3\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row29_col4\" class=\"data row29 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_28b67_row30_col0\" class=\"data row30 col0\" >Honestly, a cup of strong coffee and some good vibes do the trick! ☕️✨</td>\n",
       "      <td id=\"T_28b67_row30_col1\" class=\"data row30 col1\" >qa_2</td>\n",
       "      <td id=\"T_28b67_row30_col2\" class=\"data row30 col2\" >qa_2. We see that the user is sharing a personal method of staying motivated, which is related to their work habits and preferences.</td>\n",
       "      <td id=\"T_28b67_row30_col3\" class=\"data row30 col3\" >qa_2</td>\n",
       "      <td id=\"T_28b67_row30_col4\" class=\"data row30 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_28b67_row31_col0\" class=\"data row31 col0\" >This doesn’t work for me, so I’m saying no.</td>\n",
       "      <td id=\"T_28b67_row31_col1\" class=\"data row31 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row31_col2\" class=\"data row31 col2\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row31_col3\" class=\"data row31 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row31_col4\" class=\"data row31 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_28b67_row32_col0\" class=\"data row32 col0\" >Hey there! 😊 How's it going?</td>\n",
       "      <td id=\"T_28b67_row32_col1\" class=\"data row32 col1\" >greetings</td>\n",
       "      <td id=\"T_28b67_row32_col2\" class=\"data row32 col2\" >greetings</td>\n",
       "      <td id=\"T_28b67_row32_col3\" class=\"data row32 col3\" >greetings</td>\n",
       "      <td id=\"T_28b67_row32_col4\" class=\"data row32 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_28b67_row33_col0\" class=\"data row33 col0\" >That's a great idea! Let's run with it.</td>\n",
       "      <td id=\"T_28b67_row33_col1\" class=\"data row33 col1\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row33_col2\" class=\"data row33 col2\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row33_col3\" class=\"data row33 col3\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row33_col4\" class=\"data row33 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_28b67_row34_col0\" class=\"data row34 col0\" >Definitely! I worked in a call center where I handled escalated calls and provided solutions to complex problems.</td>\n",
       "      <td id=\"T_28b67_row34_col1\" class=\"data row34 col1\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row34_col2\" class=\"data row34 col2\" >qa_3</td>\n",
       "      <td id=\"T_28b67_row34_col3\" class=\"data row34 col3\" >qa_3</td>\n",
       "      <td id=\"T_28b67_row34_col4\" class=\"data row34 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_28b67_row35_col0\" class=\"data row35 col0\" >I'm interested in the customer service role, can you send me more info?</td>\n",
       "      <td id=\"T_28b67_row35_col1\" class=\"data row35 col1\" >company_related</td>\n",
       "      <td id=\"T_28b67_row35_col2\" class=\"data row35 col2\" >company_related</td>\n",
       "      <td id=\"T_28b67_row35_col3\" class=\"data row35 col3\" >company_related</td>\n",
       "      <td id=\"T_28b67_row35_col4\" class=\"data row35 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_28b67_row36_col0\" class=\"data row36 col0\" >Hey! What's the latest? 📢</td>\n",
       "      <td id=\"T_28b67_row36_col1\" class=\"data row36 col1\" >greetings</td>\n",
       "      <td id=\"T_28b67_row36_col2\" class=\"data row36 col2\" >greetings</td>\n",
       "      <td id=\"T_28b67_row36_col3\" class=\"data row36 col3\" >greetings</td>\n",
       "      <td id=\"T_28b67_row36_col4\" class=\"data row36 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "      <td id=\"T_28b67_row37_col0\" class=\"data row37 col0\" >Good evening! 🌙 How was your day?</td>\n",
       "      <td id=\"T_28b67_row37_col1\" class=\"data row37 col1\" >greetings</td>\n",
       "      <td id=\"T_28b67_row37_col2\" class=\"data row37 col2\" >produce the utterance_type. The user is initiating a conversation by asking about the other person's day, indicating a friendly greeting.</td>\n",
       "      <td id=\"T_28b67_row37_col3\" class=\"data row37 col3\" >greetings</td>\n",
       "      <td id=\"T_28b67_row37_col4\" class=\"data row37 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "      <td id=\"T_28b67_row38_col0\" class=\"data row38 col0\" >I'm not able to chat right now, will talk to you soon!</td>\n",
       "      <td id=\"T_28b67_row38_col1\" class=\"data row38 col1\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row38_col2\" class=\"data row38 col2\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row38_col3\" class=\"data row38 col3\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row38_col4\" class=\"data row38 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "      <td id=\"T_28b67_row39_col0\" class=\"data row39 col0\" >I remind myself that each call is a chance to learn something new.</td>\n",
       "      <td id=\"T_28b67_row39_col1\" class=\"data row39 col1\" >qa_2</td>\n",
       "      <td id=\"T_28b67_row39_col2\" class=\"data row39 col2\" >qa_2</td>\n",
       "      <td id=\"T_28b67_row39_col3\" class=\"data row39 col3\" >qa_2</td>\n",
       "      <td id=\"T_28b67_row39_col4\" class=\"data row39 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "      <td id=\"T_28b67_row40_col0\" class=\"data row40 col0\" >That's correct! 👍</td>\n",
       "      <td id=\"T_28b67_row40_col1\" class=\"data row40 col1\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row40_col2\" class=\"data row40 col2\" >produce the utterance_type. We see that the user is agreeing with a statement or response.</td>\n",
       "      <td id=\"T_28b67_row40_col3\" class=\"data row40 col3\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row40_col4\" class=\"data row40 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "      <td id=\"T_28b67_row41_col0\" class=\"data row41 col0\" >Hi! Can you tell me about the company's financial performance?</td>\n",
       "      <td id=\"T_28b67_row41_col1\" class=\"data row41 col1\" >company_related</td>\n",
       "      <td id=\"T_28b67_row41_col2\" class=\"data row41 col2\" >company_related</td>\n",
       "      <td id=\"T_28b67_row41_col3\" class=\"data row41 col3\" >company_related</td>\n",
       "      <td id=\"T_28b67_row41_col4\" class=\"data row41 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "      <td id=\"T_28b67_row42_col0\" class=\"data row42 col0\" >You bet! Teamwork is key, and I'm committed to following established policies and procedures.</td>\n",
       "      <td id=\"T_28b67_row42_col1\" class=\"data row42 col1\" >qa_4</td>\n",
       "      <td id=\"T_28b67_row42_col2\" class=\"data row42 col2\" >produce the utterance_type. We see that the user is emphasizing the importance of teamwork and commitment to following policies and procedures.</td>\n",
       "      <td id=\"T_28b67_row42_col3\" class=\"data row42 col3\" >qa_4</td>\n",
       "      <td id=\"T_28b67_row42_col4\" class=\"data row42 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "      <td id=\"T_28b67_row43_col0\" class=\"data row43 col0\" >Hi, it's nice to meet you.</td>\n",
       "      <td id=\"T_28b67_row43_col1\" class=\"data row43 col1\" >greetings</td>\n",
       "      <td id=\"T_28b67_row43_col2\" class=\"data row43 col2\" >produce the utterance_type. We see that the user is initiating a conversation in a friendly manner.</td>\n",
       "      <td id=\"T_28b67_row43_col3\" class=\"data row43 col3\" >greetings</td>\n",
       "      <td id=\"T_28b67_row43_col4\" class=\"data row43 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "      <td id=\"T_28b67_row44_col0\" class=\"data row44 col0\" >Am I still in the running for this position?</td>\n",
       "      <td id=\"T_28b67_row44_col1\" class=\"data row44 col1\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row44_col2\" class=\"data row44 col2\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row44_col3\" class=\"data row44 col3\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row44_col4\" class=\"data row44 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "      <td id=\"T_28b67_row45_col0\" class=\"data row45 col0\" >Sorry, but I don’t agree with this approach.</td>\n",
       "      <td id=\"T_28b67_row45_col1\" class=\"data row45 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row45_col2\" class=\"data row45 col2\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row45_col3\" class=\"data row45 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row45_col4\" class=\"data row45 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "      <td id=\"T_28b67_row46_col0\" class=\"data row46 col0\" >What are the working hours for the inbound sales team?</td>\n",
       "      <td id=\"T_28b67_row46_col1\" class=\"data row46 col1\" >company_related</td>\n",
       "      <td id=\"T_28b67_row46_col2\" class=\"data row46 col2\" >company_related</td>\n",
       "      <td id=\"T_28b67_row46_col3\" class=\"data row46 col3\" >company_related</td>\n",
       "      <td id=\"T_28b67_row46_col4\" class=\"data row46 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "      <td id=\"T_28b67_row47_col0\" class=\"data row47 col0\" >My experience includes working in a call center where I provided assistance with billing, technical issues, and general inquiries.</td>\n",
       "      <td id=\"T_28b67_row47_col1\" class=\"data row47 col1\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row47_col2\" class=\"data row47 col2\" >qa_1. The user is providing information about their work experience in a call center, which is related to their skills and qualifications.</td>\n",
       "      <td id=\"T_28b67_row47_col3\" class=\"data row47 col3\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row47_col4\" class=\"data row47 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "      <td id=\"T_28b67_row48_col0\" class=\"data row48 col0\" >What sets this company apart from other call centers?</td>\n",
       "      <td id=\"T_28b67_row48_col1\" class=\"data row48 col1\" >company_related</td>\n",
       "      <td id=\"T_28b67_row48_col2\" class=\"data row48 col2\" >company_related</td>\n",
       "      <td id=\"T_28b67_row48_col3\" class=\"data row48 col3\" >company_related</td>\n",
       "      <td id=\"T_28b67_row48_col4\" class=\"data row48 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "      <td id=\"T_28b67_row49_col0\" class=\"data row49 col0\" >I apologize for any inconvenience caused and work diligently to fix the issue.</td>\n",
       "      <td id=\"T_28b67_row49_col1\" class=\"data row49 col1\" >qa_3</td>\n",
       "      <td id=\"T_28b67_row49_col2\" class=\"data row49 col2\" >qa_3</td>\n",
       "      <td id=\"T_28b67_row49_col3\" class=\"data row49 col3\" >qa_3</td>\n",
       "      <td id=\"T_28b67_row49_col4\" class=\"data row49 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "      <td id=\"T_28b67_row50_col0\" class=\"data row50 col0\" >Yes, I'm quite comfortable working in a team and following all the necessary procedures.</td>\n",
       "      <td id=\"T_28b67_row50_col1\" class=\"data row50 col1\" >qa_4</td>\n",
       "      <td id=\"T_28b67_row50_col2\" class=\"data row50 col2\" >produce the utterance_type. We see that the user is confirming their ability to work in a team and adhere to procedures.</td>\n",
       "      <td id=\"T_28b67_row50_col3\" class=\"data row50 col3\" >qa_4</td>\n",
       "      <td id=\"T_28b67_row50_col4\" class=\"data row50 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "      <td id=\"T_28b67_row51_col0\" class=\"data row51 col0\" >Hello! What's up?</td>\n",
       "      <td id=\"T_28b67_row51_col1\" class=\"data row51 col1\" >greetings</td>\n",
       "      <td id=\"T_28b67_row51_col2\" class=\"data row51 col2\" >produce the utterance_type. We see that the user is initiating a conversation in a casual manner.</td>\n",
       "      <td id=\"T_28b67_row51_col3\" class=\"data row51 col3\" >greetings</td>\n",
       "      <td id=\"T_28b67_row51_col4\" class=\"data row51 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "      <td id=\"T_28b67_row52_col0\" class=\"data row52 col0\" >Got it! Next steps are...</td>\n",
       "      <td id=\"T_28b67_row52_col1\" class=\"data row52 col1\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row52_col2\" class=\"data row52 col2\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row52_col3\" class=\"data row52 col3\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row52_col4\" class=\"data row52 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "      <td id=\"T_28b67_row53_col0\" class=\"data row53 col0\" >Affirmative, let's go ahead.</td>\n",
       "      <td id=\"T_28b67_row53_col1\" class=\"data row53 col1\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row53_col2\" class=\"data row53 col2\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row53_col3\" class=\"data row53 col3\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row53_col4\" class=\"data row53 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "      <td id=\"T_28b67_row54_col0\" class=\"data row54 col0\" >Is there any update on my application status?</td>\n",
       "      <td id=\"T_28b67_row54_col1\" class=\"data row54 col1\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row54_col2\" class=\"data row54 col2\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row54_col3\" class=\"data row54 col3\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row54_col4\" class=\"data row54 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "      <td id=\"T_28b67_row55_col0\" class=\"data row55 col0\" >In my previous job, I was responsible for managing customer inquiries and complaints in a busy call center.</td>\n",
       "      <td id=\"T_28b67_row55_col1\" class=\"data row55 col1\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row55_col2\" class=\"data row55 col2\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row55_col3\" class=\"data row55 col3\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row55_col4\" class=\"data row55 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
       "      <td id=\"T_28b67_row56_col0\" class=\"data row56 col0\" >Hello! How are things? 🌟</td>\n",
       "      <td id=\"T_28b67_row56_col1\" class=\"data row56 col1\" >greetings</td>\n",
       "      <td id=\"T_28b67_row56_col2\" class=\"data row56 col2\" >produce the utterance_type. The user is initiating the conversation with a friendly greeting.</td>\n",
       "      <td id=\"T_28b67_row56_col3\" class=\"data row56 col3\" >greetings</td>\n",
       "      <td id=\"T_28b67_row56_col4\" class=\"data row56 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row57\" class=\"row_heading level0 row57\" >57</th>\n",
       "      <td id=\"T_28b67_row57_col0\" class=\"data row57 col0\" >I'm disconnecting for now, talk to you soon!</td>\n",
       "      <td id=\"T_28b67_row57_col1\" class=\"data row57 col1\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row57_col2\" class=\"data row57 col2\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row57_col3\" class=\"data row57 col3\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row57_col4\" class=\"data row57 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row58\" class=\"row_heading level0 row58\" >58</th>\n",
       "      <td id=\"T_28b67_row58_col0\" class=\"data row58 col0\" >How does the company approach work-life balance?</td>\n",
       "      <td id=\"T_28b67_row58_col1\" class=\"data row58 col1\" >company_related</td>\n",
       "      <td id=\"T_28b67_row58_col2\" class=\"data row58 col2\" >company_related</td>\n",
       "      <td id=\"T_28b67_row58_col3\" class=\"data row58 col3\" >company_related</td>\n",
       "      <td id=\"T_28b67_row58_col4\" class=\"data row58 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row59\" class=\"row_heading level0 row59\" >59</th>\n",
       "      <td id=\"T_28b67_row59_col0\" class=\"data row59 col0\" >I'm on the same page. Please proceed.</td>\n",
       "      <td id=\"T_28b67_row59_col1\" class=\"data row59 col1\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row59_col2\" class=\"data row59 col2\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row59_col3\" class=\"data row59 col3\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row59_col4\" class=\"data row59 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row60\" class=\"row_heading level0 row60\" >60</th>\n",
       "      <td id=\"T_28b67_row60_col0\" class=\"data row60 col0\" >I’m going to decline, but I appreciate the offer.</td>\n",
       "      <td id=\"T_28b67_row60_col1\" class=\"data row60 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row60_col2\" class=\"data row60 col2\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row60_col3\" class=\"data row60 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row60_col4\" class=\"data row60 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row61\" class=\"row_heading level0 row61\" >61</th>\n",
       "      <td id=\"T_28b67_row61_col0\" class=\"data row61 col0\" >Hey, what's cracking? 😄</td>\n",
       "      <td id=\"T_28b67_row61_col1\" class=\"data row61 col1\" >greetings</td>\n",
       "      <td id=\"T_28b67_row61_col2\" class=\"data row61 col2\" >produce the utterance_type. We see that the user is initiating the conversation in a casual and friendly manner.</td>\n",
       "      <td id=\"T_28b67_row61_col3\" class=\"data row61 col3\" >greetings</td>\n",
       "      <td id=\"T_28b67_row61_col4\" class=\"data row61 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row62\" class=\"row_heading level0 row62\" >62</th>\n",
       "      <td id=\"T_28b67_row62_col0\" class=\"data row62 col0\" >What is the average salary for a customer service rep?</td>\n",
       "      <td id=\"T_28b67_row62_col1\" class=\"data row62 col1\" >company_related</td>\n",
       "      <td id=\"T_28b67_row62_col2\" class=\"data row62 col2\" >company_related</td>\n",
       "      <td id=\"T_28b67_row62_col3\" class=\"data row62 col3\" >company_related</td>\n",
       "      <td id=\"T_28b67_row62_col4\" class=\"data row62 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row63\" class=\"row_heading level0 row63\" >63</th>\n",
       "      <td id=\"T_28b67_row63_col0\" class=\"data row63 col0\" >Yep, team player here! I'm good at working collaboratively and sticking to procedures.</td>\n",
       "      <td id=\"T_28b67_row63_col1\" class=\"data row63 col1\" >qa_4</td>\n",
       "      <td id=\"T_28b67_row63_col2\" class=\"data row63 col2\" >produce the utterance_type. We see that the user is emphasizing their ability to work well in a team and follow procedures, which aligns with a...</td>\n",
       "      <td id=\"T_28b67_row63_col3\" class=\"data row63 col3\" >qa_4</td>\n",
       "      <td id=\"T_28b67_row63_col4\" class=\"data row63 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row64\" class=\"row_heading level0 row64\" >64</th>\n",
       "      <td id=\"T_28b67_row64_col0\" class=\"data row64 col0\" >Good morning! What are the company's main products or services?</td>\n",
       "      <td id=\"T_28b67_row64_col1\" class=\"data row64 col1\" >company_related</td>\n",
       "      <td id=\"T_28b67_row64_col2\" class=\"data row64 col2\" >company_related</td>\n",
       "      <td id=\"T_28b67_row64_col3\" class=\"data row64 col3\" >company_related</td>\n",
       "      <td id=\"T_28b67_row64_col4\" class=\"data row64 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row65\" class=\"row_heading level0 row65\" >65</th>\n",
       "      <td id=\"T_28b67_row65_col0\" class=\"data row65 col0\" >Hey! Can you provide some information about the company's technology stack?</td>\n",
       "      <td id=\"T_28b67_row65_col1\" class=\"data row65 col1\" >company_related</td>\n",
       "      <td id=\"T_28b67_row65_col2\" class=\"data row65 col2\" >company_related</td>\n",
       "      <td id=\"T_28b67_row65_col3\" class=\"data row65 col3\" >company_related</td>\n",
       "      <td id=\"T_28b67_row65_col4\" class=\"data row65 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row66\" class=\"row_heading level0 row66\" >66</th>\n",
       "      <td id=\"T_28b67_row66_col0\" class=\"data row66 col0\" >Thanks, but I’ll have to decline.</td>\n",
       "      <td id=\"T_28b67_row66_col1\" class=\"data row66 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row66_col2\" class=\"data row66 col2\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row66_col3\" class=\"data row66 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row66_col4\" class=\"data row66 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row67\" class=\"row_heading level0 row67\" >67</th>\n",
       "      <td id=\"T_28b67_row67_col0\" class=\"data row67 col0\" >I’m not continuing with this, sorry.</td>\n",
       "      <td id=\"T_28b67_row67_col1\" class=\"data row67 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row67_col2\" class=\"data row67 col2\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row67_col3\" class=\"data row67 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row67_col4\" class=\"data row67 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row68\" class=\"row_heading level0 row68\" >68</th>\n",
       "      <td id=\"T_28b67_row68_col0\" class=\"data row68 col0\" >I need some time to myself, talk to you later!</td>\n",
       "      <td id=\"T_28b67_row68_col1\" class=\"data row68 col1\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row68_col2\" class=\"data row68 col2\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row68_col3\" class=\"data row68 col3\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row68_col4\" class=\"data row68 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row69\" class=\"row_heading level0 row69\" >69</th>\n",
       "      <td id=\"T_28b67_row69_col0\" class=\"data row69 col0\" >I believe in listening carefully and addressing their concerns with empathy and efficiency.</td>\n",
       "      <td id=\"T_28b67_row69_col1\" class=\"data row69 col1\" >qa_3</td>\n",
       "      <td id=\"T_28b67_row69_col2\" class=\"data row69 col2\" >produce the utterance_type. We see that the user is discussing their approach to handling customer concerns, which is related to their work behavior.</td>\n",
       "      <td id=\"T_28b67_row69_col3\" class=\"data row69 col3\" >qa_3</td>\n",
       "      <td id=\"T_28b67_row69_col4\" class=\"data row69 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row70\" class=\"row_heading level0 row70\" >70</th>\n",
       "      <td id=\"T_28b67_row70_col0\" class=\"data row70 col0\" >Hi! I'm really sorry, but I have to step out unexpectedly. Can we continue this discussion later?</td>\n",
       "      <td id=\"T_28b67_row70_col1\" class=\"data row70 col1\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row70_col2\" class=\"data row70 col2\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row70_col3\" class=\"data row70 col3\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row70_col4\" class=\"data row70 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row71\" class=\"row_heading level0 row71\" >71</th>\n",
       "      <td id=\"T_28b67_row71_col0\" class=\"data row71 col0\" >Hello! How does the company foster employee growth and development?</td>\n",
       "      <td id=\"T_28b67_row71_col1\" class=\"data row71 col1\" >company_related</td>\n",
       "      <td id=\"T_28b67_row71_col2\" class=\"data row71 col2\" >company_related</td>\n",
       "      <td id=\"T_28b67_row71_col3\" class=\"data row71 col3\" >company_related</td>\n",
       "      <td id=\"T_28b67_row71_col4\" class=\"data row71 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row72\" class=\"row_heading level0 row72\" >72</th>\n",
       "      <td id=\"T_28b67_row72_col0\" class=\"data row72 col0\" >Hi! How does the company encourage innovation among its employees?</td>\n",
       "      <td id=\"T_28b67_row72_col1\" class=\"data row72 col1\" >company_related</td>\n",
       "      <td id=\"T_28b67_row72_col2\" class=\"data row72 col2\" >company_related</td>\n",
       "      <td id=\"T_28b67_row72_col3\" class=\"data row72 col3\" >company_related</td>\n",
       "      <td id=\"T_28b67_row72_col4\" class=\"data row72 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row73\" class=\"row_heading level0 row73\" >73</th>\n",
       "      <td id=\"T_28b67_row73_col0\" class=\"data row73 col0\" >Hey! How's life treating you?</td>\n",
       "      <td id=\"T_28b67_row73_col1\" class=\"data row73 col1\" >greetings</td>\n",
       "      <td id=\"T_28b67_row73_col2\" class=\"data row73 col2\" >produce the utterance_type. We see that the user is initiating a casual conversation and asking about the other person's well-being.</td>\n",
       "      <td id=\"T_28b67_row73_col3\" class=\"data row73 col3\" >greetings</td>\n",
       "      <td id=\"T_28b67_row73_col4\" class=\"data row73 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row74\" class=\"row_heading level0 row74\" >74</th>\n",
       "      <td id=\"T_28b67_row74_col0\" class=\"data row74 col0\" >What kind of support does the company offer for professional development?</td>\n",
       "      <td id=\"T_28b67_row74_col1\" class=\"data row74 col1\" >company_related</td>\n",
       "      <td id=\"T_28b67_row74_col2\" class=\"data row74 col2\" >company_related</td>\n",
       "      <td id=\"T_28b67_row74_col3\" class=\"data row74 col3\" >company_related</td>\n",
       "      <td id=\"T_28b67_row74_col4\" class=\"data row74 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row75\" class=\"row_heading level0 row75\" >75</th>\n",
       "      <td id=\"T_28b67_row75_col0\" class=\"data row75 col0\" >I’ve done customer service for a software company, where I helped users with troubleshooting and product guidance.</td>\n",
       "      <td id=\"T_28b67_row75_col1\" class=\"data row75 col1\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row75_col2\" class=\"data row75 col2\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row75_col3\" class=\"data row75 col3\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row75_col4\" class=\"data row75 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row76\" class=\"row_heading level0 row76\" >76</th>\n",
       "      <td id=\"T_28b67_row76_col0\" class=\"data row76 col0\" >Hi! I'm looking forward to talking to you.</td>\n",
       "      <td id=\"T_28b67_row76_col1\" class=\"data row76 col1\" >greetings</td>\n",
       "      <td id=\"T_28b67_row76_col2\" class=\"data row76 col2\" >greetings</td>\n",
       "      <td id=\"T_28b67_row76_col3\" class=\"data row76 col3\" >greetings</td>\n",
       "      <td id=\"T_28b67_row76_col4\" class=\"data row76 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row77\" class=\"row_heading level0 row77\" >77</th>\n",
       "      <td id=\"T_28b67_row77_col0\" class=\"data row77 col0\" >Excellent, what's the next question?</td>\n",
       "      <td id=\"T_28b67_row77_col1\" class=\"data row77 col1\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row77_col2\" class=\"data row77 col2\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row77_col3\" class=\"data row77 col3\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row77_col4\" class=\"data row77 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row78\" class=\"row_heading level0 row78\" >78</th>\n",
       "      <td id=\"T_28b67_row78_col0\" class=\"data row78 col0\" >I have to go, but we can continue this on WhatsApp later</td>\n",
       "      <td id=\"T_28b67_row78_col1\" class=\"data row78 col1\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row78_col2\" class=\"data row78 col2\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row78_col3\" class=\"data row78 col3\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row78_col4\" class=\"data row78 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row79\" class=\"row_heading level0 row79\" >79</th>\n",
       "      <td id=\"T_28b67_row79_col0\" class=\"data row79 col0\" >I always stay calm and listen to the customer's concerns carefully before offering a solution.</td>\n",
       "      <td id=\"T_28b67_row79_col1\" class=\"data row79 col1\" >qa_3</td>\n",
       "      <td id=\"T_28b67_row79_col2\" class=\"data row79 col2\" >qa_3</td>\n",
       "      <td id=\"T_28b67_row79_col3\" class=\"data row79 col3\" >qa_3</td>\n",
       "      <td id=\"T_28b67_row79_col4\" class=\"data row79 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row80\" class=\"row_heading level0 row80\" >80</th>\n",
       "      <td id=\"T_28b67_row80_col0\" class=\"data row80 col0\" >First, I try to understand the problem from their perspective and then work towards a satisfactory resolution.</td>\n",
       "      <td id=\"T_28b67_row80_col1\" class=\"data row80 col1\" >qa_3</td>\n",
       "      <td id=\"T_28b67_row80_col2\" class=\"data row80 col2\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row80_col3\" class=\"data row80 col3\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row80_col4\" class=\"data row80 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row81\" class=\"row_heading level0 row81\" >81</th>\n",
       "      <td id=\"T_28b67_row81_col0\" class=\"data row81 col0\" >Okay, I'm ready to move forward.</td>\n",
       "      <td id=\"T_28b67_row81_col1\" class=\"data row81 col1\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row81_col2\" class=\"data row81 col2\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row81_col3\" class=\"data row81 col3\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row81_col4\" class=\"data row81 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row82\" class=\"row_heading level0 row82\" >82</th>\n",
       "      <td id=\"T_28b67_row82_col0\" class=\"data row82 col0\" >I’ve decided not to move forward with this process.</td>\n",
       "      <td id=\"T_28b67_row82_col1\" class=\"data row82 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row82_col2\" class=\"data row82 col2\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row82_col3\" class=\"data row82 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row82_col4\" class=\"data row82 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row83\" class=\"row_heading level0 row83\" >83</th>\n",
       "      <td id=\"T_28b67_row83_col0\" class=\"data row83 col0\" >Hi! What's the company's approach to employee wellness?</td>\n",
       "      <td id=\"T_28b67_row83_col1\" class=\"data row83 col1\" >company_related</td>\n",
       "      <td id=\"T_28b67_row83_col2\" class=\"data row83 col2\" >company_related</td>\n",
       "      <td id=\"T_28b67_row83_col3\" class=\"data row83 col3\" >company_related</td>\n",
       "      <td id=\"T_28b67_row83_col4\" class=\"data row83 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row84\" class=\"row_heading level0 row84\" >84</th>\n",
       "      <td id=\"T_28b67_row84_col0\" class=\"data row84 col0\" >Hey! Any chance I could get an update on my application status?</td>\n",
       "      <td id=\"T_28b67_row84_col1\" class=\"data row84 col1\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row84_col2\" class=\"data row84 col2\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row84_col3\" class=\"data row84 col3\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row84_col4\" class=\"data row84 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row85\" class=\"row_heading level0 row85\" >85</th>\n",
       "      <td id=\"T_28b67_row85_col0\" class=\"data row85 col0\" >What kind of benefits do you offer to employees?</td>\n",
       "      <td id=\"T_28b67_row85_col1\" class=\"data row85 col1\" >company_related</td>\n",
       "      <td id=\"T_28b67_row85_col2\" class=\"data row85 col2\" >company_related</td>\n",
       "      <td id=\"T_28b67_row85_col3\" class=\"data row85 col3\" >company_related</td>\n",
       "      <td id=\"T_28b67_row85_col4\" class=\"data row85 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row86\" class=\"row_heading level0 row86\" >86</th>\n",
       "      <td id=\"T_28b67_row86_col0\" class=\"data row86 col0\" >Absolutely! I'm a team player, and I take following policies and procedures seriously.</td>\n",
       "      <td id=\"T_28b67_row86_col1\" class=\"data row86 col1\" >qa_4</td>\n",
       "      <td id=\"T_28b67_row86_col2\" class=\"data row86 col2\" >qa_4</td>\n",
       "      <td id=\"T_28b67_row86_col3\" class=\"data row86 col3\" >qa_4</td>\n",
       "      <td id=\"T_28b67_row86_col4\" class=\"data row86 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row87\" class=\"row_heading level0 row87\" >87</th>\n",
       "      <td id=\"T_28b67_row87_col0\" class=\"data row87 col0\" >Is my application still being considered?</td>\n",
       "      <td id=\"T_28b67_row87_col1\" class=\"data row87 col1\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row87_col2\" class=\"data row87 col2\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row87_col3\" class=\"data row87 col3\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row87_col4\" class=\"data row87 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row88\" class=\"row_heading level0 row88\" >88</th>\n",
       "      <td id=\"T_28b67_row88_col0\" class=\"data row88 col0\" >Hey there! Just checking in to see if there's any update on my interview status?</td>\n",
       "      <td id=\"T_28b67_row88_col1\" class=\"data row88 col1\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row88_col2\" class=\"data row88 col2\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row88_col3\" class=\"data row88 col3\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row88_col4\" class=\"data row88 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row89\" class=\"row_heading level0 row89\" >89</th>\n",
       "      <td id=\"T_28b67_row89_col0\" class=\"data row89 col0\" >Hey there! Thanks for reaching out. I'm currently tied up with a meeting, can we continue this later?</td>\n",
       "      <td id=\"T_28b67_row89_col1\" class=\"data row89 col1\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row89_col2\" class=\"data row89 col2\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row89_col3\" class=\"data row89 col3\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row89_col4\" class=\"data row89 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row90\" class=\"row_heading level0 row90\" >90</th>\n",
       "      <td id=\"T_28b67_row90_col0\" class=\"data row90 col0\" >I focus on active listening and try to resolve their issues promptly to keep them satisfied.</td>\n",
       "      <td id=\"T_28b67_row90_col1\" class=\"data row90 col1\" >qa_3</td>\n",
       "      <td id=\"T_28b67_row90_col2\" class=\"data row90 col2\" >produce the utterance_type. We see that the user is discussing their approach to customer service, which is related to their work behavior and skills.</td>\n",
       "      <td id=\"T_28b67_row90_col3\" class=\"data row90 col3\" >qa_3</td>\n",
       "      <td id=\"T_28b67_row90_col4\" class=\"data row90 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row91\" class=\"row_heading level0 row91\" >91</th>\n",
       "      <td id=\"T_28b67_row91_col0\" class=\"data row91 col0\" >Hi! Let's catch up.</td>\n",
       "      <td id=\"T_28b67_row91_col1\" class=\"data row91 col1\" >greetings</td>\n",
       "      <td id=\"T_28b67_row91_col2\" class=\"data row91 col2\" >greetings</td>\n",
       "      <td id=\"T_28b67_row91_col3\" class=\"data row91 col3\" >greetings</td>\n",
       "      <td id=\"T_28b67_row91_col4\" class=\"data row91 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row92\" class=\"row_heading level0 row92\" >92</th>\n",
       "      <td id=\"T_28b67_row92_col0\" class=\"data row92 col0\" >👍 I'm in.</td>\n",
       "      <td id=\"T_28b67_row92_col1\" class=\"data row92 col1\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row92_col2\" class=\"data row92 col2\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row92_col3\" class=\"data row92 col3\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row92_col4\" class=\"data row92 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row93\" class=\"row_heading level0 row93\" >93</th>\n",
       "      <td id=\"T_28b67_row93_col0\" class=\"data row93 col0\" >Hi! 👋 What's up?</td>\n",
       "      <td id=\"T_28b67_row93_col1\" class=\"data row93 col1\" >greetings</td>\n",
       "      <td id=\"T_28b67_row93_col2\" class=\"data row93 col2\" >produce the utterance_type. We see that the user is initiating the conversation in a friendly manner.</td>\n",
       "      <td id=\"T_28b67_row93_col3\" class=\"data row93 col3\" >greetings</td>\n",
       "      <td id=\"T_28b67_row93_col4\" class=\"data row93 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row94\" class=\"row_heading level0 row94\" >94</th>\n",
       "      <td id=\"T_28b67_row94_col0\" class=\"data row94 col0\" >Taking a moment to stretch and move around helps keep me energized.</td>\n",
       "      <td id=\"T_28b67_row94_col1\" class=\"data row94 col1\" >qa_2</td>\n",
       "      <td id=\"T_28b67_row94_col2\" class=\"data row94 col2\" >qa_2</td>\n",
       "      <td id=\"T_28b67_row94_col3\" class=\"data row94 col3\" >qa_2</td>\n",
       "      <td id=\"T_28b67_row94_col4\" class=\"data row94 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row95\" class=\"row_heading level0 row95\" >95</th>\n",
       "      <td id=\"T_28b67_row95_col0\" class=\"data row95 col0\" >Sure thing! I'm great at collaborating with others and sticking to company policies.</td>\n",
       "      <td id=\"T_28b67_row95_col1\" class=\"data row95 col1\" >qa_4</td>\n",
       "      <td id=\"T_28b67_row95_col2\" class=\"data row95 col2\" >produce the utterance_type. The user is affirming their ability to work well with others and follow company policies.</td>\n",
       "      <td id=\"T_28b67_row95_col3\" class=\"data row95 col3\" >qa_4</td>\n",
       "      <td id=\"T_28b67_row95_col4\" class=\"data row95 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row96\" class=\"row_heading level0 row96\" >96</th>\n",
       "      <td id=\"T_28b67_row96_col0\" class=\"data row96 col0\" >Hey! I'm really sorry, but I have to step away for a moment. Can we continue this in an hour?</td>\n",
       "      <td id=\"T_28b67_row96_col1\" class=\"data row96 col1\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row96_col2\" class=\"data row96 col2\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row96_col3\" class=\"data row96 col3\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row96_col4\" class=\"data row96 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row97\" class=\"row_heading level0 row97\" >97</th>\n",
       "      <td id=\"T_28b67_row97_col0\" class=\"data row97 col0\" >I'd love to know where I stand in the process.</td>\n",
       "      <td id=\"T_28b67_row97_col1\" class=\"data row97 col1\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row97_col2\" class=\"data row97 col2\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row97_col3\" class=\"data row97 col3\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row97_col4\" class=\"data row97 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row98\" class=\"row_heading level0 row98\" >98</th>\n",
       "      <td id=\"T_28b67_row98_col0\" class=\"data row98 col0\" >No problem at all! I'm great at collaborating with others and adhering to policies and procedures.</td>\n",
       "      <td id=\"T_28b67_row98_col1\" class=\"data row98 col1\" >qa_4</td>\n",
       "      <td id=\"T_28b67_row98_col2\" class=\"data row98 col2\" >produce the utterance_type. We see that the user is responding positively to a question about their ability to work in a team and follow procedures.</td>\n",
       "      <td id=\"T_28b67_row98_col3\" class=\"data row98 col3\" >qa_4</td>\n",
       "      <td id=\"T_28b67_row98_col4\" class=\"data row98 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row99\" class=\"row_heading level0 row99\" >99</th>\n",
       "      <td id=\"T_28b67_row99_col0\" class=\"data row99 col0\" >I have to go, but we can pick this up later</td>\n",
       "      <td id=\"T_28b67_row99_col1\" class=\"data row99 col1\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row99_col2\" class=\"data row99 col2\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row99_col3\" class=\"data row99 col3\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row99_col4\" class=\"data row99 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row100\" class=\"row_heading level0 row100\" >100</th>\n",
       "      <td id=\"T_28b67_row100_col0\" class=\"data row100 col0\" >Count me in!</td>\n",
       "      <td id=\"T_28b67_row100_col1\" class=\"data row100 col1\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row100_col2\" class=\"data row100 col2\" >produce the utterance_type. The user is expressing agreement or willingness to participate in something.</td>\n",
       "      <td id=\"T_28b67_row100_col3\" class=\"data row100 col3\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row100_col4\" class=\"data row100 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row101\" class=\"row_heading level0 row101\" >101</th>\n",
       "      <td id=\"T_28b67_row101_col0\" class=\"data row101 col0\" >Hey there! Wondering if there's any news on my application status?</td>\n",
       "      <td id=\"T_28b67_row101_col1\" class=\"data row101 col1\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row101_col2\" class=\"data row101 col2\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row101_col3\" class=\"data row101 col3\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row101_col4\" class=\"data row101 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row102\" class=\"row_heading level0 row102\" >102</th>\n",
       "      <td id=\"T_28b67_row102_col0\" class=\"data row102 col0\" >Handling it with a smile and a can-do attitude usually helps in resolving their issues. 😊</td>\n",
       "      <td id=\"T_28b67_row102_col1\" class=\"data row102 col1\" >qa_3</td>\n",
       "      <td id=\"T_28b67_row102_col2\" class=\"data row102 col2\" >qa_3</td>\n",
       "      <td id=\"T_28b67_row102_col3\" class=\"data row102 col3\" >qa_3</td>\n",
       "      <td id=\"T_28b67_row102_col4\" class=\"data row102 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row103\" class=\"row_heading level0 row103\" >103</th>\n",
       "      <td id=\"T_28b67_row103_col0\" class=\"data row103 col0\" >Of course! I'm all about teamwork and making sure everything runs smoothly according to the rules.</td>\n",
       "      <td id=\"T_28b67_row103_col1\" class=\"data row103 col1\" >qa_4</td>\n",
       "      <td id=\"T_28b67_row103_col2\" class=\"data row103 col2\" >qa_4. We see that the user is emphasizing their ability to work well in teams and follow established procedures.</td>\n",
       "      <td id=\"T_28b67_row103_col3\" class=\"data row103 col3\" >qa_4</td>\n",
       "      <td id=\"T_28b67_row103_col4\" class=\"data row103 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row104\" class=\"row_heading level0 row104\" >104</th>\n",
       "      <td id=\"T_28b67_row104_col0\" class=\"data row104 col0\" >Hi! It's nice to reconnect.</td>\n",
       "      <td id=\"T_28b67_row104_col1\" class=\"data row104 col1\" >greetings</td>\n",
       "      <td id=\"T_28b67_row104_col2\" class=\"data row104 col2\" >greetings</td>\n",
       "      <td id=\"T_28b67_row104_col3\" class=\"data row104 col3\" >greetings</td>\n",
       "      <td id=\"T_28b67_row104_col4\" class=\"data row104 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row105\" class=\"row_heading level0 row105\" >105</th>\n",
       "      <td id=\"T_28b67_row105_col0\" class=\"data row105 col0\" >Of course, I'm in favor.</td>\n",
       "      <td id=\"T_28b67_row105_col1\" class=\"data row105 col1\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row105_col2\" class=\"data row105 col2\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row105_col3\" class=\"data row105 col3\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row105_col4\" class=\"data row105 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row106\" class=\"row_heading level0 row106\" >106</th>\n",
       "      <td id=\"T_28b67_row106_col0\" class=\"data row106 col0\" >Yo! What's the company's mission and values?</td>\n",
       "      <td id=\"T_28b67_row106_col1\" class=\"data row106 col1\" >company_related</td>\n",
       "      <td id=\"T_28b67_row106_col2\" class=\"data row106 col2\" >company_related</td>\n",
       "      <td id=\"T_28b67_row106_col3\" class=\"data row106 col3\" >company_related</td>\n",
       "      <td id=\"T_28b67_row106_col4\" class=\"data row106 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row107\" class=\"row_heading level0 row107\" >107</th>\n",
       "      <td id=\"T_28b67_row107_col0\" class=\"data row107 col0\" >I'm excited to see what's next!</td>\n",
       "      <td id=\"T_28b67_row107_col1\" class=\"data row107 col1\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row107_col2\" class=\"data row107 col2\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row107_col3\" class=\"data row107 col3\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row107_col4\" class=\"data row107 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row108\" class=\"row_heading level0 row108\" >108</th>\n",
       "      <td id=\"T_28b67_row108_col0\" class=\"data row108 col0\" >Hey! What's on your mind?</td>\n",
       "      <td id=\"T_28b67_row108_col1\" class=\"data row108 col1\" >greetings</td>\n",
       "      <td id=\"T_28b67_row108_col2\" class=\"data row108 col2\" >produce the utterance_type. We see that the user is initiating a conversation and asking for the other person's thoughts or feelings.</td>\n",
       "      <td id=\"T_28b67_row108_col3\" class=\"data row108 col3\" >greetings</td>\n",
       "      <td id=\"T_28b67_row108_col4\" class=\"data row108 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row109\" class=\"row_heading level0 row109\" >109</th>\n",
       "      <td id=\"T_28b67_row109_col0\" class=\"data row109 col0\" >Hi! Unfortunately, I've hit a roadblock in the process. Can we revisit this tomorrow?</td>\n",
       "      <td id=\"T_28b67_row109_col1\" class=\"data row109 col1\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row109_col2\" class=\"data row109 col2\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row109_col3\" class=\"data row109 col3\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row109_col4\" class=\"data row109 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row110\" class=\"row_heading level0 row110\" >110</th>\n",
       "      <td id=\"T_28b67_row110_col0\" class=\"data row110 col0\" >Hi! What's the company's strategy for growth and expansion?</td>\n",
       "      <td id=\"T_28b67_row110_col1\" class=\"data row110 col1\" >company_related</td>\n",
       "      <td id=\"T_28b67_row110_col2\" class=\"data row110 col2\" >company_related</td>\n",
       "      <td id=\"T_28b67_row110_col3\" class=\"data row110 col3\" >company_related</td>\n",
       "      <td id=\"T_28b67_row110_col4\" class=\"data row110 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row111\" class=\"row_heading level0 row111\" >111</th>\n",
       "      <td id=\"T_28b67_row111_col0\" class=\"data row111 col0\" >Absolutely! I used to work in customer support for a tech company, helping clients with troubleshooting and product information.</td>\n",
       "      <td id=\"T_28b67_row111_col1\" class=\"data row111 col1\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row111_col2\" class=\"data row111 col2\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row111_col3\" class=\"data row111 col3\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row111_col4\" class=\"data row111 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row112\" class=\"row_heading level0 row112\" >112</th>\n",
       "      <td id=\"T_28b67_row112_col0\" class=\"data row112 col0\" >Hey! What's happening? 🤷‍♂️</td>\n",
       "      <td id=\"T_28b67_row112_col1\" class=\"data row112 col1\" >greetings</td>\n",
       "      <td id=\"T_28b67_row112_col2\" class=\"data row112 col2\" >produce the utterance_type. We see that the user is initiating a casual conversation by asking what's happening, indicating a friendly greeting.</td>\n",
       "      <td id=\"T_28b67_row112_col3\" class=\"data row112 col3\" >greetings</td>\n",
       "      <td id=\"T_28b67_row112_col4\" class=\"data row112 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row113\" class=\"row_heading level0 row113\" >113</th>\n",
       "      <td id=\"T_28b67_row113_col0\" class=\"data row113 col0\" >Yo! Any chance I could get an update on how things are progressing with my evaluation?</td>\n",
       "      <td id=\"T_28b67_row113_col1\" class=\"data row113 col1\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row113_col2\" class=\"data row113 col2\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row113_col3\" class=\"data row113 col3\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row113_col4\" class=\"data row113 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row114\" class=\"row_heading level0 row114\" >114</th>\n",
       "      <td id=\"T_28b67_row114_col0\" class=\"data row114 col0\" >I'm down for this!</td>\n",
       "      <td id=\"T_28b67_row114_col1\" class=\"data row114 col1\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row114_col2\" class=\"data row114 col2\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row114_col3\" class=\"data row114 col3\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row114_col4\" class=\"data row114 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row115\" class=\"row_heading level0 row115\" >115</th>\n",
       "      <td id=\"T_28b67_row115_col0\" class=\"data row115 col0\" >I’m declining to move forward, thanks.</td>\n",
       "      <td id=\"T_28b67_row115_col1\" class=\"data row115 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row115_col2\" class=\"data row115 col2\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row115_col3\" class=\"data row115 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row115_col4\" class=\"data row115 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row116\" class=\"row_heading level0 row116\" >116</th>\n",
       "      <td id=\"T_28b67_row116_col0\" class=\"data row116 col0\" >Yep, I'm a team player and always follow the rules and procedures.</td>\n",
       "      <td id=\"T_28b67_row116_col1\" class=\"data row116 col1\" >qa_4</td>\n",
       "      <td id=\"T_28b67_row116_col2\" class=\"data row116 col2\" >produce the utterance_type. We see that the user is confirming their ability to work well in teams and adhere to established policies and procedures.</td>\n",
       "      <td id=\"T_28b67_row116_col3\" class=\"data row116 col3\" >qa_4</td>\n",
       "      <td id=\"T_28b67_row116_col4\" class=\"data row116 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row117\" class=\"row_heading level0 row117\" >117</th>\n",
       "      <td id=\"T_28b67_row117_col0\" class=\"data row117 col0\" >I stay focused by visualizing my career growth and future opportunities.</td>\n",
       "      <td id=\"T_28b67_row117_col1\" class=\"data row117 col1\" >qa_2</td>\n",
       "      <td id=\"T_28b67_row117_col2\" class=\"data row117 col2\" >qa_2. We see that the user is discussing how they stay motivated, which is related to personal strategies for maintaining focus and drive.</td>\n",
       "      <td id=\"T_28b67_row117_col3\" class=\"data row117 col3\" >qa_2</td>\n",
       "      <td id=\"T_28b67_row117_col4\" class=\"data row117 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row118\" class=\"row_heading level0 row118\" >118</th>\n",
       "      <td id=\"T_28b67_row118_col0\" class=\"data row118 col0\" >Hey there! Hoping to get an update on my application status.</td>\n",
       "      <td id=\"T_28b67_row118_col1\" class=\"data row118 col1\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row118_col2\" class=\"data row118 col2\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row118_col3\" class=\"data row118 col3\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row118_col4\" class=\"data row118 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row119\" class=\"row_heading level0 row119\" >119</th>\n",
       "      <td id=\"T_28b67_row119_col0\" class=\"data row119 col0\" >I’ll be bowing out of this process.</td>\n",
       "      <td id=\"T_28b67_row119_col1\" class=\"data row119 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row119_col2\" class=\"data row119 col2\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row119_col3\" class=\"data row119 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row119_col4\" class=\"data row119 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row120\" class=\"row_heading level0 row120\" >120</th>\n",
       "      <td id=\"T_28b67_row120_col0\" class=\"data row120 col0\" >Is there opportunity for growth within the company?</td>\n",
       "      <td id=\"T_28b67_row120_col1\" class=\"data row120 col1\" >company_related</td>\n",
       "      <td id=\"T_28b67_row120_col2\" class=\"data row120 col2\" >company_related</td>\n",
       "      <td id=\"T_28b67_row120_col3\" class=\"data row120 col3\" >company_related</td>\n",
       "      <td id=\"T_28b67_row120_col4\" class=\"data row120 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row121\" class=\"row_heading level0 row121\" >121</th>\n",
       "      <td id=\"T_28b67_row121_col0\" class=\"data row121 col0\" >Fine by me, let's move forward.</td>\n",
       "      <td id=\"T_28b67_row121_col1\" class=\"data row121 col1\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row121_col2\" class=\"data row121 col2\" >produce the utterance_type. The user is agreeing to continue the conversation and proceed with the next steps.</td>\n",
       "      <td id=\"T_28b67_row121_col3\" class=\"data row121 col3\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row121_col4\" class=\"data row121 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row122\" class=\"row_heading level0 row122\" >122</th>\n",
       "      <td id=\"T_28b67_row122_col0\" class=\"data row122 col0\" >I remind myself of my goals and the rewards of hard work.</td>\n",
       "      <td id=\"T_28b67_row122_col1\" class=\"data row122 col1\" >qa_2</td>\n",
       "      <td id=\"T_28b67_row122_col2\" class=\"data row122 col2\" >qa_2. We see that the user is discussing how they stay motivated, which aligns with the question about personal motivation strategies.</td>\n",
       "      <td id=\"T_28b67_row122_col3\" class=\"data row122 col3\" >qa_2</td>\n",
       "      <td id=\"T_28b67_row122_col4\" class=\"data row122 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row123\" class=\"row_heading level0 row123\" >123</th>\n",
       "      <td id=\"T_28b67_row123_col0\" class=\"data row123 col0\" >That's okay, let's try again.</td>\n",
       "      <td id=\"T_28b67_row123_col1\" class=\"data row123 col1\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row123_col2\" class=\"data row123 col2\" >produce the utterance_type. We see that the user is willing to give it another try, indicating a willingness to continue.</td>\n",
       "      <td id=\"T_28b67_row123_col3\" class=\"data row123 col3\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row123_col4\" class=\"data row123 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row124\" class=\"row_heading level0 row124\" >124</th>\n",
       "      <td id=\"T_28b67_row124_col0\" class=\"data row124 col0\" >Certainly, I agree.</td>\n",
       "      <td id=\"T_28b67_row124_col1\" class=\"data row124 col1\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row124_col2\" class=\"data row124 col2\" >produce the utterance_type. The user is expressing agreement with a previous statement.</td>\n",
       "      <td id=\"T_28b67_row124_col3\" class=\"data row124 col3\" >continue_related</td>\n",
       "      <td id=\"T_28b67_row124_col4\" class=\"data row124 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row125\" class=\"row_heading level0 row125\" >125</th>\n",
       "      <td id=\"T_28b67_row125_col0\" class=\"data row125 col0\" >Hi! I'm looking forward to chatting with you.</td>\n",
       "      <td id=\"T_28b67_row125_col1\" class=\"data row125 col1\" >greetings</td>\n",
       "      <td id=\"T_28b67_row125_col2\" class=\"data row125 col2\" >produce the utterance_type. The user is initiating the conversation in a friendly manner.</td>\n",
       "      <td id=\"T_28b67_row125_col3\" class=\"data row125 col3\" >greetings</td>\n",
       "      <td id=\"T_28b67_row125_col4\" class=\"data row125 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row126\" class=\"row_heading level0 row126\" >126</th>\n",
       "      <td id=\"T_28b67_row126_col0\" class=\"data row126 col0\" >Hi! I'm afraid I won't be able to proceed with the evaluation at the moment. Can we reconvene tomorrow?</td>\n",
       "      <td id=\"T_28b67_row126_col1\" class=\"data row126 col1\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row126_col2\" class=\"data row126 col2\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row126_col3\" class=\"data row126 col3\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row126_col4\" class=\"data row126 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row127\" class=\"row_heading level0 row127\" >127</th>\n",
       "      <td id=\"T_28b67_row127_col0\" class=\"data row127 col0\" >Hey, how are you today?</td>\n",
       "      <td id=\"T_28b67_row127_col1\" class=\"data row127 col1\" >greetings</td>\n",
       "      <td id=\"T_28b67_row127_col2\" class=\"data row127 col2\" >produce the utterance_type. We see that the user is initiating a conversation with a friendly greeting.</td>\n",
       "      <td id=\"T_28b67_row127_col3\" class=\"data row127 col3\" >greetings</td>\n",
       "      <td id=\"T_28b67_row127_col4\" class=\"data row127 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row128\" class=\"row_heading level0 row128\" >128</th>\n",
       "      <td id=\"T_28b67_row128_col0\" class=\"data row128 col0\" >Hello! I hope you're doing well. Could you please let me know the current status of my interview?</td>\n",
       "      <td id=\"T_28b67_row128_col1\" class=\"data row128 col1\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row128_col2\" class=\"data row128 col2\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row128_col3\" class=\"data row128 col3\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row128_col4\" class=\"data row128 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row129\" class=\"row_heading level0 row129\" >129</th>\n",
       "      <td id=\"T_28b67_row129_col0\" class=\"data row129 col0\" >What's the current stage of my hiring process?</td>\n",
       "      <td id=\"T_28b67_row129_col1\" class=\"data row129 col1\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row129_col2\" class=\"data row129 col2\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row129_col3\" class=\"data row129 col3\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row129_col4\" class=\"data row129 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row130\" class=\"row_heading level0 row130\" >130</th>\n",
       "      <td id=\"T_28b67_row130_col0\" class=\"data row130 col0\" >Hey! I'm happy to connect with you.</td>\n",
       "      <td id=\"T_28b67_row130_col1\" class=\"data row130 col1\" >greetings</td>\n",
       "      <td id=\"T_28b67_row130_col2\" class=\"data row130 col2\" >greetings</td>\n",
       "      <td id=\"T_28b67_row130_col3\" class=\"data row130 col3\" >greetings</td>\n",
       "      <td id=\"T_28b67_row130_col4\" class=\"data row130 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row131\" class=\"row_heading level0 row131\" >131</th>\n",
       "      <td id=\"T_28b67_row131_col0\" class=\"data row131 col0\" >I’ve thought about it, and I’m not interested.</td>\n",
       "      <td id=\"T_28b67_row131_col1\" class=\"data row131 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row131_col2\" class=\"data row131 col2\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row131_col3\" class=\"data row131 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row131_col4\" class=\"data row131 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row132\" class=\"row_heading level0 row132\" >132</th>\n",
       "      <td id=\"T_28b67_row132_col0\" class=\"data row132 col0\" >Worked at a call center for 2 years, helping customers with account setups and troubleshooting issues.</td>\n",
       "      <td id=\"T_28b67_row132_col1\" class=\"data row132 col1\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row132_col2\" class=\"data row132 col2\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row132_col3\" class=\"data row132 col3\" >qa_1</td>\n",
       "      <td id=\"T_28b67_row132_col4\" class=\"data row132 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row133\" class=\"row_heading level0 row133\" >133</th>\n",
       "      <td id=\"T_28b67_row133_col0\" class=\"data row133 col0\" >Hi! What's the company's stance on sustainability?</td>\n",
       "      <td id=\"T_28b67_row133_col1\" class=\"data row133 col1\" >company_related</td>\n",
       "      <td id=\"T_28b67_row133_col2\" class=\"data row133 col2\" >company_related</td>\n",
       "      <td id=\"T_28b67_row133_col3\" class=\"data row133 col3\" >company_related</td>\n",
       "      <td id=\"T_28b67_row133_col4\" class=\"data row133 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row134\" class=\"row_heading level0 row134\" >134</th>\n",
       "      <td id=\"T_28b67_row134_col0\" class=\"data row134 col0\" >Good morning! I'm running a bit behind schedule today. Can we continue this conversation later?</td>\n",
       "      <td id=\"T_28b67_row134_col1\" class=\"data row134 col1\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row134_col2\" class=\"data row134 col2\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row134_col3\" class=\"data row134 col3\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row134_col4\" class=\"data row134 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row135\" class=\"row_heading level0 row135\" >135</th>\n",
       "      <td id=\"T_28b67_row135_col0\" class=\"data row135 col0\" >I'm bored with this convo, will catch you later</td>\n",
       "      <td id=\"T_28b67_row135_col1\" class=\"data row135 col1\" >later_continue</td>\n",
       "      <td id=\"T_28b67_row135_col2\" class=\"data row135 col2\" >produce the utterance_type. We see that the user is expressing disinterest in continuing the conversation and plans to end it for now.</td>\n",
       "      <td id=\"T_28b67_row135_col3\" class=\"data row135 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row135_col4\" class=\"data row135 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row136\" class=\"row_heading level0 row136\" >136</th>\n",
       "      <td id=\"T_28b67_row136_col0\" class=\"data row136 col0\" >This isn’t something I want to do, sorry.</td>\n",
       "      <td id=\"T_28b67_row136_col1\" class=\"data row136 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row136_col2\" class=\"data row136 col2\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row136_col3\" class=\"data row136 col3\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row136_col4\" class=\"data row136 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row137\" class=\"row_heading level0 row137\" >137</th>\n",
       "      <td id=\"T_28b67_row137_col0\" class=\"data row137 col0\" >I’m not feeling this, so I’m out.</td>\n",
       "      <td id=\"T_28b67_row137_col1\" class=\"data row137 col1\" >not_continue_related</td>\n",
       "      <td id=\"T_28b67_row137_col2\" class=\"data row137 col2\" >produce the utterance_type. The user is indicating that they do not want to continue the conversation and are leaving.</td>\n",
       "      <td id=\"T_28b67_row137_col3\" class=\"data row137 col3\" >out_of_scope</td>\n",
       "      <td id=\"T_28b67_row137_col4\" class=\"data row137 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row138\" class=\"row_heading level0 row138\" >138</th>\n",
       "      <td id=\"T_28b67_row138_col0\" class=\"data row138 col0\" >Feedback on my interview would be appreciated, thanks!</td>\n",
       "      <td id=\"T_28b67_row138_col1\" class=\"data row138 col1\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row138_col2\" class=\"data row138 col2\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row138_col3\" class=\"data row138 col3\" >feedbacks</td>\n",
       "      <td id=\"T_28b67_row138_col4\" class=\"data row138 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28b67_level0_row139\" class=\"row_heading level0 row139\" >139</th>\n",
       "      <td id=\"T_28b67_row139_col0\" class=\"data row139 col0\" >I stay professional, listen to their problems, and work towards a quick resolution.</td>\n",
       "      <td id=\"T_28b67_row139_col1\" class=\"data row139 col1\" >qa_3</td>\n",
       "      <td id=\"T_28b67_row139_col2\" class=\"data row139 col2\" >produce the utterance_type. We see that the user is describing their approach to handling customer complaints or issues, which is related to their work behavior.</td>\n",
       "      <td id=\"T_28b67_row139_col3\" class=\"data row139 col3\" >qa_3</td>\n",
       "      <td id=\"T_28b67_row139_col4\" class=\"data row139 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x16a275c30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "93.57"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate = Evaluate(devset=devset, metric=validate_exact_utterance_type, num_threads=NUM_THREADS, display_progress=True, display_table=True)\n",
    "evaluate(compiled_prompt_opt, devset=devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
