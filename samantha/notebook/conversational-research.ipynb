{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9e60719",
   "metadata": {},
   "source": [
    "### Conversational AI - Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62681546-d45d-429c-91b5-4c83c30bd7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pgvector psycopg2 einops\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3083dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import dspy\n",
    "from dspy.functional import TypedPredictor\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from transitions import Machine\n",
    "from dotenv import dotenv_values\n",
    "from rich import print\n",
    "\n",
    "\n",
    "secret = dotenv_values('../../.secret')\n",
    "\n",
    "gpt3_5_turbo  = dspy.OpenAI(\n",
    "    model='gpt-3.5-turbo-0125',\n",
    "    api_key=secret['OPEN_AI_API_KEY'],\n",
    "    max_tokens=4096\n",
    ")\n",
    "\n",
    "gpt4o  = dspy.OpenAI(\n",
    "    model='gpt-4o',\n",
    "    api_key=secret['OPEN_AI_API_KEY'],\n",
    "    max_tokens=4096\n",
    ")\n",
    "\n",
    "\n",
    "llama3 = dspy.GROQ(\n",
    "    model='llama3-70b-8192',\n",
    "    api_key=secret['GROQ_API_KEY'],\n",
    "    max_tokens=4096\n",
    ")\n",
    "\n",
    "dspy.settings.configure(lm=llama3)\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    device = \"cuda\" \\\n",
    "        if torch.cuda.is_available() \\\n",
    "        else \"mps\" if torch.backends.mps.is_available() \\\n",
    "        else \"cpu\"\n",
    "    if device == \"mps\":\n",
    "        import os\n",
    "        os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "        os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
    "    return torch.device(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9473bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers_modules.nomic-ai.nomic-bert-2048.e55a7d4324f65581af5f483e830b80f34680e8ff.modeling_hf_nomic_bert:<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "tokenizer_embed = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_embed = AutoModel.from_pretrained('nomic-ai/nomic-embed-text-v1.5', trust_remote_code=True, safe_serialization=True)\n",
    "model_embed.eval()\n",
    "\n",
    "\n",
    "def embedd(text: str):\n",
    "    def mean_pooling(model_output, attention_mask):\n",
    "        token_embeddings = model_output[0]\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "    encoded_input = tokenizer_embed(text, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # + matryoshka_dim = 512\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_output = model_embed(**encoded_input)\n",
    "\n",
    "    embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    # + embeddings = F.layer_norm(embeddings, normalized_shape=(embeddings.shape[1],))\n",
    "    # + embeddings = embeddings[:, :matryoshka_dim]\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "    return np.array(embeddings)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d71bc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "from pgvector.psycopg2 import register_vector\n",
    "\n",
    "def persona_hub(persona_desc: str, subset: str) -> None:\n",
    "    try:\n",
    "        connection = psycopg2.connect(user=\"drfadul\",\n",
    "                                    password=\"dROG@dijoFadul\",\n",
    "                                    host=\"localhost\",\n",
    "                                    port=\"5432\",\n",
    "                                    database=\"synaia\")\n",
    "        \n",
    "        register_vector(connection)\n",
    "        cursor = connection.cursor()\n",
    "        data = [\n",
    "            (subset, persona_desc, embedd(text=persona_desc))\n",
    "        ]\n",
    "\n",
    "        execute_values(cursor, \"INSERT INTO persona_hub (subset, persona_desc, persona_embedding) VALUES %s\", data)\n",
    "        connection.commit()\n",
    "\n",
    "\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        print(\"Error while INSERTING data from PostgreSQL\", error)\n",
    "\n",
    "    finally:\n",
    "        if connection:\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "\n",
    "\n",
    "\n",
    "def retrieve_persona(text: str, K: int, negative_similarity: bool = False) -> list:\n",
    "    personas = []\n",
    "    try:\n",
    "        connection = psycopg2.connect(user=\"drfadul\",\n",
    "                                    password=\"dROG@dijoFadul\",\n",
    "                                    host=\"localhost\",\n",
    "                                    port=\"5432\",\n",
    "                                    database=\"synaia\")\n",
    "        register_vector(connection)\n",
    "        cursor = connection.cursor()\n",
    "        text_embedd = embedd(text=text)\n",
    "        data = (text_embedd, text_embedd, K)\n",
    "    \n",
    "        persona_hub_query = \"SELECT subset, persona_desc, 1 - (persona_embedding <=> %s::vector) AS similarity FROM persona_hub ORDER BY persona_embedding <=> %s::vector LIMIT %s\"\n",
    "        if negative_similarity:\n",
    "            persona_hub_query = \"SELECT subset, persona_desc, 1 - (persona_embedding <=> %s::vector) AS similarity FROM persona_hub ORDER BY persona_embedding <=> %s::vector DESC LIMIT %s\"\n",
    "\n",
    "        cursor.execute(persona_hub_query, data)\n",
    "        records = cursor.fetchall()\n",
    "\n",
    "        for row in records:\n",
    "            personas.append(\n",
    "                (row[1], row[2])\n",
    "            )\n",
    "        \n",
    "        return personas\n",
    "\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        print(\"\\x1b[1;31m Error while fetching data from PostgreSQL \\x1b[1;31m\", error)\n",
    "\n",
    "    finally:\n",
    "        # closing database connection.\n",
    "        if connection:\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83a6bd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total number of input personas: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total number of input personas: \u001b[1;36m200000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "sample_size = 200_000\n",
    "\n",
    "# Load the dataset\n",
    "persona_dataset = load_dataset(\"proj-persona/PersonaHub\", data_files=\"persona.jsonl\")['train']\n",
    "persona_dataset = persona_dataset[:sample_size]\n",
    "print(f\"Total number of input personas: {len(persona_dataset['persona'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f1a71dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [3:20:20<00:00, 16.64it/s]  \n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    for persona in tqdm(persona_dataset['persona']):\n",
    "        persona = persona.strip()\n",
    "        persona_hub(persona, \"persona\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "26403163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AlbertTokenizer, AlbertForSequenceClassification\n",
    "import random\n",
    "\n",
    "# Define the model name (the name should correspond to the fine-tuned model you want to use)\n",
    "model_name = \"JanSt/albert-base-v2_mbti-classification\"\n",
    "device = get_device()\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AlbertTokenizer.from_pretrained(model_name)\n",
    "model = AlbertForSequenceClassification.from_pretrained(model_name)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "def get_personality_indicator(persona: str):\n",
    "    # Tokenize the text\n",
    "    inputs = tokenizer(persona, return_tensors='pt').to(device)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Get the predicted class\n",
    "    logits = outputs.logits\n",
    "    probabilities = F.softmax(logits, dim=1)\n",
    "    probabilities_list = probabilities.squeeze().tolist()\n",
    "    probabilities_list = {model.config.id2label[i]: p for i, p in enumerate(probabilities_list)}\n",
    "    p_type = max(probabilities_list, key=lambda x: probabilities_list[x])\n",
    "\n",
    "    return p_type, probabilities_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca0e05c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total number of myers-briggs records: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8675</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total number of myers-briggs records: \u001b[1;36m8675\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "mb_dataset = load_dataset(\"kl08/myers-briggs-type-indicator\")['train']\n",
    "print(f\"Total number of myers-briggs records: {len(mb_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2fed0baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADMAAAAQCAYAAAC7mUeyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAABJ0AAASdAHeZh94AAACcElEQVR4nN3XTcgWVRQH8N+rgl8EhQmKC8VwYZGpgSiKKQhiSqloK8M26UYQUcqFcDjtciG6TBTfhe4EW+QHKLkQE4XEhShkuLHIItsEIoK+LeZOjOPz+H48z8oDw50599z7P/85H3dmYGhoyOsiE9qKzFyP3XgX0/AHfsahiLjWst2Cj7AQH+ANnIqIba8CHSXGFzgxDI/nETF+XGvht/gBi3EBR3ATn+JqZradPIBdhczvwwCOFeMWssv1Y7E5TyMymTkD+/AnFkTEX4251WXhNzjZANqD3/CrKkKXhyEyaoyIuFUIddqvjuJRaEZmdnm+3gQpG17Gv5je1kfEvYgYaeGNGqObZOb7WKrKiLNtMvfwFEsy8+3WwpWqerg0Qqe7ST8xdpTxeEQ8o5FmEfFPZn6NQ7iTmd/jEd7BJ7iInWPn0T+MzJyMbXiGY7X+hQYQEYexWUXyS+zHVjzAYDs1xkioHxif4U1ciIgHtbLdzb7CaQyq3tZUfIj7OJWZB3uj0jeMOsW+ayoH6kMzM1eputGZiNjccmAKfsFMzIuI+x2crNd3PWd6xSh27+G2qovOqeuFFyOzoYwvtdeIeIwbxX5RJ5ARSj8wXir8WppkJpaxW2us9U9f5e0w0hNGZk7C56rCP96eb5K5UsYdmTmrtck6LMcT/DQitztLrxhb8RbONwu/lua32WlVj1+Du5l5Bg8xX5UeA9gfEY8aDmzExvI4o4zLMnOw3P8dEft6wWhJnWJHO03+H5mIeI6PVZ8od7AJe1Wn7DmsjYgjrfULsb1ca4tubkO3pWk8RgyQmfOxQlX45zrZDLxOvwD/AQKtKEY3SXSlAAAAAElFTkSuQmCC",
      "text/latex": [
       "$\\displaystyle 8187$"
      ],
      "text/plain": [
       "8187"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from rich import print\n",
    "\n",
    "rdm = random.randint(0, len(mb_dataset))\n",
    "min_len_post = 150 # chars\n",
    "min_posts = 10\n",
    "N = len(mb_dataset)\n",
    "post_list = []\n",
    "\n",
    "for p_type, posts in zip(mb_dataset['type'][:N], mb_dataset['posts'][:N]):\n",
    "    posts = posts.split(\"|||\")\n",
    "    posts = {post for post in posts if \"http\" not in post and \"www\" not in post and len(post) > min_len_post}\n",
    "    if len(posts) > min_posts:\n",
    "        post_list.append(\n",
    "            {\n",
    "                \"type\": p_type,\n",
    "                \"posts\": posts\n",
    "            }\n",
    "        )\n",
    "\n",
    "len(post_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31564d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 500\n",
    "key_words = [\n",
    "    ['Young', 'Modern', 'Joyful', 'Outspoken',   'Inexperienced', \"Open-minded\", 'Smart', \"Change-resistant\", 'selfish', 'Honest', 'Relaxed']\n",
    "]\n",
    "\n",
    "__persona_applicant = []\n",
    "for kw in [\" \".join(k).strip() for k in key_words]:\n",
    "    retrieved = retrieve_persona(text=kw, K=K)\n",
    "    for r in retrieved:\n",
    "        __persona_applicant.append(r[0])\n",
    "\n",
    "\n",
    "\n",
    "key_words = [\n",
    "    [\"friendly\", \"knowledable\", \"professional\", \"women\"],\n",
    "    # [\"racing\", \"adventurer\", \"rich\", \"job\"],\n",
    "]\n",
    "\n",
    "__persona_recruitment = []\n",
    "for kw in [\" \".join(k).strip() for k in key_words]:\n",
    "    retrieved = retrieve_persona(text=kw, K=K)\n",
    "    for r in retrieved:\n",
    "        __persona_recruitment.append(r[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "381cfc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ISTJ -&gt; A talented young coder lured into the world of cybercrime by the promise of making a difference\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ISTJ -> A talented young coder lured into the world of cybercrime by the promise of making a difference\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">INFJ -&gt; a professional woman in STEM from Nigeria\n",
       "</pre>\n"
      ],
      "text/plain": [
       "INFJ -> a professional woman in STEM from Nigeria\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# rdm = random.randint(0, len(persona_dataset['persona']))\n",
    "# persona = persona_dataset['persona'][rdm]\n",
    "\n",
    "persona_applicant = random.choice(__persona_applicant)\n",
    "\n",
    "p_type_applicant, probabilities_list = get_personality_indicator(persona_applicant)\n",
    "\n",
    "persona_applicant_posts = random.choice([ p['posts'] for p in  post_list if p['type'] == p_type_applicant])\n",
    "\n",
    "\n",
    "\n",
    "persona_recruitment = random.choice(__persona_recruitment)\n",
    "\n",
    "p_type_recruitment, probabilities_list = get_personality_indicator(persona_recruitment)\n",
    "\n",
    "persona_recruitment_posts = random.choice([ p['posts'] for p in  post_list if p['type'] == p_type_recruitment])\n",
    "\n",
    "\n",
    "recruitment_posts = \"\\n\".join(random.choices(list(persona_recruitment_posts), k=10))\n",
    "applicant_posts = \"\\n\".join(random.choices(list(persona_applicant_posts), k=10))\n",
    "\n",
    "\n",
    "print(f\"{p_type_applicant} -> {persona_applicant}\")\n",
    "# print(applicant_posts)\n",
    "\n",
    "print(f\"{p_type_recruitment} -> {persona_recruitment}\")\n",
    "# print(recruitment_posts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "223e2ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">|Applicant:| Hi there! I'm interested in the call center agent position. Could you help me with the application \n",
       "process?\n",
       "\n",
       "|Recruiter <span style=\"font-weight: bold\">(</span>Maria<span style=\"font-weight: bold\">)</span>:| Hello! Of course, I'd be happy to help you. My name is Maria. Let's start with the basic form.\n",
       "Please fill out your name, English level, and accept the terms and conditions. Here is the form: <span style=\"font-weight: bold\">[</span>Form Link<span style=\"font-weight: bold\">]</span>\n",
       "\n",
       "|Applicant:| I've completed the form. What's next?\n",
       "\n",
       "|Recruiter <span style=\"font-weight: bold\">(</span>Maria<span style=\"font-weight: bold\">)</span>:| Great! Now, let's move on to a two-question assessment to evaluate your skills. Please answer \n",
       "each question with a long paragraph. Here is the form: <span style=\"font-weight: bold\">[</span>Assessment Form Link<span style=\"font-weight: bold\">]</span>\n",
       "\n",
       "|Applicant:| I've answered the questions. What should I do next?\n",
       "\n",
       "|Recruiter <span style=\"font-weight: bold\">(</span>Maria<span style=\"font-weight: bold\">)</span>:| Wonderful! Now, I need you to record a voice note reading a provided text aloud. This will \n",
       "help us assess your English pronunciation and fluency. Here is the text: `PLACEHOLDER_1`\n",
       "\n",
       "|Applicant:| I've sent the voice note. What's the next step?\n",
       "\n",
       "|Recruiter <span style=\"font-weight: bold\">(</span>Maria<span style=\"font-weight: bold\">)</span>:| Excellent! Finally, I need you to respond to an open-ended question with a voice note. This \n",
       "will allow us to understand your thoughts and opinions. Here is the question: `PLACEHOLDER_2`\n",
       "\n",
       "|Applicant:| I've sent the voice note with my response.\n",
       "\n",
       "|Recruiter <span style=\"font-weight: bold\">(</span>Maria<span style=\"font-weight: bold\">)</span>:| Thank you for completing all the steps. We will review your application and get back to you \n",
       "soon. Do you have any questions in the meantime?\n",
       "\n",
       "|Applicant:| No, that's all for now. Thank you for your help!\n",
       "\n",
       "|Recruiter <span style=\"font-weight: bold\">(</span>Maria<span style=\"font-weight: bold\">)</span>:| You're welcome! Have a great day!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "|Applicant:| Hi there! I'm interested in the call center agent position. Could you help me with the application \n",
       "process?\n",
       "\n",
       "|Recruiter \u001b[1m(\u001b[0mMaria\u001b[1m)\u001b[0m:| Hello! Of course, I'd be happy to help you. My name is Maria. Let's start with the basic form.\n",
       "Please fill out your name, English level, and accept the terms and conditions. Here is the form: \u001b[1m[\u001b[0mForm Link\u001b[1m]\u001b[0m\n",
       "\n",
       "|Applicant:| I've completed the form. What's next?\n",
       "\n",
       "|Recruiter \u001b[1m(\u001b[0mMaria\u001b[1m)\u001b[0m:| Great! Now, let's move on to a two-question assessment to evaluate your skills. Please answer \n",
       "each question with a long paragraph. Here is the form: \u001b[1m[\u001b[0mAssessment Form Link\u001b[1m]\u001b[0m\n",
       "\n",
       "|Applicant:| I've answered the questions. What should I do next?\n",
       "\n",
       "|Recruiter \u001b[1m(\u001b[0mMaria\u001b[1m)\u001b[0m:| Wonderful! Now, I need you to record a voice note reading a provided text aloud. This will \n",
       "help us assess your English pronunciation and fluency. Here is the text: `PLACEHOLDER_1`\n",
       "\n",
       "|Applicant:| I've sent the voice note. What's the next step?\n",
       "\n",
       "|Recruiter \u001b[1m(\u001b[0mMaria\u001b[1m)\u001b[0m:| Excellent! Finally, I need you to respond to an open-ended question with a voice note. This \n",
       "will allow us to understand your thoughts and opinions. Here is the question: `PLACEHOLDER_2`\n",
       "\n",
       "|Applicant:| I've sent the voice note with my response.\n",
       "\n",
       "|Recruiter \u001b[1m(\u001b[0mMaria\u001b[1m)\u001b[0m:| Thank you for completing all the steps. We will review your application and get back to you \n",
       "soon. Do you have any questions in the meantime?\n",
       "\n",
       "|Applicant:| No, that's all for now. Thank you for your help!\n",
       "\n",
       "|Recruiter \u001b[1m(\u001b[0mMaria\u001b[1m)\u001b[0m:| You're welcome! Have a great day!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "prompt = f\"\"\"\n",
    "Generate a conversational chitchat dialogue between an applicant and a recruiter (Maria).\n",
    "All conversation is conducted through WhatsApp.\n",
    "The position to be filled is as an agent in a call center.\n",
    "\n",
    "Take into account the Personas and Myers–Briggs personality types indicator to enrich and make the dialogue more realistic:\n",
    "- Applicant Persona: {persona_applicant}\n",
    "- Applicant Indicator: {p_type_applicant}\n",
    "- Recruiter Persona: {persona_recruitment}\n",
    "- Recruiter Indicator: {p_type_recruitment}\n",
    "\n",
    "Follow the guidances:\n",
    "- The applicant initiates the conversation with a short greeting, it is possible that the applicant did not know the name of the recruiter.\n",
    "- The recruiter's goal is to be proactive and guide the applicant through a series of tasks.\n",
    "- The text includes metadata enclosed in pipe, You should NOT explicitly put this metadata in the generation.\n",
    "- Craft a realistic and engaging conversational dialogue that simulates a real-world recruitment chat.\n",
    "- Ensure the recruiter provides clear guidance and feedback between each task.\n",
    "- Aim to reflect the authentic dynamics of a recruitment process, highlighting both the recruiter's professional advice and the applicant's genuine responses.\n",
    "- No need to reiterate the information in the chat, as it's already captured in the submitted form. Let's move forward with the next steps!\n",
    "- There is no need to transcribe voice notes in chat.\n",
    "- Recruiter should be proactive.\n",
    "- Recruiter should push the applicant to complete each step.\n",
    "- In a new turn the applicant must explicitly indicate whether they completed a step or after sending a voice note.\n",
    "\n",
    "Tasks to be completed during the chat:\n",
    "1. Complete a basic form with required information, As a proactive recruiter, share the form.  |This step consists of the name, English level and accepting the terms and conditions. This form is shared within the chat|\n",
    "2. Answer a two-question assessment within a form to evaluate your skills, it is not necessary to write the questions in the chat as they are included in the form,  As a proactive recruiter, share the form. |The applicant must answer two questions in two long paragraphs|\n",
    "3. Record a voice note reading a provided text aloud and send it to the recruiter, As a proactive recruiter, share the text. |Write `PLACEHOLDER_1` intead of text, The text to be read is random and challenges the applicant's level of English.|\n",
    "4. Respond to an open-ended question with a voice note,  allowing the recruiter to assess their thoughts and opinion, as a proactive recruiter, share the open-ended question. |Write `PLACEHOLDER_2` intead of text.|\n",
    "\"\"\"\n",
    "\n",
    "# llama3_output = llama3(prompt=prompt, temperature=0.5)\n",
    "# llama3_output = \" \".join([out for out in llama3_output])\n",
    "# print(llama3_output)\n",
    "\n",
    "\n",
    "gpt4o_output = gpt4o(prompt=prompt, temperature=0.5)\n",
    "gpt4o_output = \" \".join([out for out in gpt4o_output])\n",
    "print(gpt4o_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8af7c1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">```|Applicant:| Hi there! I'm interested in the call center agent position. Could you help me with the application \n",
       "process?\n",
       "\n",
       "|Recruiter <span style=\"font-weight: bold\">(</span>Maria<span style=\"font-weight: bold\">)</span>:| Hello! Of course, I'd be happy to help you. My name is Maria. Let's start with the basic form.\n",
       "Please fill out your name, English level, and accept the terms and conditions. Here is the form: <span style=\"font-weight: bold\">[</span>Form Link<span style=\"font-weight: bold\">]</span>\n",
       "\n",
       "|Applicant:| I've completed the form. What's next?\n",
       "\n",
       "***System***: Task <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> completed.\n",
       "\n",
       "|Recruiter <span style=\"font-weight: bold\">(</span>Maria<span style=\"font-weight: bold\">)</span>:| Great! Now, let's move on to a two-question assessment to evaluate your skills. Please answer \n",
       "each question with a long paragraph. Here is the form: <span style=\"font-weight: bold\">[</span>Assessment Form Link<span style=\"font-weight: bold\">]</span>\n",
       "\n",
       "|Applicant:| I've answered the questions. What should I do next?\n",
       "\n",
       "***System***: Task <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> completed.\n",
       "\n",
       "|Recruiter <span style=\"font-weight: bold\">(</span>Maria<span style=\"font-weight: bold\">)</span>:| Wonderful! Now, I need you to record a voice note reading a provided text aloud. This will \n",
       "help us assess your English pronunciation and fluency. Here is the text: `PLACEHOLDER_1`\n",
       "\n",
       "|Applicant:| I've sent the voice note. By the way, how long does it usually take to get feedback?\n",
       "\n",
       "|Recruiter <span style=\"font-weight: bold\">(</span>Maria<span style=\"font-weight: bold\">)</span>:| Excellent! It usually takes about <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> business days for us to review your application and get \n",
       "back to you. Now, I need you to respond to an open-ended question with a voice note. This will allow us to \n",
       "understand your thoughts and opinions. Here is the question: `PLACEHOLDER_2`\n",
       "\n",
       "|Applicant:| I've sent the voice note with my response.\n",
       "\n",
       "***System***: Task <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> completed.\n",
       "\n",
       "|Recruiter <span style=\"font-weight: bold\">(</span>Maria<span style=\"font-weight: bold\">)</span>:| Thank you for completing all the steps. We will review your application and get back to you \n",
       "soon. Do you have any other questions in the meantime?\n",
       "\n",
       "|Applicant:| Actually, I'm not sure if I want to continue with this process. I think I might not be interested \n",
       "anymore.\n",
       "\n",
       "|Recruiter <span style=\"font-weight: bold\">(</span>Maria<span style=\"font-weight: bold\">)</span>:| I understand. Thank you for your time and consideration. If you change your mind, please feel \n",
       "free to reach out. Here is a form to schedule a time if you decide to continue with the process: <span style=\"font-weight: bold\">[</span>Scheduling Form \n",
       "Link<span style=\"font-weight: bold\">]</span>\n",
       "\n",
       "***System***: Task <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> completed.\n",
       "```\n",
       "</pre>\n"
      ],
      "text/plain": [
       "```|Applicant:| Hi there! I'm interested in the call center agent position. Could you help me with the application \n",
       "process?\n",
       "\n",
       "|Recruiter \u001b[1m(\u001b[0mMaria\u001b[1m)\u001b[0m:| Hello! Of course, I'd be happy to help you. My name is Maria. Let's start with the basic form.\n",
       "Please fill out your name, English level, and accept the terms and conditions. Here is the form: \u001b[1m[\u001b[0mForm Link\u001b[1m]\u001b[0m\n",
       "\n",
       "|Applicant:| I've completed the form. What's next?\n",
       "\n",
       "***System***: Task \u001b[1;36m1\u001b[0m completed.\n",
       "\n",
       "|Recruiter \u001b[1m(\u001b[0mMaria\u001b[1m)\u001b[0m:| Great! Now, let's move on to a two-question assessment to evaluate your skills. Please answer \n",
       "each question with a long paragraph. Here is the form: \u001b[1m[\u001b[0mAssessment Form Link\u001b[1m]\u001b[0m\n",
       "\n",
       "|Applicant:| I've answered the questions. What should I do next?\n",
       "\n",
       "***System***: Task \u001b[1;36m2\u001b[0m completed.\n",
       "\n",
       "|Recruiter \u001b[1m(\u001b[0mMaria\u001b[1m)\u001b[0m:| Wonderful! Now, I need you to record a voice note reading a provided text aloud. This will \n",
       "help us assess your English pronunciation and fluency. Here is the text: `PLACEHOLDER_1`\n",
       "\n",
       "|Applicant:| I've sent the voice note. By the way, how long does it usually take to get feedback?\n",
       "\n",
       "|Recruiter \u001b[1m(\u001b[0mMaria\u001b[1m)\u001b[0m:| Excellent! It usually takes about \u001b[1;36m1\u001b[0m-\u001b[1;36m2\u001b[0m business days for us to review your application and get \n",
       "back to you. Now, I need you to respond to an open-ended question with a voice note. This will allow us to \n",
       "understand your thoughts and opinions. Here is the question: `PLACEHOLDER_2`\n",
       "\n",
       "|Applicant:| I've sent the voice note with my response.\n",
       "\n",
       "***System***: Task \u001b[1;36m3\u001b[0m completed.\n",
       "\n",
       "|Recruiter \u001b[1m(\u001b[0mMaria\u001b[1m)\u001b[0m:| Thank you for completing all the steps. We will review your application and get back to you \n",
       "soon. Do you have any other questions in the meantime?\n",
       "\n",
       "|Applicant:| Actually, I'm not sure if I want to continue with this process. I think I might not be interested \n",
       "anymore.\n",
       "\n",
       "|Recruiter \u001b[1m(\u001b[0mMaria\u001b[1m)\u001b[0m:| I understand. Thank you for your time and consideration. If you change your mind, please feel \n",
       "free to reach out. Here is a form to schedule a time if you decide to continue with the process: \u001b[1m[\u001b[0mScheduling Form \n",
       "Link\u001b[1m]\u001b[0m\n",
       "\n",
       "***System***: Task \u001b[1;36m4\u001b[0m completed.\n",
       "```\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_prompt = f\"\"\"\n",
    "Given the following WhatsApp Chat Conversation enclosed in a triple backtick, to simulates a real-world recruitment chat perform the following:\n",
    "- With 0.5 probability: between turns, incorporate the applicant's questions, concerns, opinions, doubts, statements, and any other dialogue that may naturally arise during the interaction, the Recruiter should assist the applicant in the new incorporated questions, concerns, opinions, doubts, statements, and any other dialogue that may naturally arise during the interaction.\n",
    "- Restriction: NOT after last step have had completed, only one time between turns, the applicant expresses that they can't continue right now, are busy, or prefer to continue later. They might suggest any alternative way to stop the process and continue later. The Recruiter should assist the applicant by providing a form to schedule a time when the applicant can continue with the process. After the scheduling, simulate a time-elepsed and continue the conversation.\n",
    "- Restriction: The Applicant cannot ask for a task that has already been completed, Sometimes the Applicant ask for resend of any specific form, task or question, reason for resend: the applicant may have missing it in the chat. \n",
    "- Regardless of the conversation flow, for each completed task there is a system notification with a message like this: ***System***: Task N completed, for a scheduled task: ***System***: Scheduled by the user.\n",
    "\n",
    "About the process: Its take no more than 10 minutes to be completed. \n",
    "```{gpt4o_output}```\n",
    "\"\"\"\n",
    "\n",
    "new_prompt = f\"\"\"\n",
    "Given the following WhatsApp Chat Conversation enclosed in a triple backtick, to simulates a real-world recruitment chat perform the following:\n",
    "- With 0.5 probability: between turns, incorporate the applicant's questions, concerns, opinions, doubts, statements, and any other dialogue that may naturally arise during the interaction, the Recruiter should assist the applicant in the new incorporated questions, concerns, opinions, doubts, statements, and any other dialogue that may naturally arise during the interaction.\n",
    "- NOT after last step have had completed, At least one time during the entire conversation, between turns, the applicant expresses that they don't want to continue or they are not interested anymore. The Recruiter should assist the applicant by providing a feedback and sharing a form to schedule a time if the applicant change their mind to continue with the process.\n",
    "- Restriction: The Applicant cannot ask for a task that has already been completed, Sometimes the Applicant ask for resend of any specific form, task or question, reason for resend: the applicant may have missing it in the chat. \n",
    "- Regardless of the conversation flow, for each completed task there is a system notification with a message like this: ***System***: Task N completed, for a scheduled task: ***System***: Scheduled by the user.\n",
    "\n",
    "About the process: Its take no more than 10 minutes to be completed. \n",
    "```{gpt4o_output}```\n",
    "\"\"\"\n",
    "\n",
    "new_prompt = f\"\"\"\n",
    "Given the following WhatsApp Chat Conversation enclosed in a triple backtick, to simulates a real-world recruitment chat perform the following:\n",
    "- With 0.5 probability: between turns, incorporate the applicant's questions, concerns, opinions, doubts, statements, and any other dialogue that may naturally arise during the interaction, the Recruiter should assist the applicant in the new incorporated questions, concerns, opinions, doubts, statements, and any other dialogue that may naturally arise during the interaction.\n",
    "- Restriction: NOT after last step have had completed, in a certain turn, the applicant expresses that they don't want to continue or they are not interested anymore. The Recruiter should assist the applicant by providing a feedback and sharing a form to schedule a time if the applicant change their mind to continue with the process. The applicant does not want to continue and the process ends.\n",
    "- Regardless of the conversation flow, for each completed task there is a system notification with a message like this: ***System***: Task N completed, for a scheduled task: ***System***: Scheduled by the user.\n",
    "\n",
    "About the process: Its take no more than 10 minutes to be completed. \n",
    "```{gpt4o_output}```\n",
    "\"\"\"\n",
    "\n",
    "outputs = gpt4o(prompt=new_prompt, temperature=0.5)\n",
    "outputs = \" \".join([out for out in outputs])\n",
    "print(outputs)\n",
    "\n",
    "# print(new_prompt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54b85464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Prediction</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Applicant: Hi there\\nResponse: Hello! Thank you for reaching out. I'm Maria, and I'll be guiding you </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">through the recruitment process. Could you please start by sharing your full name and the position you are applying</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for?\"</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPrediction\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"Applicant\u001b[0m\u001b[32m: Hi there\\nResponse: Hello! Thank you for reaching out. I'm Maria, and I'll be guiding you \u001b[0m\n",
       "\u001b[32mthrough the recruitment process. Could you please start by sharing your full name and the position you are applying\u001b[0m\n",
       "\u001b[32mfor?\"\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dspy\n",
    "from dspy.functional import TypedPredictor\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from transitions import Machine\n",
    "from dotenv import dotenv_values\n",
    "from rich import print\n",
    "\n",
    "\n",
    "secret = dotenv_values('../../.secret')\n",
    "\n",
    "gpt3_5_turbo  = dspy.OpenAI(\n",
    "    model='gpt-3.5-turbo-0125',\n",
    "    api_key=secret['OPEN_AI_API_KEY'],\n",
    "    max_tokens=4096\n",
    ")\n",
    "\n",
    "gpt4o_recruitment  = dspy.OpenAI(\n",
    "    model='gpt-4o',\n",
    "    api_key=secret['OPEN_AI_API_KEY'],\n",
    "    max_tokens=4096,\n",
    "    system_prompt=f\"\"\"You are a Recruiter (Maria), you conduct a recruiment process through WhatsApp, your Persona description: {persona_recruitment}.\n",
    "    Your goal is to be proactive and guide the applicant through a series of tasks.\n",
    "    Task includes metadata enclosed in pipe, You should NOT explicitly put this metadata in your responses.\n",
    "    Recruiter should push the applicant to complete each step.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "gpt4o_applicant  = dspy.OpenAI(\n",
    "    model='gpt-4o',\n",
    "    api_key=secret['OPEN_AI_API_KEY'],\n",
    "    max_tokens=4096\n",
    ")\n",
    "\n",
    "\n",
    "llama3 = dspy.GROQ(\n",
    "    model='llama3-70b-8192',\n",
    "    api_key=secret['GROQ_API_KEY'],\n",
    "    max_tokens=4096\n",
    ")\n",
    "\n",
    "T = \"\"\"Tasks to be completed during the chat:\n",
    "1. Complete a basic form with required information, As a proactive recruiter, share the form.  |This step consists of the name, English level and accepting the terms and conditions. This form is shared within the chat|\n",
    "2. Answer a two-question assessment within a form to evaluate your skills, it is not necessary to write the questions in the chat as they are included in the form,  As a proactive recruiter, share the form. |The applicant must answer two questions in two long paragraphs|\n",
    "3. Record a voice note reading a provided text aloud and send it to the recruiter, As a proactive recruiter, share the text. |Write `PLACEHOLDER_1` intead of text, The text to be read is random and challenges the applicant's level of English.|\n",
    "4. Respond to an open-ended question with a voice note,  allowing the recruiter to assess their thoughts and opinion, as a proactive recruiter, share the open-ended question. |Write `PLACEHOLDER_2` intead of text.|\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "predict = dspy.Predict(\"applicant -> response\")\n",
    "with dspy.context(lm=gpt4o_recruitment):\n",
    "    print(predict(applicant=\"Hi there\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769fecc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
