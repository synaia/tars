{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9e60719",
   "metadata": {},
   "source": [
    "### Embedding Labs - pgvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62681546-d45d-429c-91b5-4c83c30bd7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pgvector in /Users/beltre.wilton/miniforge3/envs/tars_env/lib/python3.10/site-packages (0.2.5)\n",
      "Requirement already satisfied: psycopg2 in /Users/beltre.wilton/miniforge3/envs/tars_env/lib/python3.10/site-packages (2.9.9)\n",
      "Collecting einops\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy in /Users/beltre.wilton/miniforge3/envs/tars_env/lib/python3.10/site-packages (from pgvector) (1.26.4)\n",
      "Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m723.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: einops\n",
      "Successfully installed einops-0.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pgvector psycopg2 einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3083dba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beltre.wilton/miniforge3/envs/tars_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from dspy.functional import TypedPredictor\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from transitions import Machine\n",
    "from dotenv import dotenv_values\n",
    "from rich import print\n",
    "\n",
    "\n",
    "secret = dotenv_values('../../.secret')\n",
    "llm  = dspy.OpenAI(\n",
    "    model='gpt-3.5-turbo-0125',\n",
    "    # model='gpt-3.5-turbo',\n",
    "    # model='gpt-4',\n",
    "    # model='gpt-4o',\n",
    "    api_key=secret['OPEN_AI_API_KEY'],\n",
    "    max_tokens=4096\n",
    ")\n",
    "\n",
    "dspy.settings.configure(lm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3ea3c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Selecting rows from mobile table using cursor.fetchall\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Selecting rows from mobile table using cursor.fetchall\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Print each row and it's columns values\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Print each row and it's columns values\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">applicant_id =  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "applicant_id =  \u001b[1;36m36\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">lead_stage =  New\n",
       "</pre>\n"
      ],
      "text/plain": [
       "lead_stage =  New\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">PostgreSQL connection is closed\n",
       "</pre>\n"
      ],
      "text/plain": [
       "PostgreSQL connection is closed\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "try:\n",
    "    connection = psycopg2.connect(user=\"drfadul\",\n",
    "                                  password=\"*****\",\n",
    "                                  host=\"localhost\",\n",
    "                                  port=\"5432\",\n",
    "                                  database=\"synaia\")\n",
    "    cursor = connection.cursor()\n",
    "    postgreSQL_select_Query = \"SELECT applicant_id, lead_stage FROM hr_head_check ORDER BY applicant_id DESC LIMIT 1\"\n",
    "\n",
    "    cursor.execute(postgreSQL_select_Query)\n",
    "    print(\"Selecting rows from mobile table using cursor.fetchall\")\n",
    "    mobile_records = cursor.fetchall()\n",
    "\n",
    "    print(\"Print each row and it's columns values\")\n",
    "    for row in mobile_records:\n",
    "        print(\"applicant_id = \", row[0], )\n",
    "        print(\"lead_stage = \", row[1])\n",
    "\n",
    "except (Exception, psycopg2.Error) as error:\n",
    "    print(\"Error while fetching data from PostgreSQL\", error)\n",
    "\n",
    "finally:\n",
    "    # closing database connection.\n",
    "    if connection:\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"PostgreSQL connection is closed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9473bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m,\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "tokenizer_embed = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_embed = AutoModel.from_pretrained('nomic-ai/nomic-embed-text-v1.5', trust_remote_code=True, safe_serialization=True)\n",
    "model_embed.eval()\n",
    "\n",
    "\n",
    "def embedd(text: str):\n",
    "    def mean_pooling(model_output, attention_mask):\n",
    "        token_embeddings = model_output[0]\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "    encoded_input = tokenizer_embed(text, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # + matryoshka_dim = 512\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_output = model_embed(**encoded_input)\n",
    "\n",
    "    embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    # + embeddings = F.layer_norm(embeddings, normalized_shape=(embeddings.shape[1],))\n",
    "    # + embeddings = embeddings[:, :matryoshka_dim]\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "    return np.array(embeddings)[0]\n",
    "\n",
    "text = \"\"\"GlobalConnect Solutions is a premier call center company specializing in providing top-tier customer service, technical support, and sales solutions to businesses of all sizes. \n",
    "        Our services are designed to help companies enhance customer satisfaction, streamline operations, and boost their bottom line.\n",
    "        We serve a wide range of industries including healthcare, finance, retail, telecommunications, travel, and more. \n",
    "        Our versatile team is equipped to handle industry-specific requirements and deliver customized solutions. \"\"\"\n",
    "      \n",
    "print(embedd(text).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5d71bc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Success!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Success!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">PostgreSQL connection is closed\n",
       "</pre>\n"
      ],
      "text/plain": [
       "PostgreSQL connection is closed\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "from pgvector.psycopg2 import register_vector\n",
    "\n",
    "text = \"\"\"We believe in promoting from within and offer various opportunities for career advancement. Employees who demonstrate strong performance and leadership qualities may be considered for promotions and leadership roles.\"\"\"\n",
    "try:\n",
    "    connection = psycopg2.connect(user=\"drfadul\",\n",
    "                                  password=\"*******\",\n",
    "                                  host=\"localhost\",\n",
    "                                  port=\"5432\",\n",
    "                                  database=\"synaia\")\n",
    "    \n",
    "    register_vector(connection)\n",
    "    cursor = connection.cursor()\n",
    "    data = [\n",
    "        (text, embedd(text=text))\n",
    "    ]\n",
    "\n",
    "    execute_values(cursor, \"INSERT INTO company_info (text, embedding) VALUES %s\", data)\n",
    "    connection.commit()\n",
    "\n",
    "    print('\\nSuccess!')\n",
    "\n",
    "except (Exception, psycopg2.Error) as error:\n",
    "    print(\"Error while INSERTING data from PostgreSQL\", error)\n",
    "\n",
    "finally:\n",
    "    # closing database connection.\n",
    "    if connection:\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"PostgreSQL connection is closed\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "2983aaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'Opportunities for career advancement, comprehensive training program, supportive environment. 🌟',\n",
       " 'answer_is_in_context_provided': True}"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dspy\n",
    "from dspy.functional import TypedPredictor\n",
    "from dspy.retrieve.pgvector_rm import PgVectorRM\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from transitions import Machine\n",
    "from dotenv import dotenv_values\n",
    "from rich import print\n",
    "\n",
    "\n",
    "secret = dotenv_values('../../.secret')\n",
    "llm  = dspy.OpenAI(\n",
    "    model='gpt-3.5-turbo-0125',\n",
    "    # model='gpt-3.5-turbo',\n",
    "    # model='gpt-4',\n",
    "    # model='gpt-4o',\n",
    "    api_key=secret['OPEN_AI_API_KEY'],\n",
    "    max_tokens=4096\n",
    ")\n",
    "\n",
    "db_url = \"postgresql://drfadul:*******@localhost/synaia\"\n",
    "retriever_model = PgVectorRM(\n",
    "    db_url=db_url, \n",
    "    pg_table_name=\"company_info\",\n",
    "    k=3,\n",
    "    embedding_func=embedd,\n",
    "    embedding_field=\"embedding\",\n",
    "    fields=[\"text\"],\n",
    "    include_similarity=True\n",
    ")\n",
    "dspy.settings.configure(lm=llm)\n",
    "\n",
    "class NotFound(dspy.Signature):\n",
    "    \"\"\"Generates a denial response related to the question in context\"\"\"\n",
    "    context: str = dspy.InputField()\n",
    "    response: str = dspy.OutputField(desc=\"often between 3 and 7 words\")\n",
    "\n",
    "class Veracity(dspy.Signature):\n",
    "    context_provided: str = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    answer: str = dspy.InputField()\n",
    "    answer_is_in_context_provided: bool = dspy.OutputField(desc=\"verify that the answer is in the context_provided, respond True or False\")\n",
    "\n",
    "\n",
    "class CompanySignature(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers and friendly, use emoji. Answer should be in the context.\"\"\"\n",
    "    context: str = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question: str = dspy.InputField(desc=\"user question to be answered\")\n",
    "    answer: str = dspy.OutputField(desc=\"often between 6 and 12 words\")\n",
    "\n",
    "\n",
    "class CompanyRelated(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.retriever = retriever_model\n",
    "        self.predict = dspy.ChainOfThought(CompanySignature)\n",
    "        self.veracity = dspy.TypedChainOfThought(Veracity)\n",
    "        self.not_found = dspy.Predict(NotFound)\n",
    "    \n",
    "    def forward(self, question: str):\n",
    "        context = self.retriever(question)\n",
    "        context = [ctx['text'] for ctx in context]\n",
    "        response = self.predict(context=context, question=question)\n",
    "        veracity = self.veracity(context_provided=str(context), answer=response.answer)\n",
    "        if veracity.answer_is_in_context_provided:\n",
    "            r = response\n",
    "            return {\n",
    "                \"answer\": r.answer,\n",
    "                \"answer_is_in_context_provided\": veracity.answer_is_in_context_provided\n",
    "            }\n",
    "        else:\n",
    "            r = self.not_found(context=question)\n",
    "            return {\n",
    "                \"answer\": r.response,\n",
    "                \"answer_is_in_context_provided\": veracity.answer_is_in_context_provided\n",
    "            }\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "search = CompanyRelated()\n",
    "# search(question=\"Good morning! What are the company's main products or services?\")\n",
    "# search(question=\"Hey! Can you provide some information about the company's technology stack?\")\n",
    "# search(question=\"Hello! How does the company foster employee growth and development?\")\n",
    "# search(question=\"Hi! How does the company encourage innovation among its employees?\")\n",
    "# search(question=\"Hi! What's the company's approach to employee wellness?\")\n",
    "search(question=\"What kind of benefits do you offer to employees?\")\n",
    "# search(question= \"Can I work part time?\",)\n",
    "# search(question=\"What tools and technologies will I be using?\")\n",
    "# search(question=\"How diverse is your team?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e0ee5899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers and friendly, use emoji. Answer should be in the context.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may contain relevant facts\n",
      "\n",
      "Question: user question to be answered\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "\n",
      "Answer: often between 6 and 12 words\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «We believe in promoting from within and offer various opportunities for career advancement. Employees who demonstrate strong performance and leadership qualities may be considered for promotions and leadership roles.»\n",
      "[2] «All new employees undergo a comprehensive training program that includes an introduction to our company culture, systems, and procedures. Depending on your role, you may receive additional training on specific tools, products, or services.»\n",
      "[3] «Our work environment is dynamic, inclusive, and supportive. We value collaboration, innovation, and respect. We strive to create a space where employees feel valued and motivated to contribute their best.»\n",
      "\n",
      "Question: What kind of benefits do you offer to employees?\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m provide a concise answer that highlights the benefits offered to employees.\n",
      "\n",
      "Answer: Opportunities for career advancement, comprehensive training program, supportive environment. 🌟\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Given the fields `context_provided`, `answer`, produce the fields `answer_is_in_context_provided`.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context Provided: may contain relevant facts\n",
      "\n",
      "Answer: ${answer}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer_is_in_context_provided}. We ...\n",
      "\n",
      "Answer Is In Context Provided: verify that the answer is in the context_provided, respond True or False (Respond with true or false)\n",
      "\n",
      "---\n",
      "\n",
      "Context Provided: ['We believe in promoting from within and offer various opportunities for career advancement. Employees who demonstrate strong performance and leadership qualities may be considered for promotions and leadership roles.', 'All new employees undergo a comprehensive training program that includes an introduction to our company culture, systems, and procedures. Depending on your role, you may receive additional training on specific tools, products, or services.', 'Our work environment is dynamic, inclusive, and supportive. We value collaboration, innovation, and respect. We strive to create a space where employees feel valued and motivated to contribute their best.']\n",
      "\n",
      "Answer: Opportunities for career advancement, comprehensive training program, supportive environment. 🌟\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m produce the answer_is_in_context_provided. The context provided mentions that the company believes in promoting from within and offers opportunities for career advancement, all new employees undergo a comprehensive training program, and the work environment is dynamic, inclusive, and supportive. The answer includes key phrases such as \"opportunities for career advancement,\" \"comprehensive training program,\" and \"supportive environment,\" which are directly related to the information provided in the context.\n",
      "\n",
      "Answer Is In Context Provided: True\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nAnswer questions with short factoid answers and friendly, use emoji. Answer should be in the context.\\n\\n---\\n\\nFollow the following format.\\n\\nContext: may contain relevant facts\\n\\nQuestion: user question to be answered\\n\\nReasoning: Let\\'s think step by step in order to ${produce the answer}. We ...\\n\\nAnswer: often between 6 and 12 words\\n\\n---\\n\\nContext:\\n[1] «We believe in promoting from within and offer various opportunities for career advancement. Employees who demonstrate strong performance and leadership qualities may be considered for promotions and leadership roles.»\\n[2] «All new employees undergo a comprehensive training program that includes an introduction to our company culture, systems, and procedures. Depending on your role, you may receive additional training on specific tools, products, or services.»\\n[3] «Our work environment is dynamic, inclusive, and supportive. We value collaboration, innovation, and respect. We strive to create a space where employees feel valued and motivated to contribute their best.»\\n\\nQuestion: What kind of benefits do you offer to employees?\\n\\nReasoning: Let\\'s think step by step in order to\\x1b[32m provide a concise answer that highlights the benefits offered to employees.\\n\\nAnswer: Opportunities for career advancement, comprehensive training program, supportive environment. 🌟\\x1b[0m\\n\\n\\n\\n\\n\\nGiven the fields `context_provided`, `answer`, produce the fields `answer_is_in_context_provided`.\\n\\n---\\n\\nFollow the following format.\\n\\nContext Provided: may contain relevant facts\\n\\nAnswer: ${answer}\\n\\nReasoning: Let\\'s think step by step in order to ${produce the answer_is_in_context_provided}. We ...\\n\\nAnswer Is In Context Provided: verify that the answer is in the context_provided, respond True or False (Respond with true or false)\\n\\n---\\n\\nContext Provided: [\\'We believe in promoting from within and offer various opportunities for career advancement. Employees who demonstrate strong performance and leadership qualities may be considered for promotions and leadership roles.\\', \\'All new employees undergo a comprehensive training program that includes an introduction to our company culture, systems, and procedures. Depending on your role, you may receive additional training on specific tools, products, or services.\\', \\'Our work environment is dynamic, inclusive, and supportive. We value collaboration, innovation, and respect. We strive to create a space where employees feel valued and motivated to contribute their best.\\']\\n\\nAnswer: Opportunities for career advancement, comprehensive training program, supportive environment. 🌟\\n\\nReasoning: Let\\'s think step by step in order to\\x1b[32m produce the answer_is_in_context_provided. The context provided mentions that the company believes in promoting from within and offers opportunities for career advancement, all new employees undergo a comprehensive training program, and the work environment is dynamic, inclusive, and supportive. The answer includes key phrases such as \"opportunities for career advancement,\" \"comprehensive training program,\" and \"supportive environment,\" which are directly related to the information provided in the context.\\n\\nAnswer Is In Context Provided: True\\x1b[0m\\n\\n\\n'"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.inspect_history(n=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
